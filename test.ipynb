{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/sagaruprety/miniconda3/envs/participatory-ai-for-workshops/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from docling.document_converter import DocumentConverter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Article\n",
      "\n",
      "<!-- image -->\n",
      "\n",
      "## Human-AI Interactions in Public Sector Decision Making: 'Automation Bias' and 'Selective Adherence' to Algorithmic Advice\n",
      "\n",
      "<!-- image -->\n",
      "\n",
      "Saar Alon-Barkat, *, Madalina Busuioc †,\n",
      "\n",
      "*University of Haifa, Israel\n",
      "\n",
      "†\n",
      "\n",
      "Vrije Universiteit Amsterdam, The Netherlands\n",
      "\n",
      "Address correspondence to the author at e.m.busuioc@vu.nl.\n",
      "\n",
      "## Abstract\n",
      "\n",
      "Artificial intelligence algorithms are increasingly adopted as decisional aides by public bodies, with the promise of overcoming biases of human decision-makers. At the same time, they may introduce new biases in the human-algorithm interaction. Drawing on psychology and public administration literatures, we investigate two key biases: overreliance on algorithmic advice even in the face of 'warning signals' from other sources ( automation bias ), and selective adoption of algorithmic advice when this corresponds to stereotypes ( selective adherence ).  We assess these via three experimental studies conducted in the Netherlands: In study 1 ( N = 605), we test automation bias by exploring participants' adherence to an algorithmic prediction compared to an equivalent human-expert prediction. We do not find evidence for automation bias. In study 2 ( N = 904), we replicate these findings, and also test selective adherence . We find a stronger propensity for adherence when the advice is aligned with group stereotypes, with no significant differences between algorithmic and human-expert advice. In study 3 ( N = 1,345), we replicate our design with a sample of civil servants. This study was conducted shortly after a major scandal involving public authorities' reliance on an algorithm with discriminatory outcomes (the 'childcare benefits scandal'). The scandal is itself illustrative of our theory and patterns diagnosed empirically in our experiment, yet in our study 3, while supporting our prior findings as to automation bias, we do not find patterns of selective adherence. We suggest this is driven by bureaucrats' enhanced awareness of discrimination and algorithmic biases in the aftermath of the scandal. We discuss the implications of our findings for public sector decision making in the age of automation. Overall, our study speaks to potential negative effects of automation of the administrative state for already vulnerable and disadvantaged citizens.\n",
      "\n",
      "## Introduction\n",
      "\n",
      "Artificial intelligence (AI) algorithms are being widely adopted in the public sector across jurisdictions. Essentially a set of tools that display (or can even surpass) human-level performance on  given  tasks  traditionally  associated  with  human  intelligence, AI algorithms are being relied upon in areas as varied as policing, welfare, criminal justice, healthcare, immigration, or education (Busuioc 2021; Calo and Citron 2021; Diakopoulos 2014;  Eubanks  2018;  Engstrom  et  al.  2020;  O'Neil  2016; Richardson,  Schultz,  and  Crawford  2019;  Veale  and  Brass 2019;  Yeung  and  Lodge  2019),  increasingly  permeating non-routine and high-stakes aspects of bureaucratic work. The growing and deepening reliance on AI and machine learning technologies in the public sector has been diagnosed as 'transformative' of public administrations (Bullock 2019; Vogl et al. 2020; Young, Bullock, and Lecy 2019).\n",
      "\n",
      "These  developments  are  driven  by  the  promise  of  policy solutions  that  are  potentially  more  effective,  efficient,  and low-cost. In addition, and importantly, algorithms are said to come with the 'promise of neutrality,' in contrast to decision making based on human intuition, which involves biases and can result in discrimination. In other words, AI use in decision making is said to hold the potential to help us overcome our cognitive biases and limitations. This has been an important  driver  for  the  adoption  of  such  technologies  in  highly consequential public sector areas such as law enforcement or criminal justice: Predictive policing technologies, for instance, were propagated in the US context 'as one answer to racially discriminatory policing, offering a seemingly race-neutral,  'objective' justification for police targeting of poor communities' (Ferguson  2017,  5). Numerous  other  jurisdictions  have followed suit with predictive technologies relied upon by police forces in the United Kingdom, the Netherlands, Germany, among many others. Like rationales precipitated the adoption of predictive risk assessment systems in criminal justice, similarly  in  part  in  response to concerns with human bias and discrimination (Israni 2017), despite such systems themselves being flagged as sources of bias (Angwin et al. 2016).\n",
      "\n",
      "We thank the three anonymous JPART reviewers for their extremely helpful comments. We are also grateful to Dimiter Toshkov, Nadine Raaphorst, Joris  van  der  Voet,  Dana  Vashdi,  Sharon  Gilad,  Markus  Tepe,  Stephan Grimmelikhuijsen,  Thijs  de  Boer,  Benjamin  Tidå,  Omer  Yair,  and  Aaron Swaving for their valuable comments and feedback in the process of developing this project. We thank Luuk van Roozendaal for excellent research assistance.\n",
      "\n",
      "For a large part, AI algorithms currently serve as decisional aides to human  decision-makers  ('decision-support  systems') in many bureaucratic contexts. This is especially so in  highly  consequential  public  sector  areas,  where 'full  automation seems inappropriate or far off' (Edward and Veale 2017, 45). Rather than making decisions on their own, algorithmic  outputs-be  they  risk  assessment  scores  used  in criminal  justice  or  the  algorithm-generated 'heat  maps'  of\n",
      "\n",
      "predictive  policing-support  human  decision  making.  As such, algorithms do not remove the human decision-maker out  of  the  equation-instead,  algorithmic  decision  making arises at the interaction of the two.\n",
      "\n",
      "For  all  its  promise,  the  deployment  of  AI  algorithmic technologies in the public sector has raised important concerns. High among these are concerns with algorithmic accountability and oversight of algorithmic outputs (Busuioc 2021;  Diakopoulos  2014);  issues  of  'algorithmic  bias'the well-documented propensity of algorithms to learn systemic bias through, among others, their reliance on historical data and come to perpetuate it, effectively 'automating inequality' (Eubanks 2018); as well as the potential for bias arising  from  human processing of  AI  algorithmic  outputs. This article focuses on the latter, which we believe is an important and especially worthy aspect of analysis in light of algorithms' roles as decisional aids in public sector decision making. In this context, it becomes important to understand the implications of these technologies in shaping public sector decision making and specific cognitive biases that might arise in this respect. This gains yet further relevance as in the context of the rise of algorithmic governance, human decisionmakers are regarded as important safeguards, as decisional mediators,  on  issues  of  algorithmic  bias.  Investigating  to what extent our cognitive limits allow us to act as effective decisional mediators becomes critical in an increasingly automated administrative state.\n",
      "\n",
      "In this article, we focus on two diverging biases , theorizing on  the  basis  of  two  strands  of  literature  from  different disciplines  that  have  thus  far  not  spoken  to  each  other  on this  topic.  The  first  bias,  which  builds  on  previous  social psychology  studies  is automation  bias .  It  refers  to  a  welldocumented human propensity to automatically defer to automated  systems,  despite  warning  signals  or  contradictory information from other sources. In other words, human actors are found to uncritically abdicate their decision making to automation. While robust, these findings have been documented for AI algorithmic precursors such as pilot navigation systems and in fields outside a public sector context. The second bias we theorize and test can be extrapolated from existing public administration  research  on  biased  information  processing, and pertains to decision-makers' selective adherence to algorithmic advice. Namely, the propensity to adopt algorithmic advice  selectively,  when  it  matches  pre-existing  stereotypes about decision subjects  (e.g.,  when  predicting  high  risk  for members  of  negatively  stereotyped  minority  groups).  This bias has not yet been investigated in our field with respect to algorithmic sources.\n",
      "\n",
      "We report  the  results  of  three  survey  experiment  studies conducted in the Netherlands, which provide rigorous tests for these hypothesized biases. In study 1 ( N = 605), we put automation bias to test by exploring participants' adherence to  an  algorithmic  prediction  (which  contradicts  additional evidence)  and  comparing  it  to  an  equivalent  human-expert prediction. In study 2 ( N = 904), we replicate these findings, and at the same time, we also test whether decision subjects' ethnic  background  moderates  decision-makers'  inclination to  follow  the  algorithmic  advice.  In  other  words,  whether respondents  are  more  likely  to  follow  an  algorithmic  advice when this prediction is aligned with pre-existing group stereotypes (engaging in 'selective' rather than automatic adherence). Studies 1 and 2 were conducted among citizens in a context where citizens can act as decision-makers. In study 3, we set out to further replicate our findings with a sample of Dutch civil servants ( N = 1,345). During our preparations for  that  study,  a  major  political  scandal  occurred  in  the Netherlands (the 'childcare benefits scandal'), involving algorithm use by public authorities. The scandal involved tax authorities' reliance as a decisional aid on an AI algorithm that used nationality as a discriminant predictive feature, with ensuing  bureaucratic  decisions  reflecting  discrimination  of minority groups. We discuss the results of study 3 in light of its co-occurrence with these events, which closely align with our theory.\n",
      "\n",
      "Our  focus  is  on  human  processing  biases  arising  from the  use  of  AI  algorithms  in  a public  sector  context. While we would expect such biases to be equally relevant for algorithmic  decision  making  in  the  private  sector,  we  focus on  the  public  sector  because  the  stakes  are  especially  high for  governments. AI algorithms are increasingly adopted in high-stakes  areas-where  they  are  highly  consequential  for individual's lives, rendering these questions especially pressing in a public sector context.\n",
      "\n",
      "## Automation and Decision Making in the Public Sector: A  T ale of  T wo Biases\n",
      "\n",
      "An important  and  growing  literature  in  public  administration is concerned with the effects of the increasing reliance on digital technologies for public sector decision making. A key concern in particular pertains to the implications of these technologies for the discretion and professional judgment of decision-makers  such  as  (street-level)  bureaucrats  (Bovens and  Zouridis  2002).  This  literature  has  flagged  the  potential, in the age of automation, for 'digital discretion' (Busch and Henriksen 2018), 'automated discretion' (Zouridis, van Eck, and Bovens 2020) or specifically in the context of AI, 'artificial  discretion'  (Young,  Bullock,  and  Lecy  2019)  to supplant the discretion of bureaucratic actors in the administration  (see  also  Buffat  2015;  Bullock  2019;  de  Boer  and Raaphorst 2021). In other words, the potential of digital tools to 'influence or replace human judgment' in public service provision (Busch and Hendriksen 2018, 4) and to alter the very nature of public managers' work (Kim, Andersen, and Lee 2021) and bureaucratic structures and routines (Meijer, Lorenz, and Wessels 2021). Such tools stand to fundamentally shape public sector decision making through constraining, or even  removing,  the  scope  for  human  expertise  and  discretion or influencing human judgment and cognition in unexpected  ways.  In  doing  so,  the  delegation  of  administrative decision-making  authority  to  AI  technologies  could  have profound  implications  for  bureaucratic  legitimacy  (Busuioc 2021)  and  public  values  more  broadly  (Schiff,  Schiff,  and Pierson 2021).\n",
      "\n",
      "In this context, it becomes important therefore to understand how decision-makers in a public sector context process algorithmic outputs used as decisional aids, how they incorporate them into their decision making, their implications and whether these differ in significant ways from the processing of traditional  (human-sourced)  advice.  To  operationalize the potential implications of AI advice for decision making, and given limited theorizing of potential cognitive biases in this emerging area, we borrow from, theorize and integrate insights from two separate strands of literature, which offer\n",
      "\n",
      "important  starting  points  to  unpack  this  topic:  social  psychology literature on automation and public administration research on information processing. Interestingly, these two literatures  offer  us  somewhat  competing  projections  as  to what to expect.\n",
      "\n",
      "## Automation Bias: Automatic Adherence to Algorithmic Advice\n",
      "\n",
      "While AI is meant to help us overcome our biases, research from  social  psychology  suggests  that  automated  systems might  give  rise  to  new  and  distinct  biases  arising  from human processing of automated outputs. 'Automation bias'  is  a  well-recognized  decisional  support  problem  that has emerged from studies in aviation and healthcare, areas that  have  traditionally  heavily  relied  on  automated  tools. Automation bias refers to undue deference to automated systems by human actors that disregard contradictory information  from  other  sources  or  do  not  (thoroughly)  search  for additional information (Cummings 2006; Lyell and Coiera 2017;  Mosier  et  al.  2001;  Parasuraman  and  Riley  1997; Skitka, Mosier, and Burdick 1999, 2000; Skitka et al. 2000). In other words, it is manifest in the 'the use of automation as a heuristic replacement for vigilant information seeking and processing' (Mosier et al. 1998, 201), a 'short cut that prematurely shuts down situation assessment' (Skitka, Mosier, and Burdick 2000, 714).\n",
      "\n",
      "Experimental  lab  studies  have  diagnosed  this  tendency across a number of research fields (Goddard, Roudsari, and Wyatt  2012).  While  robust,  these  findings  have  not  been investigated in  a  bureaucratic  context .  As  such,  we  do  not know to what extent such biases are relevant and replicate in  administrative  contexts.  Extant  studies  suggest  that  this propensity  to  defer  to  automation  stems  on  the  one  hand, from  the  perceived  inherent  superiority  of  automated  systems by human actors and on the other, from 'cognitive laziness,' a human reluctance to engage in cognitively demanding mental  processes,  including  thorough  information  search and  processing  (Skitka,  Mosier,  and  Burdick  2000,  702). Research findings on automation bias are further supported by ample anecdotal evidence of automation bias with respect to  commercial flights  (Skitka  et  al.  2000,  703),  car  navigation  systems  (Milner  2016)  and  more  recently,  also  specifically  documented  in  the  context  of AI  for  self-driving  cars (National Transportation  Safety  Board  2017).  Recent  business  management  experiment-based  studies  similarly  talk about 'algorithm appreciation' (Logg, Minson, and Moore 2019), describing a similar tendency to over-trust algorithmic outputs.\n",
      "\n",
      "Concerns  with automation  bias have  been  increasingly voiced by scholars in the context of a growing reliance on AI tools in the public sector and high-stakes scenarios (Cobbe 2019;  Edwards  and  Veale  2017;  Medium-Open  Letter Concerned AI Researchers 2019; Zerilli et al. 2019), and increasingly so also by public administration scholars (Busuioc 2021;  Peeters  2020;  Giest  and  Grimmelikhuijsen  2020; Young  et  al.  2021).  More  broadly,  this  also  corresponds to  concerns  raised  by  public  administration  literature,  as discussed above, on the potential of AI algorithmic tools (and digital  tools  more  broadly)  to  replace  bureaucratic  discretion and professional judgment. Our investigation into automation bias speaks directly to this literature through setting out to elucidate whether the scope for discretion of human decision-makers is removed through the introduction of such tools.\n",
      "\n",
      "Such  concerns  become  particularly  relevant  given  welldocumented  failures  and  malfunctioning  of  AI(-informed) systems (e.g., Benjamin 2019; Buolamwini and Gebru 2018; Ferguson  2017;  Eubanks  2018;  O'Neill  2016;  Richardson, Schultz,  and  Crawford  2019;  Rudin  2019).  Due,  among others,  to  model  and/or  data  inadequacies,  AI  algorithms have been found to reproduce and automate systemic bias, and to do so in ways that, by virtue of their opaqueness and/ or high complexity, have proven difficult to diagnose for both domain experts and system engineers alike. A human propensity for default deference to algorithmic systems under such circumstances  would  become  especially  problematic-even more so  given  the  high-stakes  of AI  use  in  a  public  sector context.\n",
      "\n",
      "H1 -Decision-makers are more likely to trust and to follow  algorithmic  advice  than  human  advice,  when  faced with similar contradicting external evidence. (automation bias)\n",
      "\n",
      "## Selective Adherence to Algorithmic Advice\n",
      "\n",
      "We theorize a second, diverging concern regarding decisionmakers' use of algorithmic advice extrapolating from behavioral work on public decision-makers' information processing . Following  a motivated  reasoning logic,  this  growing  body of literature has established that decision-makers are prone to selectively seek and interpret information in light of preexisting  stereotypes,  beliefs,  and  social  identities.  They  assign  greater  weight  to  information  congruent  with  prior beliefs  and  contest  inputs  that  contradict  them  (Baekgaard et  al.  2019;  Baekgaard  and  Serritzlew  2016;  Christensen et  al.  2018;  Christensen 2018; James and Van Ryzin 2017; Jilke  2017;  Jilke  and  Baekgaard  2020). These  studies  have demonstrated these 'confirmation biases' with regards to the processing and interpretation of 'unambiguous' information such as performance indicators. However, this has not been explicitly  theorized nor investigated yet in relation to algorithmic decisional aides.\n",
      "\n",
      "We theoretically extend this literature, and argue that this motivated reasoning mechanism would apply not only to information inputs generated by humans, but also to information  produced  by AI  algorithms. Thus,  we  would  similarly expect  decision-makers  to  adhere  to  algorithmic  advice selectively , when it matches stereotypical views of the decision subject  (rather  than  by  default,  as  expected  by  automation bias literature). This theoretical expectation also corresponds to works on bureaucratic discrimination indicating that bureaucratic  decision-makers  search  for  stereotype-consistent cues  in  their  decisions,  or  respond  to  them  unconsciously (e.g., Andersen and Guul 2019; Assouline, Gilad, and Bloom 2022; Jilke and Tummers 2018; Pedersen et al. 2018; Schram et al. 2009). In this regard, we theorize that an algorithmic prediction that accords with a group stereotype would similarly  amount  to  such  a  cue,  which  provides  expectancy confirmation.\n",
      "\n",
      "While  public  administration  scholars  have  thus  far  not investigated  selective  processing  of  algorithmic  outputs,  it has been the subject of recent investigations by law and computer  science  scholars  in  studies  on  the  use  of  algorithmic\n",
      "\n",
      "risk assessment by criminal courts (Green and Chen 2019a, 2019b;  Stevenson  2018),  diagnosing  patterns  that  are  consistent with selective adherence and motivated reasoning.\n",
      "\n",
      "Hence, extrapolating from and theorizing on the basis of these literatures we first hypothesize that:\n",
      "\n",
      "H2 -Decision-makers  are  more  likely  to  follow  advice (human or algorithmic-based) that matches stereotypical views of the decision subjects. (selective adherence)\n",
      "\n",
      "To clarify,  H   pertains  to  the  expectation  that  selective  ad2 herence biases diagnosed for human-sourced advice are also present  for  algorithmic  advice,  that  is, selective  adherence, across  both  human  and  algorithmic  advice  types .  In  other words,  we  theorize  that  these  biases  persist  (do  not  disappear) in the adoption of algorithms in public sector decision making. Establishing whether selective adherence is present is  important  in  a  context  where  AI  algorithms  are  said  to have the potential to do away with human decisional biases. What is more, the presence of selective adherence biases gains special relevance in the algorithmic case. As evidence of systematic algorithmic biases is accumulating, human decisionmakers in-the-loop are seen as critical checks, in their roles as decisional  mediators.  Investigating  the  presence  of  selective adherence, importantly, therefore, also speaks to the extent to which human decision-makers can actually function as effective decisional mediators and safeguards against such risks.\n",
      "\n",
      "If selective adherence biases are to persist, the next question  is  whether  they  are  more  emphasized  in  the  use  of algorithms. Are decision-makers more prone to selective adherence to algorithmic advice compared to equivalent human advice? In other words, do algorithmic outputs exacerbate the risk of selective adoption and discriminatory decisions? We theorize  that  algorithms  have  the  potential  to  amplify these biases due to their unique nature. Literature on automation has theorized that automated decisional aids tend to create a 'moral buffer,' acting as a psychological distancing mechanism resulting in a diminished sense of moral agency, personal  responsibility  and  accountability  for  the  human actor  'because  of  a  perception  that  the  automation  is  in charge'  (Cummings 2006, 8). These feelings of moral and ethical disengagement and decreased responsibility may reduce  decision-makers'  awareness  of  potential  biases  and implicit  prejudice.  Or  worse:  the  algorithmic  advice  could vindicate  and  give  free  license  to  decision-makers'  latent views  (racial,  xenophobic,  misogynistic,  etc.)  by  providing them with a seemingly legitimate reason to adopt discriminatory decisions. Algorithms, in other words, could serve to 'give permission' to decision-makers to act on their biases: Algorithms'  face-value  'neutral'  or  'objective'  character would fend-off potential suspicions of bias and/or confirm the validity of biased or prejudiced decisions. An algorithmic recommendation aligned with decision-makers' own biases could  amount  to  a  powerful  (mathematical!)  endorsement thereof. We therefore expect biased adherence to become especially  emphasized  for  algorithmic  advice  by  comparison with human advice.\n",
      "\n",
      "Consequently, we further hypothesize that:\n",
      "\n",
      "H3 -Selective adherence is likely to be exacerbated when decision-makers receive an algorithmic rather than a human advice. (exacerbated selective adherence)\n",
      "\n",
      "## Empirical Evidence from Previous Studies\n",
      "\n",
      "To date, we lack systematic empirical evidence about the prevalence of cognitive biases in algorithm-based public sector decision-making.  Existing  peer-reviewed  empirical  studies  on this topic are from law and computer science scholars in the context of algorithm use in pretrial criminal justice decisions in the United States. These studies stem from the underlying concern with high levels of detention in the United States and its growing carceral state and are aimed at investigating the promise of algorithmic risk assessments to decrease detention levels through improving the accuracy of judges' assessments of recidivism risk. Their tentative findings, as detailed below, are consistent with our theorized patterns of selective adherence .  Stevenson (2018) uses archival data of criminal cases from the state of Kentucky to compare observationally detention rates before and after a reform in 2011 that made risk assessment mandatory in pretrial procedures. She finds that the expansion in the use of risk scores led to an overall increase in pretrial release immediately after the implementation of the reform, however, this eroded and almost disappeared within a matter of years. Additionally, the study finds that judges were more likely to accept low scores for white defendants, while overriding similar scores for black defendants.\n",
      "\n",
      "These findings are further supported by a series of experimental studies among laypersons (Green and Chen 2019a, 2019b;  Grgi -Hla a,  Engel,  and  Gummadi  2019).  These ć č studies  include  a  judicial  decision-making  task  in  which participants are shown details of arrests and are asked to predict recidivism risk, comparing participants' predictions with/ without an algorithmic risk assessment. Grgi ć -Hla a, Engel, č and Gummadi (2019) find that participants did not significantly change their decisions in response to the algorithmic prediction, even when they receive feedback about its high accuracy or are incentivized to make correct predictions. Green and Chen (2019a, 2019b) further compare between outcomes for black and white defendants and diagnose participant reliance  on  algorithms  indicative  of 'disparate  interactions': participants  adhered  to  the  algorithmic  advice  to  a  greater degree when it predicted either high risk for a black defendant or low risk for a white defendant.\n",
      "\n",
      "All  in  all,  while  most  of  these  studies  demonstrate  that public decision-makers can be affected in their decisions by algorithmic decisional aids, they do not provide particularly strong  evidence  for  automatic  deference  to  algorithmic  advice, as would be expected on the basis of automation bias literature. They provide instead tentative empirical evidence that decision-makers tend to process such advice in a biased, selective manner.\n",
      "\n",
      "Still, these  studies  have  several  important  limitations. First , while the aim of these studies was to learn about the influence  of  algorithmic  decisional  aids,  their  comparison was only to a condition where decision-makers did not receive  any  advice  at  all,  as  opposed  to  comparable  human expert advice. It is an open question, therefore, whether the effects found are attributed to algorithms per se ,  or rather that  other  professional  advice  that  similarly  includes  numeric outputs would yield the same outcome. We propose that in order to isolate the distinct effect of algorithms, the appropriate counterfactual should be an equivalent numeric advice produced by a human expert. Second , we argue that these  studies  are  ill-equipped  to  investigate  automation bias,  since  they  lacked  additional  contradictory  evidence\n",
      "\n",
      "or inputs from other sources. Rather, automation bias can be  tested  effectively  by  supplementing  the  algorithmic  advice with such additional inputs, a condition which 'forces' decision-makers to choose whether to rely on the automated authority or rather take into account additional information and indicators. A similar approach was applied by previous automation  bias  experimental  studies,  where  participants were given automated aids not aligned with other indicators (Mosier et al. 1998; Skitka, Mosier, and Burdick 1999, 2000; Skitka et al. 2000). Thirdly , these studies are focused on the application of algorithms in one specific policy context. It is important to explore the generalizability of these patterns to additional public policy areas, especially given the rapid spread  of  algorithms  across  various  policy  contexts  and jurisdictions.\n",
      "\n",
      "Below, in the methodology section, we present our unique research design, and discuss how it overcomes these limitations.\n",
      "\n",
      "## Research Design\n",
      "\n",
      "To  examine  our  hypotheses,  we  designed  and  conducted  a series of three unique survey experiments among Dutch citizens and civil servants. Study 1 ( N = 605) was designed to test our automation bias hypothesis. Study 2 ( N = 904) was designed to replicate study 1 on a separate sample, as well as to test our two hypotheses regarding selective adherence to algorithmic advice. Studies 1 and 2 were conducted among Dutch citizens in a context where citizens can act as decisionmakers.  Thereafter,  in  study  3  ( N =  1,345),  we  repeated our experimental design with a large sample of Dutch civil servants. The demographic characteristics of our samples are summarized in Appendix 2.\n",
      "\n",
      "The studies involve an administrative decision-making task that concerns local school board decisions on the employment of teachers. As elaborated below, we utilized a hypothetical scenario of an algorithmic performance evaluation tool, used as a decisional aid for the assessment of Dutch high-school teachers.\n",
      "\n",
      "In  the  Netherlands,  members  of  such  boards  are  not  required to complete a specific professional certification,  and are  composed,  among  others,  of  volunteers  (lay  persons) such as parents or citizens from the local community (OECD 2014a, 14; OECD 2014b, 22, 98). As such, lay citizens are relevant  decision-makers  in  this  context.  Moreover,  to  further enhance the external validity of our study, we additionally  replicate  the  study  with  a  large  sample  of  actual  civil servants-Dutch decision-makers from various policy areas and  across  government  levels.  An  important  advantage  of our choice of empirical setting is that it involves a bureaucratic task that can be relatively easily exercised in a vignette survey experiment with participants who are not necessarily experts on the specific task, allowing us to test our expectations among decision-makers in a public sector context more broadly.  Our explicit  aim  is  to  tap  into  generalized  human biases in algorithm-supported decision making in the public sector.\n",
      "\n",
      "Our decision to focus on the education setting in the vignette was inspired by the real-life case of Sarah Wysocki-a teacher in the United States who was fired based on the prediction  of  an  algorithmic  score,  while  ignoring  her  record and reputation as a well-performing teacher (Turque 2012).\n",
      "\n",
      "Wysocki's story is often mentioned as an illustrative example as  to  the  dangers  of  bureaucracies'  reliance  on  black-box algorithms (see O'Neal 2016). We aimed to simulate a similar scenario  in  which  officials  are  required  to  make  a  decision of whether to extend the employment contract of a teacher, when an algorithmic score indicates that she performs poorly, yet  additional  evidence  suggests  otherwise.  We  test  experimentally whether people are more inclined to adhere to such advice when produced by an algorithm, compared to a human expert, as expected by our automation bias hypothesis. We further examine (in studies 2 and 3) whether participants are more likely to follow such advice when it concerns a decision subject  from  an  ethnic  minority  background,  and  whether participants do so to a greater extent when the advice comes from  an  algorithm  (as  opposed  to  a  human  expert).  This allows us to explore instead patterns of selective (rather than automatic) adherence.\n",
      "\n",
      "We tailored our survey experimental design to the Dutch context. In the Netherlands, all schools operate under publicly funded educational associations, which enjoy a large autonomy in their management. Important decisions, including personnel management, are made by a school board, which includes representatives of the educational association. In our study, as detailed below, we invite participants to a simulation task where they act as board members of a hypothetical Dutch high-school and are asked to make decisions about the employment of three new teachers. Below we present each of the three studies and their results. In addition, the results are summarized in supplementary table A4.\n",
      "\n",
      "## Study 1: Automatic Adherence to Algorithmic Versus Human Advice (Automation Bias)\n",
      "\n",
      "Study 1 is designed to examine our hypothesis that decision-makers  are  inclined  to  over-trust  algorithmic  advice-to  follow  algorithmic  predictions  despite  additional contradicting  evidence,  and  to  do  so  to  a  greater  extent than  when  presented  with  equivalent  advice  by  a  human expert (H ). We preregistered the study and administered it 1 in February 2020. 1  The survey experiments were hosted on Qualtrics, and participants ( N = 605) were recruited through a  large  online  panel  company-Dynata. 2   The  survey  was conducted in Dutch.\n",
      "\n",
      "## Procedure\n",
      "\n",
      "Survey participants are asked to act as board members of a hypothetical  Dutch  high  school.  In  the  main  experimental task,  we  ask  participants  to  make  a  decision  regarding  the employment of three teachers, who were hired the previous year for a trial period. Only two of the three new teachers can be permanently hired and accordingly, participants must choose one teacher whose contract will not be renewed. As a  basis  for  their  decision,  participants  are  given two  data inputs per  teacher  (one  qualitative  input,  and  one  numeric input-a score) in both the algorithmic and the human advice conditions. In the algorithmic condition , respondents are\n",
      "\n",
      "1 The  preregistration  form  of  study  1  is  available  at  https://aspredicted. org/5de9d.pdf. Methodological choices are further discussed in the supplementary section A6.\n",
      "\n",
      "2 We estimated that a modest effect size of OR = 1.5 is detectable with power of 0.8 ( p = .05, one-sided test), assuming a probability of .3 for the baseline human-advice group.\n",
      "\n",
      "told the numeric input is produced by an algorithm, while for the human-expert advice condition that it is produced by a human expert.\n",
      "\n",
      "The first input, which was identical for all participants, is a brief summary of a qualitative evaluation by the HR person of the educational association. The second is a numeric prediction of the teachers' potential to perform well in the future, ranging between 1 (lowest) to 10 (highest). Participants are  told  that  this  numeric  prediction  was  conducted  by  a body named ILE (short for 'Innovatieve Lerarenevaluatie''Innovative Teachers' Evaluation'), and accordingly we refer to it as the  'ILE evaluation score'. Respondents are randomly assigned to one of two conditions: they are told that the ILE score  is  either  produced  by  a  machine  learning  algorithm ( algorithmic  advice  condition ),  or  by  consultants  ( humanexpert advice condition ). To bolster participants' confidence in the predictive capacity of the ILE score, we noted (in both conditions) that it 'has proven highly effective in predicting teacher performance, with an accuracy rate of 95%.'\n",
      "\n",
      "It is noteworthy that the format we used for the ILE evaluation  score  (an  integer  between  1  and  10)  was  designed to resemble the COMPAS risk score that is used in pretrial procedures across the United States, which similarly ranges from 1 to 10. The comparison between a numeric algorithmic prediction and additional qualitative evidence (e.g., case file evidence presented to a judge) is typical for many policy areas where algorithms are used as decisional aids.\n",
      "\n",
      "characteristics of the three teachers, which could potentially affect  participants'  decisions,  all  three  teachers  are  female, have typical Dutch names and their teaching areas are in natural sciences. The order of the three teachers was randomized (see also supplementary section A5.4).\n",
      "\n",
      "In line with our theoretical focus, we deliberately designed the task so that there will be an incongruence between the two  inputs  in  the  table:  the  lowest  ILE  score  (4)  is  never matched with the most negative qualitative HR evaluation. The incongruence was as follows: One of the three teachers received a low ILE score of 4, whereas the other two received scores of 8 and 6. The HR person's qualitative evaluation similarly varies as one of the three teachers gets negative remarks, whereas the other two teachers receive positive and respectively, mixed evaluations. Most importantly however, the negative qualitative evaluation is never assigned to the teacher with the lowest ILE score (4), but to one of the other teachers. Instead, the teacher with the lowest ILE score receives either the positive or the mixed qualitative evaluation. Accordingly, participants faced a decision of whether or not to follow the ILE score (i.e., to fire the teacher with the most negative ILE score), given its incongruence with the HR person's qualitative evaluation.\n",
      "\n",
      "Participants  were  shown  a  table  that  presents  the  three teachers  and  the  two  inputs  for  each  teacher,  as  illustrated in figure 1. To minimize additional differences in the\n",
      "\n",
      "For exploratory purposes, we also randomized the distribution of the ILE scores (4, 6, and 8) across the three teachers, to  generate  different  levels  of  incongruence  between  the  ILE score and the qualitative evaluation. We assigned participants to one of two main conditions of incongruence. In the high incongruence condition (displayed in figure 1), the teacher with the  lowest  ILE  score  receives  the  most  favorable  qualitative\n",
      "\n",
      "<!-- image -->\n",
      "\n",
      "Whose contract would you recommend not to renew? To reiterate, you are requested to choose teacher.\n",
      "\n",
      "evaluation. In the modest incongruence condition, the teacher with the lowest ILE score receives the mixed qualitative evaluation. In other words, through the qualitative input (the HR evaluation), respondents in both conditions receive informational cues that are at odds, to varying degrees, with the ILE score.\n",
      "\n",
      "Our main outcome variable is  participants'  likelihood  to follow the ILE score. We coded 1 when participants chose to fire the teacher with the lowest ILE score and 0 otherwise. In our analyses below, we compare this binary variable between the two conditions (algorithmic versus human-expert).\n",
      "\n",
      "The main task was followed by a series of manipulation check  questions  to  confirm  that  participants  were  aware of  the  source  of  advice  (algorithmic  versus  human)  as  well as  of  the  actual  ILE  score  (supplementary  section A3). The survey further included an attention check, additional items regarding participants' perceptions of algorithms and their familiarity with the use of algorithms by public bodies and a set of demographic questions. The full survey is attached in the supplementary sections A8 and A9.\n",
      "\n",
      "We excluded  from  all  analyses  participants  who  did  not pass  the  attention  check  or  completed  the  questionnaire under  3  minutes. These  filtering  criteria  are  not  associated with  the  assignment  to  the  experimental  conditions  (supplementary  table  A2.1).  The  two  experimental  groups  are balanced in relation to gender, reported income and education,  yet  participants  assigned  to  the  algorithmic  group  are slightly older on average (supplementary table A1.1). In robust analyses, we further control for these covariates (supplementary table A5.1.1). While this sample consists of Dutch citizens, their average age (47) and the share of participants with high education (50%) are comparable to that of the population of Dutch civil servants. Compared with civil servants, our sample over-represents women, and people aged less than 25 or above 65 (Appendix 2). In our analyses below, we control for these variables and confirm that these characteristics do not affect our results.\n",
      "\n",
      "A  technical  clarification  on  our  statistical  reporting:  in all  results  tables  presented  in  the  article  we  use  two-tailed p values  uniformly,  for  consistency. We  additionally  report, for our preregistered directional hypotheses, the one-sided p values, both in the tables and in the main text when discussing the effects.\n",
      "\n",
      "## Results (Study 1)\n",
      "\n",
      "Tables  1  and  2  present  the  main  experimental  results  of study 1. Table 1 reports the results of the logistic regression analysis as to the effect of our manipulation of the type of advice (algorithmic versus human) and Table 2 presents descriptively  the  distribution  of  participants'  decisions  across the two conditions. Based on our first hypothesis, and in line with automation bias literature, we expected the probability of following the advice of the ILE score (i.e., selecting not to renew the contract of the teacher with the lowest ILE score) to be higher among those assigned to the AI algorithmic advice,  compared  to  those  receiving  an  equivalent  prediction produced by human experts.\n",
      "\n",
      "In contrast to our theoretical expectation, we find very small, statistically insignificant differences between the algorithmicadvice  and  human-advice  conditions  (table  1).  Under  both conditions,  the  vast  majority  of  participants  chose  to  override  the  ILE  score  and  instead  preferred  to  fire  (not  renew) the teacher with the poorest qualitative evaluation (table 2).\n",
      "\n",
      "Table 1. Study 1-Regression Results of Participants' Adherence to Algorithmic Versus Human-Expert Advice (Automation Bias)\n",
      "\n",
      "| Predictors     | (1)              |        |         |\n",
      "|----------------|------------------|--------|---------|\n",
      "|                | OR [95% CI]      | z      | p value |\n",
      "| Algorithm      | 0.96 [0.58-1.58] | -0.16  | .876    |\n",
      "| Intercept      | 0.14 [0.09-0.19] | -11.41 | <.001   |\n",
      "| Observations   | 605              |        |         |\n",
      "| Log-likelihood | -218.769         |        |         |\n",
      "\n",
      "Note : Logistic regression model; OR , odds ratio; p values refer to a twosided test (by default). Binary outcome: following the ILE score (1 = non-renewal of employment of teacher with lowest ILE score).\n",
      "\n",
      "Table 2. Study 1-Descriptive Results (Automation Bias)\n",
      "\n",
      "| Outcome: Teacher Selected (Non-renewal of employment)     |   Algorithmic Advice ( n = 295), % |   Human-Expert Advice ( n = 310), % |\n",
      "|-----------------------------------------------------------|------------------------------------|-------------------------------------|\n",
      "| Teacher with lowest ILE score (algorithmic/ human-expert) |                               11.5 |                                11.9 |\n",
      "| Teacher with poorest qualitative evaluation               |                               77.3 |                                81   |\n",
      "| Other                                                     |                               11.2 |                                 7.1 |\n",
      "\n",
      "Including covariates and restricting the samples to those who successfully  completed  the  manipulation  checks  does  not change the results (supplementary tables A5.1.1 and A5.2.1).\n",
      "\n",
      "Furthermore, these patterns are similar regardless of whether  the  lowest  ILE  score  was  assigned  to  the  teacher with the best qualitative evaluation (high incongruence condition) or the teacher with the mixed qualitative evaluation (modest  incongruence  condition)-providing  further  confidence  that  the  diagnosed  patterns  are  stable  (supplementary section A5.3). Also, randomizing the order of the three teachers did not significantly alter the results (supplementary section A5.4).\n",
      "\n",
      "In summary, in study 1, we did not find evidence supporting the automation bias expectation. The majority of participants, under both algorithmic and human advice conditions, and across the conditions of incongruence, chose to override the ILE score.\n",
      "\n",
      "## Study 2: Selective Adherence to Algorithmic Versus Human Advice Matching Stereotypes\n",
      "\n",
      "The purpose of study  2  is  two-fold:  First,  it  aims  to  replicate the results of study 1 on a separate sample. Second, it is also designed to test the additional hypotheses that, similar to human advice, decision-makers are more inclined to follow algorithmic advice inasmuch as this is aligned with stereotypical views of the decision subjects (H ), and that this selective 2 adherence pattern is exacerbated by AI algorithms compared with equivalent human expert advice (H ). We preregistered 3 the study and administered it mid-March 2020, and similarly recruited participants through Dynata ( N = 904). 3\n",
      "\n",
      "3 The preregistration forms of study 2 is available at https://aspredicted.org/ v3u29.pdf. Methodological choices are further discussed in the supplementary section A6.\n",
      "\n",
      "## Procedure\n",
      "\n",
      "We repeated the procedure of study 1, while adding a manipulation of teachers' names as a cue for their ethnic background. The control condition is identical to study 1-all three teachers are given typical Dutch surnames ('Verhagen,' 'Jansen,' and 'den  Heijer').  In  the  treatment  condition,  the  name  of  the teacher who received the lowest ILE score (4) is changed to 'El Amrani,' a common surname for citizens with a Moroccan background. We henceforth refer to these conditions as 'Dutch teacher' and  'Moroccan-Dutch teacher.' We  specifically selected this ethnic minority group in the Netherlands, since it is a minority group that is often negatively stereotyped (Jilke, Van Dooren, and Rys 2018; Kamans et al. 2009). Identical to study 1, we randomized the level of incongruence between the ILE score and the qualitative evaluation. 4\n",
      "\n",
      "Based on our theory, we expect that participants will be more inclined to fire the teacher with the lowest ILE score when that teacher has a Moroccan-sounding name (H ). Our 2 sample testing the selective adherence hypotheses were therefore filtered to include only respondents of Dutch descent ( n = 792). 5 In our analyses below, we examine the effect of this manipulation on participants' inclination to follow the ILE score, and its interaction with the type of advice (algorithmic versus human, H ). 3\n",
      "\n",
      "It  is  important  to  note  that  previous  vignette  survey experimental  studies  have  frequently  failed  to  identify discriminatory patterns, which has been explained by methodological  reasons,  mainly  social  desirability  pressures and  the  difficulty  of  simulating  the  conditions  of  realworld  decision  making  (Wulff  and  Villadsen  2020).  We were certainly aware of this limitation when designing our study, and for this reason we argue that our study can be considered as a particularly hard case for our selective adherence hypothesis.\n",
      "\n",
      "Similar  to  study  1,  we  excluded  from  all  the  analyses participants who did not pass the attention check or completed the questionnaire in less than 3 minutes. These filtering criteria are  not  associated  with  the  assignment  to  the  experimental conditions (supplementary table A2.2). After this filtering, we were left with an analytical sample of N = 904 for the replication of study 1 (automation bias hypothesis) and N = 792 for testing of our selective adherence hypotheses, that is, H  and 2 H3 , the teacher ethnicity manipulation. The advice groups and teacher names' groups are balanced in relation to gender, reported income, education, and age (supplementary table A1.2).\n",
      "\n",
      "## Results (Study 2) Automation Bias\n",
      "\n",
      "The results of study 2 with regards to the automation bias hypothesis are displayed in tables 3 and 4. Consistent with our study 1 findings, we find small, statistically insignificant differences  between  algorithmic-advice  and  human-advice conditions.  Including  covariates  and  restricting  the  samples to those who successfully completed the manipulation checks does not change the results (supplementary tables A5.1.1 and A5.2.1).\n",
      "\n",
      "Also, there were no major differences across the randomized  incongruence versions. In both cases, the\n",
      "\n",
      "4 In study 2, we did not randomize the order of the three teachers, based on the results of study 1.\n",
      "\n",
      "5 We assume negative stereotypes toward citizens of migrant descent to be more emphasized among citizens without a migration background.\n",
      "\n",
      "differences  are  in  the  expected  direction,  yet  they  are  relatively  small  and  statistically  insignificant  (supplementary tables A5.3.2 and A5.3.4).\n",
      "\n",
      "Thus,  in  both  studies  1  and  2,  we  did  not  find  that participants are more likely to follow the algorithmic advice compared with equivalent human advice. We also pooled the two samples to maximize statistical power ( N = 1,509), and the differences, while in the expected direction (11.1% versus 10.5%), were still statistically insignificant ( OR =  1.07, z = 0.41, tables 3 and 4). 6  We do not find support for automation bias. We further ruled out that potential differences in demographic and socioeconomic characteristics between our sample  and  the  civil  service  population  might  impact  our experimental  results  via  interaction  models  (supplementary table A5.5.1). We also examined whether participants' propensity to follow the algorithmic advice is influenced by their familiarity with the use of algorithms by public organizations. 21% of the participants assigned to the algorithmic advice in the two studies reported that they were familiar with algorithm use by public bodies. This variable too had an insignificant effect (supplementary table A5.6.1).\n",
      "\n",
      "## Selective Adherence\n",
      "\n",
      "We now turn to discuss the results of our second study in relation to our hypotheses of selective adherence . Table 5 reports the  regression  results  of  the  comparison  between  the  two teacher ethnicity conditions, across the algorithm and human advice. In Model 1, we regressed our outcome variable on the two manipulations to test their main effects, and thereafter in Model 2 we add their interaction. Table 6 then summarizes the descriptive differences in raw scores.\n",
      "\n",
      "We find a main effect for the teacher ethnicity manipulation in the expected direction. Respondents are more likely to adhere to an advice when it predicts low performance for a  decision  subject  from  a  negatively  stereotyped  minority. A  Moroccan-Dutch  teacher  with  a  low  ILE  score  is  50% more likely not to  have  their  contract  renewed,  compared to a Dutch teacher with the same score ( OR = 1.50, p = .04, one-sided test). Descriptively, the difference in probabilities is 12.3% versus 8.6%. In other words, in line with our H , we 2 find selective adherence across both types of advice : human and  algorithmic.  This  effect  remains  positive  and  significant  when  controlling  for  covariates  (supplementary  table A5.1.2). 7 Given  established  difficulties  for  survey  experimental designs to identify such discriminatory patterns, these findings are important and likely speak to the prevalence of such biases.\n",
      "\n",
      "This  pattern  is  consistent  across  our  two  incongruence conditions (supplementary tables A5.3.3 and A5.3.5), which further  speaks  to  its  robustness.  We  also  examined  the  interaction  between  the  teacher  ethnicity  manipulation  and participants' age, gender, level of education, and reported income. All these interactions are statistically insignificant (supplementary table A5.5.2).\n",
      "\n",
      "6 For  this  sample  size  and  baseline  probability,  we  estimate  that  a  small effect-size of OR = 1.45 (a probability change of approximately 5%) is detectable (power = 0.8, p = .05, one-sided test). For post hoc power analyses, see supplementary section A7.\n",
      "\n",
      "7 Consistently,  the  coefficient  is  positive  in  supplementary  analyses  after filtering out those who did not properly read the task ( OR =  1.39, 9.5% versus 7%), yet it is not sufficiently significant, arguably due to the smaller sample size (supplementary table A5.2.2).\n",
      "\n",
      "Table 3. Study 2-Regression Results of Participants' Adherence to Algorithmic Versus Human-Expert Advice (Automation Bias)\n",
      "\n",
      "| Predictors               | Study 2 (1)      | Study 2 (1)   | Study 2 (1)   | Studies 1 and 2 (pooled) (2)   | Studies 1 and 2 (pooled) (2)   | Studies 1 and 2 (pooled) (2)   |\n",
      "|--------------------------|------------------|---------------|---------------|--------------------------------|--------------------------------|--------------------------------|\n",
      "|                          | OR [95% CI]      | z             | p value       | OR [95% CI]                    | z                              | p value                        |\n",
      "| Algorithm                | 1.16 [0.75-1.80] | 0.68          | .498          | 1.07 [0.77-1.48]               | 0.41                           | .683                           |\n",
      "| Study 2 (ref. = study 1) |                  |               |               | 0.85 [0.61-1.18]               | -0.96                          | .335                           |\n",
      "| Intercept                | 0.10 [0.08-0.14] | -13.91        | <.001         | 0.13 [0.09-0.17]               | -13.57                         | <.001                          |\n",
      "| Observations             | 904              |               |               | 1,509                          |                                |                                |\n",
      "| Log-likelihood           | -297.144         |               |               | -516.073                       |                                |                                |\n",
      "\n",
      "Note: Binary outcome: following the ILE score (1 = non-renewal of employment of teacher with lowest ILE score).\n",
      "\n",
      "Table 4. Study 2-Descriptive Results (Automation Bias)\n",
      "\n",
      "| Outcome: Teacher Selected (Non-renewal of employment)    | Study 2 ( N = 904)               | Study 2 ( N = 904)                | Studies 1 and 2 (pooled) ( N = 1,509)   | Studies 1 and 2 (pooled) ( N = 1,509)   |\n",
      "|----------------------------------------------------------|----------------------------------|-----------------------------------|-----------------------------------------|-----------------------------------------|\n",
      "| Outcome: Teacher Selected (Non-renewal of employment)    | Algorithmic Advice ( n = 461), % | Human-Expert Advice ( n = 443), % | Algorithmic Advice ( n = 756), %        | Human-Expert Advice ( n = 753), %       |\n",
      "| Teacher with lowest ILE score (algorithmic/human-expert) | 10.8                             | 9.5                               | 11.1                                    | 10.5                                    |\n",
      "| Teacher with poorest qualitative evaluation              | 81.6                             | 83.3                              | 79.9                                    | 82.3                                    |\n",
      "| Other                                                    | 7.6                              | 7.2                               | 9.0                                     | 7.2                                     |\n",
      "\n",
      "Next,  we  examine  the  interaction  effect,  in  line  with our H . While we find statistically  significant  evidence  that 3 participants are more inclined to follow the ILE score when the prediction is aligned with stereotypes, our findings do not suggest that this bias is increased when the score is produced by  an  algorithm  compared  to  human  advice,  in  contrast with our H . Participants under both conditions were more 3 likely not to renew the contract of the teacher of Moroccan background,  and  the  interaction  between  the  teacher  ethnicity manipulation and the algorithmic advice condition is not  statistically  significant  in  our  interaction  model  (table 5,  model  2).  The  differences  between  the  Moroccan-Dutch and Dutch teachers in the human-expert advice group were slightly  greater  compared  with  the  algorithmic  group,  yet these descriptive differences are not statistically significant, as evidenced by the insignificant interaction term (| z |  = 1.45, p = .147), 8 and as such could be entirely due to chance (type I error). The coefficient of the interaction further diminishes when we control for  covariates  (| z |  =  1.25, p =  .210),  and restricting the samples to those who successfully completed the manipulation checks does not change the results (supplementary tables A5.1.2 and A5.2.2).\n",
      "\n",
      "On this basis, given the significant main effect and insignificant interaction, our findings indicate that decision-makers are subject to selective adherence when processing decisional aid outputs, regardless of whether these outputs are produced by humans or algorithms. At the same time, and despite our considerable sample size, we acknowledge statistical power limitations in our interaction analysis (H ). 9 3 Still, we can infer with  sufficient  confidence  that  a  significant  increase  (as  we\n",
      "\n",
      "8 A similar result is produced by a likelihood ratio comparing the interaction model with a main-effect-only model ( χ 2 (1) = 2.141, p = .143). Comparing the two models via BIC and AIC indicates that the main effect model is more appropriate (Lorah 2020).\n",
      "\n",
      "hypothesized) is unlikely due to the fact that the interaction coefficient is in the opposite direction.\n",
      "\n",
      "To summarize our main findings in study 2, we find that participants,  across  both  sources  of  advice  (human  and  algorithmic), tend to follow the advice in a selective manner -when it  corresponds  to  pre-existing  biases  and  stereotypes, which translates into group disparities (in support of our H ). 2 All else constant, a Moroccan-Dutch teacher is significantly more likely  to  get  sanctioned  due  to  a  negative  evaluation score compared to a Dutch teacher with the same score. Our findings indicate that there are no significant differences between human and algorithmic advice in this respect. Selective biased processing patterns are found for both types of advice, persisting in algorithm adoption.\n",
      "\n",
      "## Study 3: Replication with a Sample of Civil Servants\n",
      "\n",
      "In  study  3,  we  aimed  to  replicate  studies  1  and  2  with  a sample  of  civil  servants.  For  this  purpose,  we  contracted a government-owned personnel research program (Internetspiegel/ICTU)  operating  an  online  panel  of  Dutch civil servants  (Flitspanel/'Flashpanel').  Participating  civil servants  register  themselves  for  their  participation  in  the panel, and it is used both by the government itself to survey current policy issues as well as for academic studies. 10\n",
      "\n",
      "The  online  survey  was  administered  and  distributed  by ICTU to 3,294 civil servants. The fieldwork was conducted between the 2nd and 22nd of February 2021. ICTU sent the invitations  to  the  participants  via  email,  followed  by  two reminders. A total number of 1,345 participants completed\n",
      "\n",
      "10 For additional information, see https://flitspanel.nl.\n",
      "\n",
      "11 Assuming the baseline probability we found in studies 1 and 2, we estimate this sample size is sufficient for detecting a modest effect-size of OR = 1.52.\n",
      "\n",
      "Table 5. Regression Results of Study 2-Participants' Selective Adherence to Advice (Algorithmic Versus Human-Expert) that Matches Stereotypical View of Decision Subjects\n",
      "\n",
      "| Predictors                         | (1)              | (1)    | (1)                    | (2)              | (2)   | (2)     |\n",
      "|------------------------------------|------------------|--------|------------------------|------------------|-------|---------|\n",
      "|                                    | OR [95% CI]      | z      | p value                | OR [95% CI]      | z     | p value |\n",
      "| Algorithm                          | 1.20 [0.76-1.91] | 0.78   | .438                   | 1.80 [0.88-3.83] | 1.58  | .114    |\n",
      "| Moroccan-Dutch teacher             | 1.50 [0.95-2.40] | 1.73   | .083 (.042 one-sided ) | 2.23 [1.11-4.73] | 2.19  | 0.029   |\n",
      "| Algorithm × Moroccan-Dutch teacher |                  |        |                        | 0.50 [0.19-1.27] | -1.45 | .147    |\n",
      "| Intercept                          | 0.08 [0.05-0.13] | -11.16 | <.001                  | 0.07 [0.03-0.11] | -9.10 | <.001   |\n",
      "| Observations                       | 792              |        |                        | 792              |       |         |\n",
      "| Log-likelihood                     | -261.789         |        |                        | -260.719         |       |         |\n",
      "| BIC                                | 543.602          |        |                        | 548.136          |       |         |\n",
      "| AIC                                | 529.579          |        |                        | 529.438          |       |         |\n",
      "\n",
      "Note: Binary outcome: following the ILE score (1 = non-renewal of employment of teacher with lowest ILE score).\n",
      "\n",
      "Table 6. Study 2-Descriptive Results (Selective Adherence)\n",
      "\n",
      "| Outcome: Teacher Selected (Non-renewal of employment)    | All ( n = 792) Teacher with lowest ILE score:   | All ( n = 792) Teacher with lowest ILE score:   | Algorithmic Advice ( n = 405) Teacher with lowest ILE score:   | Algorithmic Advice ( n = 405) Teacher with lowest ILE score:   | Human-Expert Advice ( n = 387) Teacher with lowest ILE score:   | Human-Expert Advice ( n = 387) Teacher with lowest ILE score:   |\n",
      "|----------------------------------------------------------|-------------------------------------------------|-------------------------------------------------|----------------------------------------------------------------|----------------------------------------------------------------|-----------------------------------------------------------------|-----------------------------------------------------------------|\n",
      "| Outcome: Teacher Selected (Non-renewal of employment)    | Dutch n = 409), %                               | Moroccan-Dutch ( n = 383), %                    | Dutch ( n = 216), %                                            | Moroccan-Dutch ( n = 189), %                                   | Dutch ( n = 193), %                                             | Moroccan-Dutch ( n = 194), %                                    |\n",
      "| Teacher with lowest ILE score (algorithmic/human-expert) | 8.6                                             | 12.3                                            | 10.6                                                           | 11.6                                                           | 6.2                                                             | 12.9                                                            |\n",
      "| Teacher with poorest qualitative evaluation              | 84.1                                            | 79.9                                            | 82.4                                                           | 78.8                                                           | 86.0                                                            | 80.9                                                            |\n",
      "| Other                                                    | 7.3                                             | 7.8                                             | 6.9                                                            | 9.5                                                            | 7.8                                                             | 6.2                                                             |\n",
      "\n",
      "the survey (41% response rate). 11  The sample includes civil servants working in different policy sectors, at both national and local levels. 12 Yet, it should be noted that the sample is not entirely representative of the Dutch public sector. Women are underrepresented in our sample, and the mean age was higher compared with the Dutch public sector. In Appendix 2, we present the demographic characteristics of the sample and control for these characteristics in our robust analyses, as detailed below.\n",
      "\n",
      "balanced in relation to gender, reported income, education, and age (supplementary table A1.3).\n",
      "\n",
      "We repeated the 2 × 2 factorial design and the experimental procedure  of  study  2.  The  online  survey  was  administered by ICTU (using a different software than Qualtrics), and for technical  reasons  we  could  not  include  the  additional  randomization  into  high  and  modest  incongruence.  Hence,  in this study, we assigned all participants to the high incongruence scenario, where the teacher who receives the lowest ILE score is the one with the most positive qualitative evaluation. We did not include an attention check in this survey, as per the panel's request, and therefore our analytical sample for the  automation  bias  hypothesis  is  the  full  sample  of  1,345 participants. 13 For the analyses of the teacher's ethnicity manipulation, same as in study 2, we included only participants of Dutch descent ( N =  1,203). This screening is not associated with the assignment to the experimental conditions (supplementary  table A2.3),  and  the  randomization  groups  are\n",
      "\n",
      "12 The survey was sent to participants from the following sectors: central government (national ministries), municipalities, provinces, inter-municipal cooperative arrangements, water boards, defense, and police.\n",
      "\n",
      "13 All participants completed the survey in more than 3 minutes.\n",
      "\n",
      "It is important to note that the fieldwork of study 3 coincided with  the  occurrence  of  significant  events  in  the  Netherlands, surrounding the 'childcare benefits scandal' ( toeslagenaffaire in  Dutch).  The  scandal  reached  its  peak  during  the  technical  preparations  of  our  survey,  and  shortly  before  its  distribution  with  growing  public  attention  in  December  2020, following  the  publication  of  a  parliamentary  report  on  the scandal (titled 'Unprecedented Injustice,' Parlementaire Ondervragingscommissie Kinderopvangtoeslag 2020), resulting in the resignation of the Dutch government mid-January 2021.\n",
      "\n",
      "The  scandal  involved  the  reliance  by  the  Dutch  tax authorities on an AI algorithm-a 'learning algorithm' that used,  among  other  criteria,  nationality  as  a  discriminant predictive feature, and served as a decisional aid in flagging high-risk applicants for further scrutiny. The requests flagged by the algorithm were checked manually by tax employees after  considering  (and/or  requesting  from applicants) additional information (Autoriteit Persoonsgegevens/Dutch Data Protection Authority 2020). The scandal disproportionately affected  citizens  of  foreign  descent,  with  mostly  dual  nationality  families  wrongly  accused of benefits fraud: '[T]he tax ministry singled out tens of thousands of families often on  the  basis  of  their  ethnic  background'  (Financial  Times 2021). Victims of the scandal were required to retroactively repay large sums of money (amounting to as much as tens of  thousands  of  euros),  with  the  financial  strain  reportedly resulting  in  acute  financial  problems,  bankruptcies,  mental health issues, and broken families (Geiger 2021).\n",
      "\n",
      "The scandal is a textbook example of the meeting point between  algorithmic bias and human  decision-makers' biases.  While  the  system  itself  was  biased,  using  nationality  as  a  predictive  feature,  the  way  tax  officials  went about their work reinforced the system's biases: 'Both the automated  risk  selection  and  the  individual  investigations of  officials  were  discriminatory,  the  data  protection  authority  ruled'  (Volkskrant  2020).  The  scandal  is  illustrative  of  the  patterns  diagnosed  in  our  study  2:  algorithmic recommendations  aligned  with  prevalent  stereotypes  (i.e., indicating a negative assessment for members of an ethnic minority group) with decision-makers likely not to override such  recommendations. Victims  of  the  scandal,  much  like our teacher of Moroccan heritage in study 2, were specifically singled out for targeted scrutiny because of their ethnic origin or double nationality, following an algorithmic prediction ('families of largely Moroccan, Turkish and Dutch Antilles origin were targeted, according to the national data protection authority,' Financial Times 2021).\n",
      "\n",
      "Given  that  the  survey  was  conducted  shortly  after  the scandal, the results of this study should be interpreted in light of it. Our participants were highly aware of the risk of algorithmic bias, and sensitive to this issue. 63% of the participants reported  that  they  are  familiar  with  the  use  of  algorithms by public organizations, and more than half of these (33%) mentioned  this  case  when  asked  to  give  an  example,  and many  of  them  spontaneously  expressed  their  criticism  toward  it  in  their  qualitative  answers.  While  we  anticipated such public reactions to be reflected in participants' answers, we decided not to withhold the fieldwork, as we believe that investigating  our  research  question  under  these  conditions can yield meaningful insights. We return to this point below in our discussion.\n",
      "\n",
      "## Results-Study 3 Automation Bias\n",
      "\n",
      "The logistic regression results of study 3 with regards to the comparison between algorithmic and human advice (automation bias hypothesis) are displayed in table 7, with descriptive differences  presented  in  table  8.  Participants  were  significantly less likely to follow the ILE score when produced by an algorithm, and more likely to select the teacher with the poorest qualitative evaluation. This confirms the findings of our previous two studies, which similarly did not diagnose automation bias in decision making. In fact, the patterns in study 3 are in the opposite direction to the automation bias expectations. Including covariates and restricting the sample to those who successfully completed the manipulation checks does not change the results (supplementary tables A5.1.1 and A5.2.1).\n",
      "\n",
      "Also,  the  interactions  between  the  advice  manipulation and participants' gender, age and higher education are all statistically insignificant (supplementary table A5.5.3). This suggests that a sample more representative of the civil service's  demographic  and  socioeconomic  characteristics would  have  yielded  similar  results.  However,  in  contrast with studies 1 and 2, the negative effect of the algorithmic advice  is  linked  to  respondents'  reported  familiarity  with the use of algorithms  by  public organizations.  When filtering our sample in study 3 to participants who were not familiar with the use of algorithms by public organizations\n",
      "\n",
      "Table 7 . Study 3-Regression Results of Participants' Adherence to Algorithmic Versus Human-Expert Advice (Automation Bias)\n",
      "\n",
      "| Predictors     | (1)              |        |         |\n",
      "|----------------|------------------|--------|---------|\n",
      "|                | OR [95% CI]      | z      | p value |\n",
      "| Algorithm      | 0.54 [0.34-0.83] | -2.74  | .006    |\n",
      "| Intercept      | 0.09 [0.07-0.12] | -17.32 | <.001   |\n",
      "| Observations   | 1345             |        |         |\n",
      "| Log-likelihood | -329.022         |        |         |\n",
      "\n",
      "Note: Binary outcome: following the ILE score (1 = non-renewal of employment of teacher with lowest ILE score).\n",
      "\n",
      "Table 8. Study 3-Descriptive Results (Automation Bias)\n",
      "\n",
      "| Outcome: Teacher Selected (Non-renewal of employment)    |   Algorithmic Advice ( n = 662), % |   HumanAdvice ( n = 683), % |\n",
      "|----------------------------------------------------------|------------------------------------|-----------------------------|\n",
      "| Teacher with lowest ILE score (algorithmic/human-expert) |                                4.8 |                         8.6 |\n",
      "| Teacher with poorest qualitative evaluation              |                               89.1 |                        83.9 |\n",
      "| Other                                                    |                                6   |                         7.5 |\n",
      "\n",
      "before the survey ( n = 498), the likelihood of following the algorithmic advice increases and is not significantly lower compared  to  the  human-expert  condition  (6.9%  versus 8.8%, p = .431, two-sided). We return to this point later in our discussion.\n",
      "\n",
      "## Selective Adherence\n",
      "\n",
      "Tables  9  and  10  present  the  results  of  the  comparison  between the teacher ethnicity conditions, across the algorithm and  human  advice,  which  is  relevant  to  our  selective  adherence  hypotheses. We  find  a  negative  main  effect  for  the Moroccan-Dutch  teacher  (table  9).  In  departure  from  our study 2, participants in study 3 (civil servants in the aftermath of a major public scandal involving algorithm use and ethnic discrimination)  were  less  likely  to  fire  a  Moroccan-Dutch teacher with a low ILE score, compared to a Dutch teacher with the same score. These differences are fairly similar across the  two  groups,  and  the  interaction  is  insignificant.  These results do not change when adding controls and filtering out those who did not properly read the task (supplementary tables A5.1.3 and A5.2.3).\n",
      "\n",
      "To summarize the main results, in this study with a sample of civil servants, similar to our previous two studies, we do not find support for automation bias. Our study 3 reveals participants in the aftermath of the scandal were less likely to  be  influenced  in  their  decision  by  the  ILE  score  when generated by an AI algorithm rather than by human experts. Also, and in contrast with our study 2, they were less likely to sanction the Moroccan-Dutch teacher, regardless of the type of advice. These findings arguably speak to the effect of the scandal in shaping bureaucratic responses, as we discuss below.\n",
      "\n",
      "Table 9. Regression Results of Study 3-Participants' Selective Adherence to Advice (Algorithmic Versus Human-Expert) that Matches Stereotypical View of Decision Subjects\n",
      "\n",
      "| Predictors                         | (1)              | (1)    | (1)     | (2)              | (2)    | (2)     |\n",
      "|------------------------------------|------------------|--------|---------|------------------|--------|---------|\n",
      "|                                    | OR [95% CI]      | z      | p value | OR [95% CI]      | z      | p value |\n",
      "| Algorithm                          | 0.46 [0.28-0.74] | -3.12  | .002    | 0.53 [0.28-0.95] | -2.08  | .038    |\n",
      "| Moroccan-Dutch teacher             | 0.57 [0.35-0.91] | -2.33  | .020    | 0.64 [0.36-1.13] | -1.52  | .129    |\n",
      "| Algorithm × Moroccan-Dutch teacher |                  |        |         | 0.69 [0.24-1.89] | -0.71  | .480    |\n",
      "| Intercept                          | 0.13 [0.09-0.17] | -12.13 | <.001   | 0.12 [0.08-0.17] | -11.36 | <.001   |\n",
      "| Observations                       | 1,203            |        |         | 1,203            |        |         |\n",
      "| Log-likelihood                     | -286.297         |        |         | -286.044         |        |         |\n",
      "| BIC                                | 593.872          |        |         | 600.458          |        |         |\n",
      "| AIC                                | 578.594          |        |         | 580.087          |        |         |\n",
      "\n",
      "Note: Binary outcome: following the ILE score (1 = non-renewal of employment of teacher with lowest ILE score).\n",
      "\n",
      "Table 10. Study 3-Descriptive Results (Selective Adherence)\n",
      "\n",
      "| Outcome: Teacher Selected (Non-renewal of employment)    | All ( n = 1,203) Teacher with lowest ILE score:   | All ( n = 1,203) Teacher with lowest ILE score:   | Algorithmic Advice ( n = 595) Teacher with lowest ILE score:   | Algorithmic Advice ( n = 595) Teacher with lowest ILE score:   | Human-Expert Advice ( n = 608) Teacher with lowest ILE score:   | Human-Expert Advice ( n = 608) Teacher with lowest ILE score:   |\n",
      "|----------------------------------------------------------|---------------------------------------------------|---------------------------------------------------|----------------------------------------------------------------|----------------------------------------------------------------|-----------------------------------------------------------------|-----------------------------------------------------------------|\n",
      "|                                                          | Dutch ( n = 603), %                               | Moroccan-Dutch ( n = 600), %                      | Dutch ( n = 303), %                                            | Moroccan-Dutch ( n = 292), %                                   | Dutch ( n = 300), %                                             | Moroccan-Dutch ( n = 308), %                                    |\n",
      "| Teacher with lowest ILE score (algorithmic/human-expert) | 8.3                                               | 5.0                                               | 5.9                                                            | 2.7                                                            | 10.7                                                            | 7.1                                                             |\n",
      "| Teacher with poorest qualitative evaluation              | 83.6                                              | 89.2                                              | 86.8                                                           | 92.5                                                           | 80.3                                                            | 86.0                                                            |\n",
      "| Other                                                    | 8.1                                               | 5.8                                               | 7.3                                                            | 4.8                                                            | 9.0                                                             | 6.8                                                             |\n",
      "\n",
      "## Discussion and Conclusion\n",
      "\n",
      "With AI set to fundamentally alter decision making in public organizations, how  do  human  decision-makers actually process algorithmic advice? Drawing on two separate strands of behavioral literature, we have theorized that two biases in particular are of high relevance and in dire need of investigation by public administration scholars: 'automation bias' and 'selective adherence' to algorithmic advice.\n",
      "\n",
      "advice. Across the three studies, we consistently did not find evidence for an overall tendency for automation bias.\n",
      "\n",
      "A  first  bias  stemming  from  automation  studies  is  that decision-makers  would  automatically  default  to  the  algorithm,  potentially  then  also  to  poor  algorithmic  advice, ignoring contradictory cues from other sources: automation bias .  A  second  hypothesized  bias,  which  we  extrapolated from public administration literature, regards decisionmakers' tendency to defer to the algorithm selectively-when algorithmic  predictions  match  pre-existing  stereotypes: selective adherence . The use of algorithms could then disproportionately negatively affect stereotyped groups, potentially creating administrative burdens (Herd and Moynihan 2019) and compounding discrimination. Below we discuss and reflect, in turn, on our findings in relation to each of these biases and their implications for public sector decision making in the age of automation.\n",
      "\n",
      "## Automation Bias\n",
      "\n",
      "Overall, our experimental findings from three separate studies with an aggregated sample of 2,854 participants do not reveal a general pattern of automatic adherence to algorithmic\n",
      "\n",
      "In none  of  the  three  studies were  participants  more likely  to  follow  the  ILE  score  when  produced  by  an  algorithm compared to a human-expert: in studies 1 and 2, the differences  were  small  and  statistically  insignificant,  and  in study 3 conducted shortly after the childcare benefits scandal, participants  were  actually  less  likely  to  follow  the  algorithmic  advice,  indicative  of  a  growing  reluctance  to  trust algorithms in its aftermath. We attribute this latter negative effect primarily to the proximity of the study to the scandal, increasing participants'  exposure to the dangers of reliance on AI algorithmic models (as exemplified by the scandal). A considerable number of respondents in study 3 (33%) were aware  of  the  use  of  algorithms  in  the  benefits  scandal,  as evidenced by their  open  answers.  Furthermore,  as  reported above, among those respondents who were not aware of the use of algorithms by public organizations we did not find a lower propensity to follow the algorithmic advice compared to human advice. This suggests the results of study 3 represent a response to the scandal rather than indicative of an inherent distrust toward algorithmic-sourced advice. At the same time, our study should also serve as further caution as to the adoption  of  unvetted,  under-performing  algorithmic  systems  in public sector decision making, increasingly diagnosed in practice (e.g., Ferguson 2017; Eubanks 2018; O'Neil 2016), and as exemplified in our article by the Dutch childcare benefits scandal. Such failures, once exposed, have consequences, with poorly implemented systems resulting in lower levels of trust in algorithms' performance.\n",
      "\n",
      "These  experimental  findings  are  largely  consistent  with findings from earlier studies outside our discipline on pretrial algorithmic risk scores in the US context. These studies, too, did not reveal an overwhelming pattern of automatic adherence  to  algorithmic  risk  scores. An  important  limitation  of these previous studies however, was that they failed to compare algorithmic advice with equivalent human advice, which we remedy with our current investigation.\n",
      "\n",
      "Still, how can we reconcile the results of our study (and the studies above) with findings from studies in social psychology on  the  use  of  automation  in  aviation  and  healthcare  (e.g., Lyell  and  Coiera  2017;  Skitka,  Mosier,  and  Burdick  1999, 2000),  where  patterns  of  automation  bias  have  been  welldocumented  and  recognized?  One  possible  explanation  for this discrepancy is a relative skepticism about the performative capacity of AI algorithms, with many participants, based on their self-reporting, still under-exposed to their performative capacities (in studies 1 and 2), or exposed to their negative consequences (in study 3, following the benefits scandal). This is  an  important  difference  to  earlier  studies  on  automation applied  in  areas  well-accustomed  to  such  devices  (aviation, healthcare), characterized by routine use of reliable automation, resulting in high levels of trust in their performance.\n",
      "\n",
      "These  findings  also  have  important  implications  for  the public  administration  literature  on  automation  and  discretion. Introducing algorithmic tools into the decision-making process, we find in our studies, did not supplant the discretion and judgment of human decision-makers, with the vast majority of our respondents overriding the prediction. At the same time, we argue that it is too soon to rule out concerns with undue bureaucratic deference to AI systems. Rather, automatic deference to algorithmic advice could become more prevalent  as  decision-makers  become  increasingly  exposed to  AI  algorithms  in  the  practice  of  public  organizations. Repeated experience with high-performing systems (in so far as  such  systems  are  high-performing)  might  increase 'user appreciation'  of  their  judgment  capacities  (decrease  skepticism),  leading  to  higher  levels  of  deference  over  repeated interactions.\n",
      "\n",
      "## Selective Adherence\n",
      "\n",
      "We also theorized, extrapolating from behavioral literature, that  similar  to  human advice, decision-makers are likely to rely  on  algorithmic  inputs  in  a  biased,  selective  mannerto  assign  more  weight  to  the  advice  and  follow  it  against contradicting evidence when this is aligned with pre-existing stereotypes. Establishing whether selective adherence is present across both types of advice is important in a context where AI algorithms are said to have the potential to do away with human decisional biases. We further theorized that selective adherence biases could be exacerbated by algorithms, by virtue of their unique nature.\n",
      "\n",
      "In study 2, which consisted of a sample of Dutch citizens in  a  context  where  citizens  can  serve  as  actual  decisionmakers, we  found evidence supporting selective adherence patterns  across  both  human  and  algorithmic  advice conditions. Namely, when the low prediction score is assigned to  a  teacher  from  a  negatively  stereotyped  ethnic  minority, participants were significantly more likely to rely on it in their decisions and less likely to override it. These selective adherence patterns are present across both types of advice (human and algorithmic), as evidenced by the positive and significant main effect  for  the  teacher  ethnicity  manipulation.  In  both conditions,  participants  were  more  likely  not  to  renew  the contract of the ethnic minority teacher.\n",
      "\n",
      "Importantly, we found that this bias is not more emphasized for algorithmic advice when compared to human advice, as the  interaction  between  the  two  manipulations  in  our  factorial design is insignificant. Taken jointly, these two sets of findings  indicate  that  while  not  exacerbated  by  algorithms, selective  adherence  patterns  occur  across  both  sources  of advice rather than being restricted to human advice. The replacement of human advice with algorithmic advice does not make selective adherence disappear. These findings are also in line with results from other studies on pretrial algorithmic risk scores by law and computer science scholars respectively, which report patterns consistent with biased adherence to algorithmic advice (Green and Chen 2019a, 2019b; Stevenson 2018). The findings of our study, and others, carry important implications as they indicate decision-making biases endure in  AI  algorithm  adoption as  decisional  aides  in  the  public sector, contrary to the promise that propelled their adoption as a means to do away with such biases. Similar to humansourced advice, a tendency to follow algorithmic advice, too, rather than generalized, is instead selective and more likely when  this  advice  matches  pre-existing  stereotypical  beliefs. Our sample of civil servants in study 3 did not yield similar results. The participants in study 3, conducted in the aftermath of a scandal involving algorithm use and discrimination in bureaucratic decision making, were less likely not to renew the contract of a teacher from a negatively stereotyped minority with a low score compared to a Dutch teacher with the same score.\n",
      "\n",
      "How can we explain the discrepancy between the studies on this aspect? Several explanations could account for these findings:  First,  one  could  speculate  that  these  differences might  stem  from  distinctive  characteristics  of  civil  servants compared with lay citizens, namely the ability of the former to overcome social biases and prejudice as a result of their professional  training,  expertise,  or  background.  However, a  vast  body  of  literature  in  social  science  provides  us  with theory and empirical evidence for the existence of discriminatory  decision-making  that  are  also  rooted  in  subtle  and unconscious cognitive mechanisms (e.g., Schram et al. 2009). These patterns have been theorized and are well-documented in  bureaucratic  contexts,  also  among  highly  educated,  professional  decision-makers  (e.g.,  Andersen  and  Guul  2019; Assouline,  Gilad,  and  Bloom  2022;  Giulietti,  Tonin,  and Vlassopoulos 2019).\n",
      "\n",
      "A  methodological  explanation  is  also  plausible  for  the patterns  encountered  in  study  3:  namely,  that  civil  servant participants' responses could reflect social desirability bias, an  (unconscious)  need  to  answer  questions  in  ways  that demonstrate that they do not discriminate. This is a common threat to studies of discrimination more broadly, and indeed several survey experimental studies have 'failed' to find racial  discrimination  in  their  data,  arguably  for  this  reason (e.g.,  Baekgaard  and  George  2018;  Wulff  and  Villadsen 2020). This  threat  is  plausibly  more  likely  for  the  sample of professional civil servants surveyed in study 3, compared with the sample of lay citizens in study 2 (even though both groups were explicitly guaranteed anonymity). Furthermore, this  threat  is  potentially  exacerbated  by  the  fact  that  civil servant  participants  were  invited  by  a  panel  linked  to  the Dutch government.\n",
      "\n",
      "The  more  plausible  explanation,  in  our  reading,  for  the fact  that  we  did  not  encounter  patterns  of  selective  adherence in study 3 (as we did in study 2) is that participants' responses were an authentic reaction to the recent childcare benefits  scandal  and  the  political,  media  and  public  scrutiny that followed from it. The scandal represented a case of systemic bureaucratic discrimination against citizens with a migration  background,  an  empirical  case  that  incidentally closely  matched our own hypothetical scenario, with many civil  servants  respondents  spontaneously  indicating  familiarity with the scandal in their open answers. It is likely that the scandal increased civil servants' awareness of racial profiling  and  discrimination  toward  ethnic  minorities  in  the Netherlands-explicitly also in relation to algorithm use in bureaucratic decision-making. Indeed, social psychology studies  have  theorized  that  racial  biases  can  be  attenuated when  people  are  highly  motivated  to  do  so  (Devine  et  al. 2002). This would suggest the scandal had a learning effect although our study does not allow us to assess to what extent these effects are long-lived.\n",
      "\n",
      "It  is  important  to  note  that  the  scandal  itself  is  an  illustrative example of the theorized patterns of decision-makers' adherence to algorithmic advice, and how it can result in discrimination in decision making. The scandal speaks acutely to the serious real-life repercussions that can arise when human bias meets algorithmic bias in bureaucratic decision making. Taken  together  with  our  empirical  findings  in  study  2,  we believe  that  there  is  evidence  for  selective  adherence  to  algorithmic advice that calls for additional and pressing investigation of this issue by public administration scholars.\n",
      "\n",
      "A key justification put forward for algorithm adoption in high-stakes public sector areas such as criminal justice or policing, and for  'tolerating' shortcomings of such systems (e.g., pertaining to their opaqueness and associated concerns with transparency  and  accountability)  has  been  their  perceived superior  performance  and  said 'objectivity'  as  data-driven technologies, as a way to overcome human biases and limitations. While such claims have been deflated when it comes to algorithms' own learning and functioning (e.g., algorithms replicating  and  propagating  systematic  biases  learned  from training  data  is  a  well-documented  problem  that  can  arise in  algorithm  deployment),  it  is  important  to  keep  in  mind that  bias  can  also  crop  up  at  another  level:  in  the  humanAI  interaction,  in  how  decision-makers  process,  interpret, and  act  upon  algorithmic  outputs.  Our  findings  raise  further questions about the added value of the reliance on algorithmic advice as a mechanism to avoid bias and speak to potential  negative  effects  of  automation  of  the  administrative  state  for  already  vulnerable  and  disadvantaged citizens (Eubanks 2018; Ranchordas 2022). Even assuming that the algorithmic  outputs  themselves  could  be  bias-free,  we  find some evidence that human decision-makers tend to rely on such outputs selectively, that is, when their predictions 'suit' pre-existing stereotypes.\n",
      "\n",
      "Keeping  humans-in-the-loop  (human  intervention)  is  an important safeguard against algorithmic failures and is even legally mandated to that end in forward-looking regulatory frameworks such as the EU GDPR. While our findings as to a lack of automatic deference are encouraging in this context, the  likelihood  that  decision-makers  adhere  to  algorithmic advice  (rather  than  resist  it) precisely when  predictions  are aligned  with  group  stereotypes  and  disadvantage  minority groups is disconcerting, and speaks to potential blind spots in our ability to exercise meaningful oversight. Such concerns can become especially problematic, as we saw, in mixed algorithmic decision making when human bias meets algorithmic bias. At the same time, an encouraging, tentative take-away that  emerges  from  our  investigation  is  that  high-visibility, public  exposure  of  such  biases  (as  in  the  aftermath  of  the benefits scandal) can have learning effects through rendering civil servants more conscious and alert to such risks leading to their potential attenuation in decision making, at least in the short term.\n",
      "\n",
      "Our  study  takes  a  first  step  to  investigate  how  public decision-makers process AI algorithmic advice from decisional support  systems.  As  AI  tools  proliferate  in the public  sector, this comes  with  significant  possible implications for the nature of administrative decision making,  rendering  this  issue  increasingly  salient  for  our discipline.  Future  studies  may  investigate  these  aspects  in scenarios  pertaining  to  different  sectors  and  across  multiple national  jurisdictions. Importantly,  and  following our results,  follow-up  work could further test the role of decision-makers'  learning  and  repeat  exposure  through  a design  that  allows  for  repeat  interactions  with  the  algorithm so as to assess to what extent participants' trust in the  algorithm  changes  over  time,  potentially  leading  to patterns of enhanced deference. Investigating the cognitive mechanisms underpinning algorithmic decision making in an administrative context will be of crucial theoretical and empirical significance, part and parcel of tackling broader, fundamental questions as to the impact of artificial intelligence for bureaucratic expertise and discretion, the nature of public authority, and public accountability in the age of automation.\n",
      "\n",
      "## Supplementary Material\n",
      "\n",
      "Supplementary  data  is  available  at  the Journal  of  Public Administration Research and Theory online.\n",
      "\n",
      "## Funding\n",
      "\n",
      "This article is part of a project that has received funding from the European Research Council (ERC) under the European Union's Horizon 2020 research and innovation programme (grant agreement 716439).\n",
      "\n",
      "## Data Availability\n",
      "\n",
      "The  data  underlying  this  article  are  available  in  Harvard Dataverse, at https://doi.org/10.7910/DVN/TQYJNF.\n",
      "\n",
      "## Appendix A\n",
      "\n",
      "## Randomization Groups\n",
      "\n",
      "<!-- image -->\n",
      "\n",
      "## Exclusions:\n",
      "\n",
      "- * Participants who failed the attention check or completed the questionnaire in less than 3 min.\n",
      "- ** Participants not of Dutch descent (excluded from the analysis of selective adherence hypotheses-H  and H ). 2 3\n",
      "\n",
      "## Appendix B\n",
      "\n",
      "## Sample Characteristics\n",
      "\n",
      "|                |                 | Study 1     | Study 2     | Study 3    | Dutch Civil Service   |\n",
      "|----------------|-----------------|-------------|-------------|------------|-----------------------|\n",
      "| Gender         | %Women          | 54.5        | 47.8        | 28.5       | 42.0                  |\n",
      "| Age            | Mean (SD)       | 47.1 (16.6) | 47.5 (17.5) | 55.4 (7.5) | 46.3                  |\n",
      "|                | % 18-25         | 14.3        | 17.3        | 0.1        | 19.7                  |\n",
      "|                | 26-35           | 14.6        | 12.6        | 1.4        | (age 18-35)           |\n",
      "|                | 36-45           | 17.3        | 12.8        | 9.1        | 50.0                  |\n",
      "|                | 46-55           | 18.0        | 18.5        | 33.4       | (age 36-55)           |\n",
      "|                | 56-65           | 19.7        | 21.4        | 54.3       | 30.3                  |\n",
      "|                | 65+             | 16.0        | 17.4        | 1.6        | (age 56+)             |\n",
      "| Education      | %high education | 50.1        | 49.0        | 71.0       | 50.0                  |\n",
      "| N participants |                 | 605         | 904         | 1,345      |                       |\n",
      "\n",
      "Note : Valid percentages are reported. Dutch civil service data is from 2018, regarding 412,999 civil servants from national and local civil service, including defense and police.\n",
      "\n",
      "Source: https://kennisopenbaarbestuur.nl/.\n",
      "\n",
      "## References\n",
      "\n",
      "Andersen, Simon Calmar, and Thorbjørn Sejr Guul. 2019. Reducing minority discrimination at the front line-Combined survey and field experimental evidence. Journal of Public Administration Research and Theory 29 (3): 429-44.\n",
      "\n",
      "Angwin, Julia, Jeff Larson, Surya Mattu, and Lauren Kirchner. 2016. Machine bias. ProPublica , May  23. https://www.propublica. org/article/machine-bias-risk-assessments-in-criminal-sentencing (accessed March 2022).\n",
      "\n",
      "Assouline, Michaela, Sharon Gilad, and Pazit Ben-Nun Bloom. 2022. Discrimination of minority welfare claimants in the real world: The effect  of  implicit  prejudice. Journal of Public Administration Research and Theory 32 (1): 75-96.\n",
      "\n",
      "Autoriteit Persoonsgegevens/Dutch Data Protection Authority. 2020. Belastingdienst/Toeslagen: De verwerking van de nationaliteit van  aanvragers  van  kinderopvangtoeslag.  https:// autoriteitpersoonsgegevens.nl/sites/default/files/atoms/files/ onderzoek\\_belastingdienst\\_kinderopvangtoeslag.pdf (accessed March 2022).\n",
      "\n",
      "Baekgaard,  Martin,  and  Bert  George.  2018.  Equal  access  to  the top? Representative bureaucracy and politicians' recruitment preferences for top administrative staff. Journal of Public Administration Research and Theory 28 (4): 535-50.\n",
      "\n",
      "Baekgaard,  Martin,  Julian  Christensen,  Casper  Mondrup  Dahlmann, Asbjørn Mathiasen, and Niels Bjørn Grund Petersen. 2019. The role of evidence in politics: Motivated reasoning and persuasion among politicians. British Journal of Political Science 49 (3): 1117-40.\n",
      "\n",
      "Baekgaard,  Martin,  and  Søren  Serritzlew.  2016.  Interpreting  performance information: Motivated reasoning or unbiased comprehension. Public Administration Review 76 (1): 73-82.\n",
      "\n",
      "Benjamin, Ruha. 2019. Race after technology: Abolitionist tools for the New Jim Code . Polity Press.\n",
      "\n",
      "Bovens, Mark, and Stavros Zouridis. 2002. From street-level to systemlevel  bureaucracies:  How  information  and  communication  technology is transforming administrative discretion and constitutional control. Public Administration Review 62 (2): 174-84.\n",
      "\n",
      "Buffat,  Aurélien.  2015.  Street-level  bureaucracy  and  e-government. Public Management Review 17 (1): 149-61.\n",
      "\n",
      "Bullock, Justin B. 2019. Artificial intelligence, discretion, and bureaucracy. The American Review of Public Administration 49 (7): 751-61. Buolamwini,  Joy,  and Timnit  Gebru.  2018.  Gender  shades:  Intersectional accuracy disparities in commercial gender classification. Proceedings of Machine Learning Research 81:1-15.\n",
      "\n",
      "Busch, Peter, and Helle Henriksen. 2018. Digital discretion: A systematic literature review of ICT and street-level discretion. Information Polity 23 (1): 3-28.\n",
      "\n",
      "Busuioc,  Madalina.  2021.  Accountable  artificial  intelligence:  Holding algorithms to account. Public Administration Review 81  (5): 825-36.\n",
      "\n",
      "Calo, Ryan, and Danielle Keats Citron. 2021. The automated administrative state: A crisis of legitimacy. Emory Law Journal 70: 797-846.\n",
      "\n",
      "Christensen, Julian. 2018. Biased, not blind: An experimental test of self-serving biases in service users' evaluations of performance in- formation. Public Administration 96 (3): 468-80.\n",
      "\n",
      "Christensen,  Julian,  Casper  Mondrup  Dahlmann, Asbjørn  Hovgaard Mathiasen, Donald P. Moynihan, and Niels Bjørn Grund Petersen. 2018.  How  do  elected  officials evaluate performance?  Goal preferences,  governance  preferences,  and  the  process  of  goal reprioritization. Journal  of  Public  Administration  Research  and Theory 28 (2): 197-211.\n",
      "\n",
      "Cobbe, Jennifer. 2019. Administrative law and the machines of government: Judicial review of automated public-sector decision-making. Legal Studies 39 (4): 636-55.\n",
      "\n",
      "Cummings, Mary L. 2006. Automation and accountability in decision support system interface design. The Journal of Technology Studies 32(1): 23-31.\n",
      "\n",
      "- de Boer, Noortje, and Nadine Raaphorst. 2021. Automation and discretion:  Explaining  the  effect  of  automation  on  how  street-level\n",
      "\n",
      "bureaucrats enforce. Public Management Review . doi:10.1080/14 719037.2021.1937684\n",
      "\n",
      "Devine, Patricia G., E. Ashby Plant, David M. Amodio, Eddie HarmonJones, and Stephanie L. Vance. 2002. The regulation of explicit and implicit race bias: The role of motivations to respond without prejudice. Journal of Personality and Social Psychology 82 (5): 835-48.\n",
      "\n",
      "Diakopoulos,  Nicholas.  2014. Algorithmic  accountability  reporting: On the investigation of black boxes . New York: Columbia Univ., Tow Center for Digital Journalism.\n",
      "\n",
      "Edwards, Lilian, and Michael Veale. 2017. Slave to the algorithm? Why a 'right to an explanation' is probably not the remedy you are looking for. Duke Law &amp; Technology Review 18:18-84.\n",
      "\n",
      "Engstrom, David F., Daniel E. Ho, Catherine M. Sharkey, and MarianoFlorentino Cuéllar. 2020. Government by algorithm: Artificial intelligence in federal administrative agencies .  Report Submitted to the Administrative Conference of the United States, February 19.\n",
      "\n",
      "Eubanks, Virginia. 2018. Automating inequality: How high-tech tools profile, police, and punish the poor . New York: St. Martin's Press.\n",
      "\n",
      "Ferguson, Andrew Guthrie. 2017. The rise of big data policing: Surveillance, race, and the future of law enforcement . New York: NYU Press.\n",
      "\n",
      "Financial Times. 2021. Scandals tarnish Dutch reputation for clean government. June 24. https://www.ft.com/content/9996a65e-0996-4a08aa65-041be685deae?shareType=nongift (accessed March 2022).\n",
      "\n",
      "Geiger,  Gabriel.  2021.  How  a  discriminatory  algorithm  wrongly  accused  thousands  of  families  of  fraud. Vice , March  1.  https:// www.vice.com/en/article/jgq35d/how-a-discriminatory-algorithmwrongly-accused-thousands-of-families-of-fraud\n",
      "\n",
      "Giest,  Sarah,  and  Stephan  Grimmelikhuijsen.  2020.  Introduction  to special issue algorithmic transparency in government: Towards a multi-level perspective. Information Polity 25 (4): 409-17.\n",
      "\n",
      "Giulietti, Corrado, Mirco Tonin, and Michael Vlassopoulos. 2019. Racial  discrimination in local public services: A field experiment in the United States. Journal of the European Economic Association 17 (1): 165-204.\n",
      "\n",
      "Goddard, Kate, Abdul Roudsari, and Jeremy C. Wyatt. 2012. Automation bias: A systematic review of frequency, effect mediators, and mitigators. Journal of the American Medical Informatics Association 19 (1): 121-7.\n",
      "\n",
      "Green,  Ben,  and  Yiling  Chen.  2019a.  Disparate  interactions:  An algorithm-in-the-loop  analysis  of  fairness  in  risk  assessments.  In FAT* '19: Proceedings of the Conference on Fairness, Accountability, and Transparency, Atlanta, GA, January 29-31.\n",
      "\n",
      "---. 2019b. The principles and limits of algorithm-in-the-loop decision making. Proceedings of the ACM on Human-Computer Interaction , 3 (CSCW): 1-24.\n",
      "\n",
      "Grgi -Hla a, Nina, Christoph Engel, and Krishna P. Gummadi. 2019. ć č Human  decision  making  with  machine  assistance:  An  experiment on bailing and jailing. Proceedings of the ACM on HumanComputer Interaction 3:1-25.\n",
      "\n",
      "Herd, Pamela, and Donald P. Moynihan. 2019. Administrative burden: Policymaking by other means .  New York: Russell Sage Foundation.\n",
      "\n",
      "Israni,  Ellora  Thadaney.  2017.  When  an  algorithm  helps  send  you to  prison. New  York  Times , October  26.  https://www.nytimes. com/2017/10/26/opinion/algorithm-compas-sentencing-bias.html\n",
      "\n",
      "James, Oliver, and Gregg G. Van Ryzin. 2017. Motivated reasoning about public performance: An experimental study of how citizens judge the Affordable Care Act. Journal of Public Administration Research and Theory 27 (1): 197-209.\n",
      "\n",
      "Jilke,  Sebastian.  2017.  Citizen  satisfaction  under  changing  political leadership: The role of partisan motivated reasoning. Governance 31 (3): 515-33.\n",
      "\n",
      "Jilke, Sebastian, and Lars Tummers. 2018. Which clients are deserving of help? A theoretical model and experimental test. Journal of Public Administration Research and Theory 28 (2): 226-38.\n",
      "\n",
      "Jilke, Sebastian, and Martin Baekgaard. 2020. The political psychology of citizen satisfaction: Does functional responsibility matter? Journal  of  Public  Administration  Research  and  Theory 30  (1): 130-43.\n",
      "\n",
      "Kamans, Elanor, Ernestine H. Gordijn, Hilbrand Oldenhuis, and Sabine Otten. 2009. What I think you see is what you get: Influence of  prejudice  on  assimilation  to  negative  meta-stereotypes  among Dutch Moroccan teenagers. European Journal of Social Psychology 39 (5): 842-51.\n",
      "\n",
      "Kim, Soonhee, Kim Normann Andersen, and Jungwoo Lee. 2021. Platform government in the era of smart technology. Public Administration Review . doi:10.1111/puar.13422\n",
      "\n",
      "Logg, Jennifer, Julia A. Minson, and Don A. Moore. 2019. Algorithm appreciation: People prefer algorithmic to human judgment. Organizational Behavior and Human Decision Processes 151:90-103.\n",
      "\n",
      "Lorah, Julie A. 2020. Interpretation of main effects in the presence of non-significant interaction effects. The Quantitative Methods for Psychology 16 (1): 33-45.\n",
      "\n",
      "Lyell, David, and Enrico Coiera. 2017. Automation bias and verification complexity: a systematic review. Journal of the American Medical Informatics Association 24 (2): 423-31.\n",
      "\n",
      "Medium-Open  Letter  Concerned  AI  Researchers.  2019.  On  recent research  auditing  commercial  facial  analysis  technology. Medium , March  26.  https://medium.com/@bu64dcjrytwitb8/onrecent-research-auditing-commercial-facial-analysis-technology19148bda1832\n",
      "\n",
      "Meijer, Albert, Lukas Lorenz, and Martijn Wessels. 2021. Algorithmization of bureaucratic organizations:  Using  a  practice lens to study how context shapes predictive policing systems. Public Administration Review 81 (5): 837-46.\n",
      "\n",
      "Milner, Greg. 2016. Death by GPS: Are Satnavs changing our brains? The  Guardian , June  25.  https://www.theguardian.com/technology/2016/jun/25/gps-horror-stories-driving-satnav-greg-milner\n",
      "\n",
      "Mosier,  Kathleen,  Melisa  Dunbar,  Lori  McDonnell,  Linda  Skitka, Mark  Burdick,  and  Bonnie  Rosenblatt.  1998.  Automation  bias and errors: Are teams better than individuals? Proceedings of the Human Factors and Ergonomics Society Annual Meeting 42  (3): 201-5.\n",
      "\n",
      "Mosier,  Kathleen  L., Linda  J. Skitka, Melisa  Dunbar,  and  Lori McDonnell. 2001. Aircrews and automation bias: the advantages of  teamwork? The International  Journal  of Aviation  Psychology 11 (1): 1-14.\n",
      "\n",
      "National Transportation Safety Board. 2017. 'Collision between a car operating with automated vehicle control systems and a tractorsemitrailer truck near williston, Florida May 7, 2016'. National Transportation Safety Board. September 12. https://www.ntsb.gov/ investigations/Pages/HWY16FH018.aspx (accessed March 2022).\n",
      "\n",
      "- OECD.  2014a.  Education  policy  outlook:  Netherlands.  http://www. oecd.org/education/EDUCATION%20POLICY%20OUTLOOK\\_ NETHERLANDS\\_EN%20.pdf (accessed March 2022).\n",
      "- OECD. 2014b. OECD reviews of evaluation and assessment in education: Netherlands 2014. https://www.oecd.org/education/school/ OECD-Evaluation-Assessment-Review-Netherlands.pdf (accessed March 2022).\n",
      "- O'Neil,  Cathy.  2016. Weapons  of  math  destruction:  How  big  data increases inequality and threatens democracy . Crown Books.\n",
      "- Parasuraman, Raja, and Victor Riley. 1997. Humans and automation: Use, misuse, disuse, abuse. Human Factors 39 (2): 230-53.\n",
      "\n",
      "Parlementaire  Ondervragingscommissie  Kinderopvangtoeslag.  2020. Ongekend onrecht. https://www.tweedekamer.nl/sites/default/files/ atoms/files/20201217\\_eindverslag\\_parlementaire\\_ ondervragingscommissie\\_kinderopvangtoeslag.pdf (accessed March 2022).\n",
      "\n",
      "Pedersen, Mogens Jin, Justin M. Stritch, and Frederik Thuesen. 2018. Punishment on the frontlines of public service delivery: Client ethnicity and caseworker sanctioning decisions in a Scandinavian welfare state. Journal of Public Administration Research and Theory 28 (3): 339-54.\n",
      "\n",
      "Peeters, Rik. 2020. The agency of algorithms: Understanding humanalgorithm interaction in administrative decision-making. Information Polity 25 (4): 507-22.\n",
      "\n",
      "Ranchordas, Sofia. 2022. Empathy in the digital administrative state. Duke Law Journal , forthcoming.\n",
      "\n",
      "Richardson, Rashida, Jason Schultz, and Kate Crawford. 2019. Dirty data,  bad  predictions:  How  civil  rights  violations  impact  police data, predictive policing systems, and justice. New York University Law Review Online 94:192-233.\n",
      "\n",
      "Rudin,  Cynthia.  2019.  Stop  explaining  black  box  machine  learning models for high stakes decisions and use interpretable models instead. Nature Machine Intelligence 1 (5):206-15.\n",
      "\n",
      "- Schiff,  Daniel  S.,  Kaylyn  Jackson  Schiff,  and  Patrick  Pierson.  2021. Assessing public value failure in government adoption of artificial intelligence. Public Administration . doi:10.1111/padm.12742\n",
      "\n",
      "Schram, Sanford F., Joe Soss, Richard C. Fording, and Linda Houser. 2009. Deciding to discipline: Race, choice, and punishment at the frontlines of welfare reform. American Sociological Review 74 (3): 398-422.\n",
      "\n",
      "- Skitka,  Linda  J.,  Kathleen  L.  Mosier,  and  Mark  D.  Burdick.  1999. Does automation bias decision-making? International  Journal  of Human-Computer Studies 51 (5): 991-1006.\n",
      "- ---. 2000. Accountability and automation bias. International Journal of Human-Computer Studies 52 (4): 701-17.\n",
      "- Skitka,  Linda  J.,  Kathleen  L.  Mosier,  Mark  D.  Burdick,  and  Bonnie Rosenblatt.  2000. Automation  bias  and  errors: Are  crews  better than individuals? The International Journal of Aviation Psychology 10 ( 1 ): 85-97.\n",
      "\n",
      "Stevenson, Megan. 2018. Assessing risk assessment in action. Minnesota Law Review 103:303-84.\n",
      "\n",
      "- Turque, Bill. 2012.  'Creative...motivating' and  fired. Washington Post ,  March  6.  https://www.washingtonpost.com/local/education/ creative--motivating-and-fired/2012/02/04/gIQAwzZpvR\\_story. html\n",
      "\n",
      "Veale, Michael, and Irina Brass. 2019. Administration by algorithm? Public management meets public sector machine learning. In Algorithmic Regulation , eds. Karen Yeung and Martin Lodge. Oxford: Oxford University Press.\n",
      "\n",
      "Vogl, Thomas M., Cathrine Seidelin, Bharath Ganesh, and Jonathan Bright. 2020. Smart technology and the emergence of algorithmic bureaucracy: Artificial intelligence in UK local authorities. Public Administration Review 80 (6): 946-61.\n",
      "\n",
      "Volkskrant. 2020. Belastingdienst schuldig aan structurele discriminatie van mensen die toeslagen ontvingen. Volkskrant , July 21. https://www.volkskrant.nl/nieuws-achtergrond/belastingdienstschuldig-aan-structurele-discriminatie-van-mensen-die-toeslagenontvingen~baebefdb/\n",
      "\n",
      "Wulff, Jesper N., and Anders R. Villadsen. 2020. Are survey experiments as valid as field experiments in management research? An empirical comparison using the case of ethnic employment discrimination. European Management Review 17 (1): 347-56.\n",
      "\n",
      "Yeung,  Karen,  and  Martin  Lodge.  2019. Algorithmic  regulation: An introduction.  In Algorithmic  regulation , eds.  Karen  Yeung  and Martin Lodge, 1-18. Oxford Univ. Press.\n",
      "\n",
      "Young,  Matthew  M.,  Justin  B.  Bullock,  and  Jesse  D.  Lecy.  2019. Artificial  discretion  as  a  tool  of  governance:  A  framework  for understanding the impact of artificial intelligence on public administration. Perspectives on Public Management and Governance 2 (4): 301-13.\n",
      "\n",
      "- Young,  Matthew  M.,  Johannes  Himmelreich,  Justin  B.  Bullock,  and Kyoung-Cheol Kim. 2021. Artificial intelligence and administrative evil. Perspectives  on  Public  Management  and  Governance 4  (3): 244-58.\n",
      "\n",
      "Zerilli,  John, Alistair  Knott,  James  Maclaurin,  and  Colin  Gavaghan. 2019.  Algorithmic  decision-making  and  the  control  problem. Minds &amp; Machines 29:555-78.\n",
      "\n",
      "Zouridis  Stavros,  Marlies  van  Eck,  and  Mark  Bovens.  2020.  Automated discretion. In Discretion and the quest for controlled freedom , eds. Tony Evans and Peter Hupe, 313-29. London: Palgrave Macmillan.\n"
     ]
    }
   ],
   "source": [
    "source = (\n",
    "    \"uploads/0e37f6b9-f2cd-47e8-8112-a5d157408925.pdf\"  # document per local path or URL\n",
    ")\n",
    "converter = DocumentConverter()\n",
    "result = converter.convert(source)\n",
    "print(result.document.export_to_markdown())\n",
    "# output: ## Docling Technical Report [...]\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 25 pages from 8ed4812d-4073-45ea-a685-be605f36da3e.pdf\n",
      "\n",
      "\n",
      "page_content='Urban Planning\n",
      "2025 • Volume 10• Article 9165\n",
      "https://doi.org/10.17645/up.9165\n",
      "A R T I C L E Open Access Journal\n",
      "AI‐Supported Participatory Workshops: Middle‐Out Engagement\n",
      "for Crisis Events\n",
      "Martin Tomitsch1\n",
      " , Joel Fredericks2\n",
      " , Marius Hoggenmüller2\n",
      " , Alexandra Crosby3\n",
      " ,\n",
      "Adrian Wong2\n",
      " , Xinyan Yu2\n",
      " , and Weidong Huang1\n",
      "1 TransdisciplinarySchool,UniversityofTechnologySydney,Australia\n",
      "2 SchoolofArchitecture,DesignandPlanning,TheUniversityofSydney,Australia\n",
      "3 FacultyofDesign,ArchitectureandBuilding,UniversityofTechnologySydney,Australia\n",
      "Correspondence: MartinTomitsch(martin.tomitsch@uts.edu.au)\n",
      "Submitted: 9August2024 Accepted: 5November2024 Published: 27January2025\n",
      "Issue: This article is part of the issue “The Role of Participatory Planning and Design in Addressing the\n",
      "UN Sustainable Development Goals” edited by Hilary Davis (Swinburne University of Technology), Joel\n",
      "Fredericks(TheUniversityofSydney),MarcusFoth(QueenslandUniversityofTechnology),GlendaCaldwell\n",
      "(QueenslandUniversityofTechnology),andCallumParker(TheUniversityofSydney),fullyopenaccessat\n",
      "https://doi.org/10.17645/up.i394\n",
      "Abstract\n",
      "Consideringthelivedexperienceofcommunitiesiskeywhenmakingdecisionsincomplexscenarios,suchas\n",
      "preparingforandrespondingtocrisisevents.Thearticlereportsonthreeparticipatoryworkshops,which\n",
      "assigned community representative roles to workshop participants. Using role‐playing as a method,\n",
      "participantsweregiventhetaskofcollaboratingonmakingadecisionrelatingtoaspeculativecrisisscenario.\n",
      "Acrosstheworkshops,wecollecteddataaboutsimulatingamiddle‐outengagementapproachandtherole\n",
      "of artificial intelligence (AI) in enhancing collaboration, supporting decision‐making, and representing\n",
      "non‐humanactors.Thearticlemakesthreecontributionstoparticipatoryplanninganddesigninthecontext\n",
      "of the UN Sustainable Development Goals. First, it presents insights about the use of AI in enhancing\n",
      "collaboration and decision‐making in crisis event situations. Second, it discusses approaches for bringing\n",
      "more‐than‐human considerations into participatory planning and design. Third, it reflects on the value of\n",
      "role‐playingasawaytosimulateamiddle‐outengagementprocess,wherebyactorsfromthetopandthe\n",
      "bottomcollaboratetowardsmakinginformeddecisionsincomplexscenarios.Drawingonthefindingsfrom\n",
      "theworkshops,thearticlecriticallyreflectsonchallengesandrisksassociatedwithusingAIinparticipatory\n",
      "workshopsandcollaborativedecision‐making.\n",
      "Keywords\n",
      "artificialintelligence;communityengagement;conversationalagents;middle‐outengagement;non‐human\n",
      "personas;participatorydesign;participatoryplanning\n",
      "©2025bytheauthor(s),licensedunderaCreativeCommonsAttribution4.0InternationalLicense(CCBY). 1' metadata={'producer': 'xdvipdfmx (20240407)', 'creator': 'LaTeX with hyperref', 'creationdate': '2025-01-20T14:46:41+00:00', 'moddate': '2025-01-20T15:21:30+00:00', 'title': 'AI-Supported Participatory Workshops: Middle-Out Engagement for Crisis Events', 'keywords': 'artificial intelligence; community engagement; conversational agents; middle-out engagement; non-human personas; participatory design; participatory planning', 'author': 'Martin Tomitsch, Joel Fredericks, Marius Hoggenmüller, Alexandra Crosby, Adrian Wong, Xinyan Yu, and Weidong Huang', 'source': 'uploads/8ed4812d-4073-45ea-a685-be605f36da3e.pdf', 'total_pages': 25, 'page': 0, 'page_label': '1'}\n",
      "Loaded 17 pages from 0ae51831-7deb-4e5a-ba1b-8bc3e8529bea.pdf\n",
      "\n",
      "\n",
      "page_content='Journal of Public Administration Research and Theory, 2023, 33, 153–169\n",
      "https://doi.org/10.1093/jopart/muac007\n",
      "Advance access publication 8 February 2022\n",
      "Article\n",
      "Human–AI Interactions in Public Sector Decision Making: \n",
      "“ Automation Bias” and “Selective Adherence” to \n",
      "Algorithmic Advice\n",
      "Saar Alon-Barkat,*,  Madalina Busuioc†,\n",
      "*University of Haifa, Israel\n",
      "†Vrije Universiteit Amsterdam, The Netherlands\n",
      "Address correspondence to the author at e.m.busuioc@vu.nl.\n",
      "Abstract \n",
      "Artificial intelligence algorithms are increasingly adopted as decisional aides by public bodies, with the promise of overcoming biases of human \n",
      "decision-makers. At the same time, they may introduce new biases in the human–algorithm interaction. Drawing on psychology and public \n",
      "administration literatures, we investigate two key biases: overreliance on algorithmic advice even in the face of “warning signals” from other \n",
      "sources (automation bias), and selective adoption of algorithmic advice when this corresponds to stereotypes (selective adherence). We assess \n",
      "these via three experimental studies conducted in the Netherlands: In study 1 (N = 605), we test automation bias by exploring participants’ \n",
      "adherence to an algorithmic prediction compared to an equivalent human-expert prediction. We do not find evidence for automation bias. In \n",
      "study 2 (N = 904), we replicate these findings, and also test selective adherence. We find a stronger propensity for adherence when the advice \n",
      "is aligned with group stereotypes, with no significant differences between algorithmic and human-expert advice. In study 3 (N = 1,345), we \n",
      "replicate our design with a sample of civil servants. This study was conducted shortly after a major scandal involving public authorities’ reliance \n",
      "on an algorithm with discriminatory outcomes (the “childcare benefits scandal”). The scandal is itself illustrative of our theory and patterns \n",
      "diagnosed empirically in our experiment, yet in our study 3, while supporting our prior findings as to automation bias, we do not find patterns of \n",
      "selective adherence. We suggest this is driven by bureaucrats’ enhanced awareness of discrimination and algorithmic biases in the aftermath of \n",
      "the scandal. We discuss the implications of our findings for public sector decision making in the age of automation. Overall, our study speaks to \n",
      "potential negative effects of automation of the administrative state for already vulnerable and disadvantaged citizens.\n",
      "Introduction\n",
      "Artificial intelligence (AI) algorithms are being widely adopted \n",
      "in the public sector across jurisdictions. Essentially a set of tools \n",
      "that display (or can even surpass) human-level performance \n",
      "on given tasks traditionally associated with human intelli-\n",
      "gence, AI algorithms are being relied upon in areas as varied as \n",
      "policing, welfare, criminal justice, healthcare, immigration, or \n",
      "education (Busuioc 2021; Calo and Citron 2021; Diakopoulos \n",
      "2014; Eubanks 2018; Engstrom et al. 2020; O’Neil 2016; \n",
      "Richardson, Schultz, and Crawford 2019; Veale and Brass \n",
      "2019; Yeung and Lodge 2019), increasingly permeating  \n",
      "non-routine and high-stakes aspects of bureaucratic work. The \n",
      "growing and deepening reliance on AI and machine learning \n",
      "technologies in the public sector has been diagnosed as “trans-\n",
      "formative” of public administrations (Bullock 2019; Vogl et al. \n",
      "2020; Young, Bullock, and Lecy 2019).\n",
      "These developments are driven by the promise of policy \n",
      "solutions that are potentially more effective, efficient, and \n",
      "low-cost. In addition, and importantly, algorithms are said to \n",
      "come with the “promise of neutrality,” in contrast to decision \n",
      "making based on human intuition, which involves biases and \n",
      "can result in discrimination. In other words, AI use in deci-\n",
      "sion making is said to hold the potential to help us overcome \n",
      "our cognitive biases and limitations. This has been an impor-\n",
      "tant driver for the adoption of such technologies in highly \n",
      "consequential public sector areas such as law enforcement or \n",
      "criminal justice: Predictive policing technologies, for instance, \n",
      "were propagated in the US context “as one answer to racially \n",
      "discriminatory policing, offering a seemingly race-neutral, ‘ob-\n",
      "jective’ justification for police targeting of poor communities” \n",
      "(Ferguson 2017, 5). Numerous other jurisdictions have \n",
      "followed suit with predictive technologies relied upon by po-\n",
      "lice forces in the United Kingdom, the Netherlands, Germany, \n",
      "among many others. Like rationales precipitated the adoption \n",
      "of predictive risk assessment systems in criminal justice, sim-\n",
      "ilarly in part in response to concerns with human bias and \n",
      "discrimination (Israni 2017), despite such systems themselves \n",
      "being flagged as sources of bias (Angwin et al. 2016).\n",
      "For a large part, AI algorithms currently serve as decisional \n",
      "aides to human decision-makers (“decision-support sys-\n",
      "tems”) in many bureaucratic contexts. This is especially so \n",
      "in highly consequential public sector areas, where “full au-\n",
      "tomation seems inappropriate or far off” (Edward and Veale \n",
      "2017, 45). Rather than making decisions on their own, al-\n",
      "gorithmic outputs—be they risk assessment scores used in \n",
      "criminal justice or the algorithm-generated “heat maps” of \n",
      "© The Author(s) 2022. Published by Oxford University Press on behalf of the Public Management Research Association.\n",
      "This is an Open Access article distributed under the terms of the Creative Commons Attribution-NonCommercial License (https://creativecommons.org/\n",
      "licenses/by-nc/4.0/), which permits non-commercial re-use, distribution, and reproduction in any medium, provided the original work is properly cited. For \n",
      "commercial re-use, please contact journals.permissions@oup.com\n",
      "We thank the three anonymous JPART reviewers for their extremely help-\n",
      "ful comments. We are also grateful to Dimiter Toshkov, Nadine Raaphorst, \n",
      "Joris van der Voet, Dana Vashdi, Sharon Gilad, Markus Tepe, Stephan \n",
      "Grimmelikhuijsen, Thijs de Boer, Benjamin Tidå, Omer Yair, and Aaron \n",
      "Swaving for their valuable comments and feedback in the process of devel-\n",
      "oping this project. We thank Luuk van Roozendaal for excellent research \n",
      "assistance.\n",
      "Downloaded from https://academic.oup.com/jpart/article/33/1/153/6524536 by guest on 21 March 2025' metadata={'producer': 'Adobe PDF Library 15.0; modified using iTextSharp 4.1.6 by 1T3XT', 'creator': 'Adobe InDesign 15.1 (Windows)', 'creationdate': '2022-12-23T18:23:16+05:30', 'trapped': '/False', 'moddate': '2025-03-21T10:34:28+00:00', 'source': 'uploads/0ae51831-7deb-4e5a-ba1b-8bc3e8529bea.pdf', 'total_pages': 17, 'page': 0, 'page_label': '153'}\n",
      "Loaded 14 pages from 9102c4fe-1c59-40dd-b170-cb3976a36874.pdf\n",
      "\n",
      "\n",
      "page_content='AI and the Future of Collaborative Work: Group Ideation with an\n",
      "LLM in a Virtual Canvas\n",
      "Jessica He\n",
      "IBM Research AI\n",
      "Seattle, USA\n",
      "jessicahe@ibm.com\n",
      "Stephanie Houde\n",
      "IBM Research AI\n",
      "Cambridge, USA\n",
      "Stephanie.Houde@ibm.com\n",
      "Gabriel Enrique Gonzalez\n",
      "IBM Argentina\n",
      "Necochea, Argentina\n",
      "gabriel.gonzalez@ibm.com\n",
      "Dario Andres Silva Moran\n",
      "IBM Argentina\n",
      "La Plata, Argentina\n",
      "dario.silva@ibm.com\n",
      "Steven I. Ross\n",
      "IBM Research AI\n",
      "Cambridge, USA\n",
      "steven_ross@us.ibm.com\n",
      "Michael Muller\n",
      "IBM Research AI\n",
      "Cambridge, USA\n",
      "michael_muller@us.ibm.com\n",
      "Justin D. Weisz\n",
      "IBM Research AI\n",
      "Yorktown Heights, USA\n",
      "jweisz@us.ibm.com\n",
      "ABSTRACT\n",
      "The introduction of generative AI into multi-user applications raises\n",
      "novel considerations for the future of collaborative work. How\n",
      "might collaborative work practices change? How might we incor-\n",
      "porate generative AI into shared tools with users’ needs at the\n",
      "forefront? We examine these questions in the context of a remote\n",
      "team conducting ideation tasks – an example of collaborative work\n",
      "enabled by a shared digital workspace. We conducted a user study\n",
      "with 17 professionals experienced with virtual group ideation work-\n",
      "shops. Our study examined their use of the Collaborative Canvas , a\n",
      "virtual canvas tool with integrated generative AI capabilities that\n",
      "we created as a probe. Participants saw value in using generative\n",
      "AI to assist with group facilitation and to augment perspectives\n",
      "and ideas. However, they worried about losing human perspectives\n",
      "and critical thinking, as well as reputational harms resulting from\n",
      "harmful AI outputs. Participants shared suggestions for appropriate\n",
      "ways to incorporate generative AI capabilities within multi-user\n",
      "applications and identified needs for transparency of content own-\n",
      "ership, private digital spaces, and specialized AI capabilities. Based\n",
      "on participants’ insights, we share implications and opportunities\n",
      "for the incorporation of generative AI into collaborative work in\n",
      "ways that place user needs at the forefront.\n",
      "CCS CONCEPTS\n",
      "• Human-centered computing →Empirical studies in HCI ;\n",
      "Empirical studies in collaborative and social computing ; •\n",
      "Computing methodologies →Artificial intelligence.\n",
      "This work is licensed under a Creative Commons Attribution-NonCommercial\n",
      "International 4.0 License.\n",
      "CHIWORK ’24, June 25–27, 2024, Newcastle upon Tyne, United Kingdom\n",
      "© 2024 Copyright held by the owner/author(s).\n",
      "ACM ISBN 979-8-4007-1017-9/24/06\n",
      "https://doi.org/10.1145/3663384.3663398\n",
      "KEYWORDS\n",
      "Group ideation, Brainstorming, Shared virtual canvas, Mixed initia-\n",
      "tive, Generative AI, Future of work\n",
      "ACM Reference Format:\n",
      "Jessica He, Stephanie Houde, Gabriel Enrique Gonzalez, Dario Andres Silva\n",
      "Moran, Steven I. Ross, Michael Muller, and Justin D. Weisz. 2024. AI and\n",
      "the Future of Collaborative Work: Group Ideation with an LLM in a Virtual\n",
      "Canvas. In Proceedings of the 3rd Annual Meeting of the Symposium on\n",
      "Human-Computer Interaction for Work (CHIWORK ’24), June 25–27, 2024,\n",
      "Newcastle upon Tyne, United Kingdom. ACM, New York, NY, USA, 14 pages.\n",
      "https://doi.org/10.1145/3663384.3663398\n",
      "1 INTRODUCTION\n",
      "Generative AI has the potential to automate tasks that were pre-\n",
      "viously thought to be exclusive to humans, raising questions of\n",
      "its impact on the future of work. Rapid advancements in gener-\n",
      "ative AI have already enabled its incorporation into professional\n",
      "work domains such as programming [ 95], research [ 1, 60], and\n",
      "design [41, 57, 113]. In these domains, generative AI can produce\n",
      "ideas, summaries, and suggestions that rival those produced by\n",
      "humans.\n",
      "In the past, many research studies on AI-augmented work have\n",
      "been configured such that one human works with a single AI agent\n",
      "(e.g., [55, 94, 119, 122]). Work by Farrell et al. [26] took an expanded\n",
      "view in which a human works with a back-end collection of AI\n",
      "agents, through a single front-end interface [26]. However, this view\n",
      "does not reflect the reality that work is often performed by groups\n",
      "of colleagues working together [104, 116, 127]. As advancements in\n",
      "generative AI make their way into collaborative domains, there is a\n",
      "need to shift our view to realistic work contexts in which multiple\n",
      "humans interact with each other along with AI agents.\n",
      "One indication of the rise of AI-supported group work is in the\n",
      "introduction of generative AI features to digital canvas tools such as\n",
      "Mural1, Miro2, and Microsoft Whiteboard3. These features include\n",
      "1Mural. https://mural.co\n",
      "2Miro. https://miro.com\n",
      "3Microsoft Whiteboard. https://whiteboard.microsoft.com' metadata={'producer': 'pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5; modified using iText 4.2.0 by 1T3XT', 'creator': 'LaTeX with acmart 2024/04/17 v2.07 Typesetting articles for the Association for Computing Machinery and hyperref 2023-02-07 v7.00v Hypertext links for LaTeX', 'creationdate': '2024-05-06T19:54:44+00:00', 'moddate': '2025-03-20T06:29:09-07:00', 'trapped': '/False', 'subject': '-  Human-centered computing  ->  Empirical studies in HCI.Empirical studies in collaborative and social computing.-  Computing methodologies  ->  Artificial intelligence.', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'title': 'AI and the Future of Collaborative Work: Group Ideation with an LLM in a Virtual Canvas', 'source': 'uploads/9102c4fe-1c59-40dd-b170-cb3976a36874.pdf', 'total_pages': 14, 'page': 0, 'page_label': '1'}\n",
      "Loaded 17 pages from bf798843-8e18-45b7-bd9b-1751d4d6212f.pdf\n",
      "\n",
      "\n",
      "page_content='Evaluation and Facilitation of Online Discussions in the LLM Era:\n",
      "A Survey\n",
      "Katerina Korre†⋆ , Dimitris Tsirmpas†‡ , Nikos Gkoumas† , Emma Cabalé♢\n",
      "Dionysios Kontarinis†, Danai Myrtzani‡ , Theodoros Evgeniou♠\n",
      "Ion Androutsopoulos‡†, John Pavlopoulos‡†\n",
      "†Archimedes/Athena RC, Greece (n.goumas@athenarc.gr, denniskont@gmail.com)\n",
      "‡Athens University of Economics and Business, Greece ({dim.tsirmpas,dan.myrtzani,ion,annis}@aueb.gr)\n",
      "♢École Normale Supérieure Paris-Saclay, France (emma.cabale@ens-paris-saclay.fr)\n",
      "♠INSEAD, Technology and Business, France (theodoros.evgeniou@insead.edu)\n",
      "⋆Università di Bologna, Italy (aikaterini.korre2@unibo.it)\n",
      "Abstract\n",
      "We present a survey of methods for assessing\n",
      "and enhancing the quality of online discussions,\n",
      "focusing on the potential of Large Language\n",
      "Models (LLMs). While online discourses aim,\n",
      "at least in theory, to foster mutual understand-\n",
      "ing, they often devolve into harmful exchanges,\n",
      "such as hate speech, threatening social cohe-\n",
      "sion and democratic values. Recent advance-\n",
      "ments in LLMs enable facilitation agents that\n",
      "not only moderate content, but also actively\n",
      "improve the quality of interactions. Our sur-\n",
      "vey synthesizes ideas from Natural Language\n",
      "Processing (NLP) and Social Sciences to pro-\n",
      "vide (a) a new taxonomy on discussion quality\n",
      "evaluation, (b) an overview of intervention and\n",
      "facilitation strategies, along with a new taxon-\n",
      "omy on conversation facilitation datasets, (c) an\n",
      "LLM-oriented roadmap of good practices and\n",
      "future research directions, from technological\n",
      "and societal perspectives.\n",
      "1 Introduction\n",
      "Discussions, especially of complex or controver-\n",
      "sial topics, are a cornerstone of collective decision-\n",
      "making (Burton et al., 2024). In contrast to initial\n",
      "hopes of promoting mutual understanding (Rhein-\n",
      "gold, 2000), online discussions (especially in social\n",
      "media) often degenerate into hate speech, personal\n",
      "attacks, promoting conspiracy theories or propa-\n",
      "ganda – to the extent that they can even be con-\n",
      "sidered a threat to social cohesion and democracy\n",
      "(Tucker et al., 2018; Mathew et al., 2019).\n",
      "Natural Language Processing ( NLP) and\n",
      "Machine Learning (ML) can potentially help im-\n",
      "prove the quality of online discussions. For exam-\n",
      "ple, automatic classifiers (Bang et al., 2023; Molina\n",
      "and Sundar, 2022) are already being used to help or\n",
      "even replace human moderators, by flagging posts\n",
      "that violate the law or policies of online discussion\n",
      "fora (Saeidi et al., 2021).\n",
      "Social Science provides theories and applica-\n",
      "tions for the facilitation of a discussion, but in\n",
      "specific contexts, such as teaching/learning (Man-\n",
      "sour, 2024) or clinical discussions (Gelula, 1997),\n",
      "without much research conducted for thread-like\n",
      "discussions.\n",
      "Improving the quality of online discussions pre-\n",
      "supposes being able to define and measure discus-\n",
      "sion quality. Here, work from Social Science, but\n",
      "also Argument Mining (AM) (Lapesa et al., 2024),\n",
      "can again provide several ideas on dimensions (as-\n",
      "pects) of discussion quality, such as logical co-\n",
      "hesion and constructiveness, as well as ideas on\n",
      "methods to measure quality along each dimension.\n",
      "This paper surveys research from Social Sci-\n",
      "ence and relevant NLP areas (e.g., AM, Senti-\n",
      "ment Analysis, Toxicity Detection), focusing on\n",
      "how Large Language Models (LLMs) can facilitate\n",
      "human discussions—similar to human facilitators\n",
      "(Kahane, 2013). While prior studies have explored\n",
      "LLM-facilitated discussions (Burton et al., 2024;\n",
      "Aher et al., 2023; Beck et al., 2024; Schroeder\n",
      "et al., 2024; Small et al., 2023; Cho et al., 2024),\n",
      "their connection to Social Science remains underex-\n",
      "plored. In this survey, we include methods from So-\n",
      "cial Science (e.g., linguistics) when discussing ap-\n",
      "proaches for evaluating online discussions, as well\n",
      "as when exploring intervention strategies (e.g., fa-\n",
      "cilitative tactics). LLM-based facilitation again pre-\n",
      "supposes defining and evaluating discussion qual-\n",
      "ity. This is even more necessary in the case of\n",
      "LLMs, because of their rapid deployment, poten-\n",
      "tial biases, and long-term societal consequences.\n",
      "Without continuous and thorough assessment, we\n",
      "risk implementing LLM-based facilitation systems\n",
      "that may be ineffective, biased, or even harmful,\n",
      "before their full implications are understood.\n",
      "Therefore, we survey discussion evaluation as-\n",
      "pects and their feasibility with LLMs, introducing\n",
      "a new taxonomy inspired by deliberation studies.\n",
      "We map tasks suited for ML models, LLMs, and\n",
      "humans, aggregate multidimensional insights on\n",
      "facilitation strategies, and outline future capabil-\n",
      "1\n",
      "arXiv:2503.01513v1  [cs.CL]  3 Mar 2025' metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2025-03-04T03:13:50+00:00', 'author': '', 'keywords': '', 'moddate': '2025-03-04T03:13:50+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'subject': '', 'title': '', 'trapped': '/False', 'source': 'uploads/bf798843-8e18-45b7-bd9b-1751d4d6212f.pdf', 'total_pages': 17, 'page': 0, 'page_label': '1'}\n",
      "Loaded 14 pages from e92516ec-0488-43ba-b761-10b53e08dd61.pdf\n",
      "\n",
      "\n",
      "page_content='AI and the Future of Collaborative Work: Group Ideation with an\n",
      "LLM in a Virtual Canvas\n",
      "Jessica He\n",
      "IBM Research AI\n",
      "Seattle, USA\n",
      "jessicahe@ibm.com\n",
      "Stephanie Houde\n",
      "IBM Research AI\n",
      "Cambridge, USA\n",
      "Stephanie.Houde@ibm.com\n",
      "Gabriel Enrique Gonzalez\n",
      "IBM Argentina\n",
      "Necochea, Argentina\n",
      "gabriel.gonzalez@ibm.com\n",
      "Dario Andres Silva Moran\n",
      "IBM Argentina\n",
      "La Plata, Argentina\n",
      "dario.silva@ibm.com\n",
      "Steven I. Ross\n",
      "IBM Research AI\n",
      "Cambridge, USA\n",
      "steven_ross@us.ibm.com\n",
      "Michael Muller\n",
      "IBM Research AI\n",
      "Cambridge, USA\n",
      "michael_muller@us.ibm.com\n",
      "Justin D. Weisz\n",
      "IBM Research AI\n",
      "Yorktown Heights, USA\n",
      "jweisz@us.ibm.com\n",
      "ABSTRACT\n",
      "The introduction of generative AI into multi-user applications raises\n",
      "novel considerations for the future of collaborative work. How\n",
      "might collaborative work practices change? How might we incor-\n",
      "porate generative AI into shared tools with users’ needs at the\n",
      "forefront? We examine these questions in the context of a remote\n",
      "team conducting ideation tasks – an example of collaborative work\n",
      "enabled by a shared digital workspace. We conducted a user study\n",
      "with 17 professionals experienced with virtual group ideation work-\n",
      "shops. Our study examined their use of the Collaborative Canvas , a\n",
      "virtual canvas tool with integrated generative AI capabilities that\n",
      "we created as a probe. Participants saw value in using generative\n",
      "AI to assist with group facilitation and to augment perspectives\n",
      "and ideas. However, they worried about losing human perspectives\n",
      "and critical thinking, as well as reputational harms resulting from\n",
      "harmful AI outputs. Participants shared suggestions for appropriate\n",
      "ways to incorporate generative AI capabilities within multi-user\n",
      "applications and identified needs for transparency of content own-\n",
      "ership, private digital spaces, and specialized AI capabilities. Based\n",
      "on participants’ insights, we share implications and opportunities\n",
      "for the incorporation of generative AI into collaborative work in\n",
      "ways that place user needs at the forefront.\n",
      "CCS CONCEPTS\n",
      "• Human-centered computing →Empirical studies in HCI ;\n",
      "Empirical studies in collaborative and social computing ; •\n",
      "Computing methodologies →Artificial intelligence.\n",
      "This work is licensed under a Creative Commons Attribution-NonCommercial\n",
      "International 4.0 License.\n",
      "CHIWORK ’24, June 25–27, 2024, Newcastle upon Tyne, United Kingdom\n",
      "© 2024 Copyright held by the owner/author(s).\n",
      "ACM ISBN 979-8-4007-1017-9/24/06\n",
      "https://doi.org/10.1145/3663384.3663398\n",
      "KEYWORDS\n",
      "Group ideation, Brainstorming, Shared virtual canvas, Mixed initia-\n",
      "tive, Generative AI, Future of work\n",
      "ACM Reference Format:\n",
      "Jessica He, Stephanie Houde, Gabriel Enrique Gonzalez, Dario Andres Silva\n",
      "Moran, Steven I. Ross, Michael Muller, and Justin D. Weisz. 2024. AI and\n",
      "the Future of Collaborative Work: Group Ideation with an LLM in a Virtual\n",
      "Canvas. In Proceedings of the 3rd Annual Meeting of the Symposium on\n",
      "Human-Computer Interaction for Work (CHIWORK ’24), June 25–27, 2024,\n",
      "Newcastle upon Tyne, United Kingdom. ACM, New York, NY, USA, 14 pages.\n",
      "https://doi.org/10.1145/3663384.3663398\n",
      "1 INTRODUCTION\n",
      "Generative AI has the potential to automate tasks that were pre-\n",
      "viously thought to be exclusive to humans, raising questions of\n",
      "its impact on the future of work. Rapid advancements in gener-\n",
      "ative AI have already enabled its incorporation into professional\n",
      "work domains such as programming [ 95], research [ 1, 60], and\n",
      "design [41, 57, 113]. In these domains, generative AI can produce\n",
      "ideas, summaries, and suggestions that rival those produced by\n",
      "humans.\n",
      "In the past, many research studies on AI-augmented work have\n",
      "been configured such that one human works with a single AI agent\n",
      "(e.g., [55, 94, 119, 122]). Work by Farrell et al. [26] took an expanded\n",
      "view in which a human works with a back-end collection of AI\n",
      "agents, through a single front-end interface [26]. However, this view\n",
      "does not reflect the reality that work is often performed by groups\n",
      "of colleagues working together [104, 116, 127]. As advancements in\n",
      "generative AI make their way into collaborative domains, there is a\n",
      "need to shift our view to realistic work contexts in which multiple\n",
      "humans interact with each other along with AI agents.\n",
      "One indication of the rise of AI-supported group work is in the\n",
      "introduction of generative AI features to digital canvas tools such as\n",
      "Mural1, Miro2, and Microsoft Whiteboard3. These features include\n",
      "1Mural. https://mural.co\n",
      "2Miro. https://miro.com\n",
      "3Microsoft Whiteboard. https://whiteboard.microsoft.com' metadata={'producer': 'pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5; modified using iText 4.2.0 by 1T3XT', 'creator': 'LaTeX with acmart 2024/04/17 v2.07 Typesetting articles for the Association for Computing Machinery and hyperref 2023-02-07 v7.00v Hypertext links for LaTeX', 'creationdate': '2024-05-06T19:54:44+00:00', 'moddate': '2025-03-20T06:29:09-07:00', 'trapped': '/False', 'subject': '-  Human-centered computing  ->  Empirical studies in HCI.Empirical studies in collaborative and social computing.-  Computing methodologies  ->  Artificial intelligence.', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'title': 'AI and the Future of Collaborative Work: Group Ideation with an LLM in a Virtual Canvas', 'source': 'uploads/e92516ec-0488-43ba-b761-10b53e08dd61.pdf', 'total_pages': 14, 'page': 0, 'page_label': '1'}\n",
      "Loaded 14 pages from 87c8c578-e0bb-4081-a85e-4de936bc73cd.pdf\n",
      "\n",
      "\n",
      "page_content='See discussions, stats, and author profiles for this publication at: https://www.researchgate.net/publication/384228166\n",
      "How large language models can reshape collective intelligence\n",
      "Article  in   Nature Human Behaviour · September 2024\n",
      "DOI: 10.1038/s41562-024-01959-9\n",
      "CITATIONS\n",
      "27\n",
      "READS\n",
      "3,000\n",
      "28 authors, including:\n",
      "Jason Burton\n",
      "Copenhagen Business School\n",
      "11 PUBLICATIONS   646 CITATIONS   \n",
      "SEE PROFILE\n",
      "Ezequiel Lopez-Lopez\n",
      "Max Planck Institute for Human Development\n",
      "5 PUBLICATIONS   28 CITATIONS   \n",
      "SEE PROFILE\n",
      "Zoe Rahwan\n",
      "Max Planck Institute for Human Development\n",
      "13 PUBLICATIONS   115 CITATIONS   \n",
      "SEE PROFILE\n",
      "Samuel Aeschbach\n",
      "University of Basel\n",
      "8 PUBLICATIONS   103 CITATIONS   \n",
      "SEE PROFILE\n",
      "All content following this page was uploaded by Taha Yasseri on 25 September 2024.\n",
      "The user has requested enhancement of the downloaded file.' metadata={'producer': 'PyPDF', 'creator': 'Springer', 'creationdate': '2024-09-16T16:43:21+05:30', 'author': 'Jason W. Burton', 'crossmarkdomains[1]': 'springer.com', 'crossmarkdomains[2]': 'springerlink.com', 'keywords': '', 'moddate': '2024-09-16T16:44:15+05:30', 'subject': 'Nature Human Behaviour, doi:10.1038/s41562-024-01959-9', 'title': 'How large language models can reshape collective intelligence', 'doi': '10.1038/s41562-024-01959-9', 'rgid': 'PB:384228166_AS:11431281279985736@1727266110169', 'source': 'uploads/87c8c578-e0bb-4081-a85e-4de936bc73cd.pdf', 'total_pages': 14, 'page': 0, 'page_label': '1'}\n",
      "Loaded 17 pages from ab84c804-452e-4753-aae2-880fed297436.pdf\n",
      "\n",
      "\n",
      "page_content='Evaluation and Facilitation of Online Discussions in the LLM Era:\n",
      "A Survey\n",
      "Katerina Korre†⋆ , Dimitris Tsirmpas†‡ , Nikos Gkoumas† , Emma Cabalé♢\n",
      "Dionysios Kontarinis†, Danai Myrtzani‡ , Theodoros Evgeniou♠\n",
      "Ion Androutsopoulos‡†, John Pavlopoulos‡†\n",
      "†Archimedes/Athena RC, Greece (n.goumas@athenarc.gr, denniskont@gmail.com)\n",
      "‡Athens University of Economics and Business, Greece ({dim.tsirmpas,dan.myrtzani,ion,annis}@aueb.gr)\n",
      "♢École Normale Supérieure Paris-Saclay, France (emma.cabale@ens-paris-saclay.fr)\n",
      "♠INSEAD, Technology and Business, France (theodoros.evgeniou@insead.edu)\n",
      "⋆Università di Bologna, Italy (aikaterini.korre2@unibo.it)\n",
      "Abstract\n",
      "We present a survey of methods for assessing\n",
      "and enhancing the quality of online discussions,\n",
      "focusing on the potential of Large Language\n",
      "Models (LLMs). While online discourses aim,\n",
      "at least in theory, to foster mutual understand-\n",
      "ing, they often devolve into harmful exchanges,\n",
      "such as hate speech, threatening social cohe-\n",
      "sion and democratic values. Recent advance-\n",
      "ments in LLMs enable facilitation agents that\n",
      "not only moderate content, but also actively\n",
      "improve the quality of interactions. Our sur-\n",
      "vey synthesizes ideas from Natural Language\n",
      "Processing (NLP) and Social Sciences to pro-\n",
      "vide (a) a new taxonomy on discussion quality\n",
      "evaluation, (b) an overview of intervention and\n",
      "facilitation strategies, along with a new taxon-\n",
      "omy on conversation facilitation datasets, (c) an\n",
      "LLM-oriented roadmap of good practices and\n",
      "future research directions, from technological\n",
      "and societal perspectives.\n",
      "1 Introduction\n",
      "Discussions, especially of complex or controver-\n",
      "sial topics, are a cornerstone of collective decision-\n",
      "making (Burton et al., 2024). In contrast to initial\n",
      "hopes of promoting mutual understanding (Rhein-\n",
      "gold, 2000), online discussions (especially in social\n",
      "media) often degenerate into hate speech, personal\n",
      "attacks, promoting conspiracy theories or propa-\n",
      "ganda – to the extent that they can even be con-\n",
      "sidered a threat to social cohesion and democracy\n",
      "(Tucker et al., 2018; Mathew et al., 2019).\n",
      "Natural Language Processing ( NLP) and\n",
      "Machine Learning (ML) can potentially help im-\n",
      "prove the quality of online discussions. For exam-\n",
      "ple, automatic classifiers (Bang et al., 2023; Molina\n",
      "and Sundar, 2022) are already being used to help or\n",
      "even replace human moderators, by flagging posts\n",
      "that violate the law or policies of online discussion\n",
      "fora (Saeidi et al., 2021).\n",
      "Social Science provides theories and applica-\n",
      "tions for the facilitation of a discussion, but in\n",
      "specific contexts, such as teaching/learning (Man-\n",
      "sour, 2024) or clinical discussions (Gelula, 1997),\n",
      "without much research conducted for thread-like\n",
      "discussions.\n",
      "Improving the quality of online discussions pre-\n",
      "supposes being able to define and measure discus-\n",
      "sion quality. Here, work from Social Science, but\n",
      "also Argument Mining (AM) (Lapesa et al., 2024),\n",
      "can again provide several ideas on dimensions (as-\n",
      "pects) of discussion quality, such as logical co-\n",
      "hesion and constructiveness, as well as ideas on\n",
      "methods to measure quality along each dimension.\n",
      "This paper surveys research from Social Sci-\n",
      "ence and relevant NLP areas (e.g., AM, Senti-\n",
      "ment Analysis, Toxicity Detection), focusing on\n",
      "how Large Language Models (LLMs) can facilitate\n",
      "human discussions—similar to human facilitators\n",
      "(Kahane, 2013). While prior studies have explored\n",
      "LLM-facilitated discussions (Burton et al., 2024;\n",
      "Aher et al., 2023; Beck et al., 2024; Schroeder\n",
      "et al., 2024; Small et al., 2023; Cho et al., 2024),\n",
      "their connection to Social Science remains underex-\n",
      "plored. In this survey, we include methods from So-\n",
      "cial Science (e.g., linguistics) when discussing ap-\n",
      "proaches for evaluating online discussions, as well\n",
      "as when exploring intervention strategies (e.g., fa-\n",
      "cilitative tactics). LLM-based facilitation again pre-\n",
      "supposes defining and evaluating discussion qual-\n",
      "ity. This is even more necessary in the case of\n",
      "LLMs, because of their rapid deployment, poten-\n",
      "tial biases, and long-term societal consequences.\n",
      "Without continuous and thorough assessment, we\n",
      "risk implementing LLM-based facilitation systems\n",
      "that may be ineffective, biased, or even harmful,\n",
      "before their full implications are understood.\n",
      "Therefore, we survey discussion evaluation as-\n",
      "pects and their feasibility with LLMs, introducing\n",
      "a new taxonomy inspired by deliberation studies.\n",
      "We map tasks suited for ML models, LLMs, and\n",
      "humans, aggregate multidimensional insights on\n",
      "facilitation strategies, and outline future capabil-\n",
      "1\n",
      "arXiv:2503.01513v1  [cs.CL]  3 Mar 2025' metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2025-03-04T03:13:50+00:00', 'author': '', 'keywords': '', 'moddate': '2025-03-04T03:13:50+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'subject': '', 'title': '', 'trapped': '/False', 'source': 'uploads/ab84c804-452e-4753-aae2-880fed297436.pdf', 'total_pages': 17, 'page': 0, 'page_label': '1'}\n",
      "Loaded 26 pages from 3dd01866-6102-42e0-91e6-37b8b3b33940.pdf\n",
      "\n",
      "\n",
      "page_content='LM Agents for Coordinating Multi-User Information Gathering\n",
      "Harsh Jhamtani, Jacob Andreas, Benjamin Van Durme\n",
      "Microsoft\n",
      "{hjhamtani,jaandrea,ben.vandurme}@microsoft.com\n",
      "Abstract\n",
      "This paper introduces PEOPLE JOIN , a bench-\n",
      "mark for evaluating LM-mediated collaborative\n",
      "problem solving. Given a user request, PEO-\n",
      "PLE JOIN agents must identify teammates who\n",
      "might be able to assist, converse with these\n",
      "teammates to gather information, and finally\n",
      "compile a useful answer or summary for the\n",
      "original user. PEOPLE JOIN comprises two eval-\n",
      "uation domains: PEOPLE JOIN -QA, focused on\n",
      "questions about tabular data, and PEOPLE JOIN -\n",
      "DOCCREATION , focused on document creation\n",
      "tasks. The two domains are adapted from ex-\n",
      "isting NLP benchmarks for database question\n",
      "answering and multi-document summarization;\n",
      "here, however, the information needed to com-\n",
      "plete these tasks is distributed across synthetic\n",
      "“organizations” of 2–20 users, simulating natu-\n",
      "ral multi-user collaboration scenarios. We im-\n",
      "plemented several popular LM agent architec-\n",
      "tures, evaluating their accuracy and efficiency\n",
      "at completing tasks, and highlight new research\n",
      "questions that can be studied using PEOPLE -\n",
      "JOIN .1\n",
      "1 Introduction\n",
      "In today’s fast-paced and interconnected world,\n",
      "effective collaboration is essential for achieving\n",
      "complex tasks and making informed decisions\n",
      "(Papachristou et al., 2023; Gemp et al., 2024).\n",
      "Many decision-making, content creation, and\n",
      "information-gathering tasks require collecting in-\n",
      "formation from multiple people. For example,\n",
      "preparing a list of interns across teams in an or-\n",
      "ganization by reaching out to the leader of each\n",
      "team; preparing a newsletter for project updates\n",
      "might necessitate coordinating with multiple con-\n",
      "tributors; identifying a suitable time to meet might\n",
      "require several rounds of negotiations (Lin et al.,\n",
      "2024). Identifying what information is available,\n",
      "1Code and data can be found at https://github.com/\n",
      "microsoft/peoplejoin/\n",
      "judiciously determining who to contact, asking pre-\n",
      "cise questions, and compiling research results can\n",
      "be a challenging and time-consuming process—\n",
      "especially when real-time interaction between team\n",
      "members is difficult to coordinate.\n",
      "At the same time, recent large language mod-\n",
      "els (LLMs), such as GPT-4 (OpenAI, 2023), Phi-3\n",
      "(Abdin et al., 2024), LLaMa (Touvron et al., 2023),\n",
      "and Gemini (Team et al., 2023), are becoming a cru-\n",
      "cial building block in developing automated agents\n",
      "that can assist human users with complex tasks\n",
      "(Xi et al., 2023; Wang et al., 2024; Butler et al.,\n",
      "2023). These tasks include chat applications for\n",
      "assisting individual users with searching and sum-\n",
      "marizing information (such as in Microsoft Copilot\n",
      "Chat2), and even supporting these users in work-\n",
      "place decision-making (Butler et al., 2023; Kim\n",
      "and Hsu, 2024). Could these agents be extended to\n",
      "improve collaboration among multiple users?\n",
      "In this paper, we introduce PEOPLE JOIN , an\n",
      "evaluation framework for studying effectiveness\n",
      "of LLM-powered agents to assist with multi-user\n",
      "collaboration tasks. Each PEOPLE JOIN task takes\n",
      "place within a fictitious organization with 2–20\n",
      "employees, some of whom possess a collection of\n",
      "documents necessary to solve some task. One of\n",
      "the users (the initiating user) communicates the\n",
      "task to an agent (Fig. 1). Agents have direct ac-\n",
      "cess to the initiating user’s documents, and can\n",
      "engage in conversations with other users to gather\n",
      "relevant information. They must rely on limited\n",
      "descriptions of other users, and potentially previ-\n",
      "ous interactions, to determine who to contact for a\n",
      "given task. PEOPLE JOIN comprises two families\n",
      "of tasks: PEOPLE JOIN -QA and PEOPLE JOIN -\n",
      "DOCCREATION , derived from the SPIDER (Yu\n",
      "et al., 2018) and MULTINEWS (Fabbri et al., 2019)\n",
      "datasets respectively. It evaluates agents’ ability\n",
      "to answer questions involving complex relational\n",
      "2https://copilot.microsoft.com/\n",
      "arXiv:2502.12328v1  [cs.CL]  17 Feb 2025' metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2025-02-19T01:08:14+00:00', 'author': '', 'keywords': '', 'moddate': '2025-02-19T01:08:14+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'subject': '', 'title': '', 'trapped': '/False', 'source': 'uploads/3dd01866-6102-42e0-91e6-37b8b3b33940.pdf', 'total_pages': 26, 'page': 0, 'page_label': '1'}\n",
      "Loaded 5 pages from 89fcf830-0965-40e2-9d81-5c88ea5b13f2.pdf\n",
      "\n",
      "\n",
      "page_content='Amplifying Minority Voices: AI-Mediated Devil’s Advocate\n",
      "System for Inclusive Group Decision-Making\n",
      "Soohwan Lee∗\n",
      "Department of Design, UNIST\n",
      "Ulsan, Republic of Korea\n",
      "soohwanlee@unist.ac.kr\n",
      "Mingyu Kim∗\n",
      "Department of Design, UNIST\n",
      "Ulsan, Republic of Korea\n",
      "gyu7991@unist.ac.kr\n",
      "Seoyeong Hwang\n",
      "Department of Design, UNIST\n",
      "Ulsan, Republic of Korea\n",
      "hseoyeong@unist.ac.kr\n",
      "Dajung Kim\n",
      "Department of Design, UNIST\n",
      "Ulsan, Republic of Korea\n",
      "dajungkim@unist.ac.kr\n",
      "Kyungho Lee\n",
      "Department of Design, UNIST\n",
      "Ulsan, Republic of Korea\n",
      "kyungho@unist.ac.kr\n",
      "T h e  M a j o r i t y  ( ≥ 3 )\n",
      "w i t h  H i g h  P o w e r\n",
      "T h e  M i n o r i t y\n",
      "w i t h  L o w  P o w e r\n",
      "C o m p l i a n c e\n",
      "L L M - p o w e r e d\n",
      "D e v i l ’ s  A d v o c a t e\n",
      "S o c i a l\n",
      "I n f l u e n c e\n",
      "Figure 1: Mitigating Social Influence with an LLM-powered Devil’s Advocate. Minority members often conform to majority\n",
      "opinions due to social pressure. Our system allows minorities to share different opinions with an LLM-powered Devil’s Advocate,\n",
      "which reframes and presents them as its own. This increases psychological safety, mitigates bias, and fosters critical discussion.\n",
      "Abstract\n",
      "Group decision-making often benefits from diverse perspectives, yet\n",
      "power imbalances and social influence can stifle minority opinions\n",
      "and compromise outcomes. This prequel introduces an AI-mediated\n",
      "communication system that leverages the Large Language Model\n",
      "to serve as a devil’s advocate, representing underrepresented view-\n",
      "points without exposing minority members’ identities. Rooted in\n",
      "persuasive communication strategies and anonymity, the system\n",
      "aims to improve psychological safety and foster more inclusive\n",
      "decision-making. Our multi-agent architecture, which consists of\n",
      "∗Equally contributed to this work.\n",
      "Permission to make digital or hard copies of all or part of this work for personal or\n",
      "classroom use is granted without fee provided that copies are not made or distributed\n",
      "for profit or commercial advantage and that copies bear this notice and the full citation\n",
      "on the first page. Copyrights for third-party components of this work must be honored.\n",
      "For all other uses, contact the owner/author(s).\n",
      "IUI Companion ’25, March 24–27, 2025, Cagliari, Italy\n",
      "© 2025 Copyright held by the owner/author(s).\n",
      "ACM ISBN 979-8-4007-1409-2/25/03\n",
      "https://doi.org/10.1145/3708557.3716334\n",
      "a summary agent, conversation agent, AI duplicate checker, and\n",
      "paraphrase agent, encourages the group’s critical thinking while\n",
      "reducing repetitive outputs. We acknowledge that reliance on text-\n",
      "based communication and fixed intervention timings may limit\n",
      "adaptability, indicating pathways for refinement. By focusing on\n",
      "the representation of minority viewpoints anonymously in power-\n",
      "imbalanced settings, this approach highlights how AI-driven meth-\n",
      "ods can evolve to support more divergent and inclusive group\n",
      "decision-making.\n",
      "CCS Concepts\n",
      "• Human-centered computing → Collaborative interaction;\n",
      "Collaborative and social computing systems and tools .\n",
      "Keywords\n",
      "AI-mediated Communication; AI-assisted Decision-making, Group\n",
      "Dynamics, Social Influence, Compliance, LLM\n",
      "arXiv:2502.06251v1  [cs.HC]  10 Feb 2025' metadata={'producer': 'pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'creator': 'LaTeX with acmart 2024/05/27 v2.08 Typesetting articles for the Association for Computing Machinery and hyperref 2023-04-22 v7.00x Hypertext links for LaTeX', 'creationdate': '2025-02-11T02:22:50+00:00', 'moddate': '2025-02-11T02:22:50+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'subject': '-  Human-centered computing  ->  Collaborative interaction.Collaborative and social computing systems and tools.', 'title': \"Amplifying Minority Voices: AI-Mediated Devil's Advocate System for Inclusive Group Decision-Making\", 'trapped': '/False', 'source': 'uploads/89fcf830-0965-40e2-9d81-5c88ea5b13f2.pdf', 'total_pages': 5, 'page': 0, 'page_label': '1'}\n",
      "Loaded 17 pages from 24416b95-ccae-4a69-81cf-50c03382514d.pdf\n",
      "\n",
      "\n",
      "page_content='Evaluation and Facilitation of Online Discussions in the LLM Era:\n",
      "A Survey\n",
      "Katerina Korre†⋆ , Dimitris Tsirmpas†‡ , Nikos Gkoumas† , Emma Cabalé♢\n",
      "Dionysios Kontarinis†, Danai Myrtzani‡ , Theodoros Evgeniou♠\n",
      "Ion Androutsopoulos‡†, John Pavlopoulos‡†\n",
      "†Archimedes/Athena RC, Greece (n.goumas@athenarc.gr, denniskont@gmail.com)\n",
      "‡Athens University of Economics and Business, Greece ({dim.tsirmpas,dan.myrtzani,ion,annis}@aueb.gr)\n",
      "♢École Normale Supérieure Paris-Saclay, France (emma.cabale@ens-paris-saclay.fr)\n",
      "♠INSEAD, Technology and Business, France (theodoros.evgeniou@insead.edu)\n",
      "⋆Università di Bologna, Italy (aikaterini.korre2@unibo.it)\n",
      "Abstract\n",
      "We present a survey of methods for assessing\n",
      "and enhancing the quality of online discussions,\n",
      "focusing on the potential of Large Language\n",
      "Models (LLMs). While online discourses aim,\n",
      "at least in theory, to foster mutual understand-\n",
      "ing, they often devolve into harmful exchanges,\n",
      "such as hate speech, threatening social cohe-\n",
      "sion and democratic values. Recent advance-\n",
      "ments in LLMs enable facilitation agents that\n",
      "not only moderate content, but also actively\n",
      "improve the quality of interactions. Our sur-\n",
      "vey synthesizes ideas from Natural Language\n",
      "Processing (NLP) and Social Sciences to pro-\n",
      "vide (a) a new taxonomy on discussion quality\n",
      "evaluation, (b) an overview of intervention and\n",
      "facilitation strategies, along with a new taxon-\n",
      "omy on conversation facilitation datasets, (c) an\n",
      "LLM-oriented roadmap of good practices and\n",
      "future research directions, from technological\n",
      "and societal perspectives.\n",
      "1 Introduction\n",
      "Discussions, especially of complex or controver-\n",
      "sial topics, are a cornerstone of collective decision-\n",
      "making (Burton et al., 2024). In contrast to initial\n",
      "hopes of promoting mutual understanding (Rhein-\n",
      "gold, 2000), online discussions (especially in social\n",
      "media) often degenerate into hate speech, personal\n",
      "attacks, promoting conspiracy theories or propa-\n",
      "ganda – to the extent that they can even be con-\n",
      "sidered a threat to social cohesion and democracy\n",
      "(Tucker et al., 2018; Mathew et al., 2019).\n",
      "Natural Language Processing ( NLP) and\n",
      "Machine Learning (ML) can potentially help im-\n",
      "prove the quality of online discussions. For exam-\n",
      "ple, automatic classifiers (Bang et al., 2023; Molina\n",
      "and Sundar, 2022) are already being used to help or\n",
      "even replace human moderators, by flagging posts\n",
      "that violate the law or policies of online discussion\n",
      "fora (Saeidi et al., 2021).\n",
      "Social Science provides theories and applica-\n",
      "tions for the facilitation of a discussion, but in\n",
      "specific contexts, such as teaching/learning (Man-\n",
      "sour, 2024) or clinical discussions (Gelula, 1997),\n",
      "without much research conducted for thread-like\n",
      "discussions.\n",
      "Improving the quality of online discussions pre-\n",
      "supposes being able to define and measure discus-\n",
      "sion quality. Here, work from Social Science, but\n",
      "also Argument Mining (AM) (Lapesa et al., 2024),\n",
      "can again provide several ideas on dimensions (as-\n",
      "pects) of discussion quality, such as logical co-\n",
      "hesion and constructiveness, as well as ideas on\n",
      "methods to measure quality along each dimension.\n",
      "This paper surveys research from Social Sci-\n",
      "ence and relevant NLP areas (e.g., AM, Senti-\n",
      "ment Analysis, Toxicity Detection), focusing on\n",
      "how Large Language Models (LLMs) can facilitate\n",
      "human discussions—similar to human facilitators\n",
      "(Kahane, 2013). While prior studies have explored\n",
      "LLM-facilitated discussions (Burton et al., 2024;\n",
      "Aher et al., 2023; Beck et al., 2024; Schroeder\n",
      "et al., 2024; Small et al., 2023; Cho et al., 2024),\n",
      "their connection to Social Science remains underex-\n",
      "plored. In this survey, we include methods from So-\n",
      "cial Science (e.g., linguistics) when discussing ap-\n",
      "proaches for evaluating online discussions, as well\n",
      "as when exploring intervention strategies (e.g., fa-\n",
      "cilitative tactics). LLM-based facilitation again pre-\n",
      "supposes defining and evaluating discussion qual-\n",
      "ity. This is even more necessary in the case of\n",
      "LLMs, because of their rapid deployment, poten-\n",
      "tial biases, and long-term societal consequences.\n",
      "Without continuous and thorough assessment, we\n",
      "risk implementing LLM-based facilitation systems\n",
      "that may be ineffective, biased, or even harmful,\n",
      "before their full implications are understood.\n",
      "Therefore, we survey discussion evaluation as-\n",
      "pects and their feasibility with LLMs, introducing\n",
      "a new taxonomy inspired by deliberation studies.\n",
      "We map tasks suited for ML models, LLMs, and\n",
      "humans, aggregate multidimensional insights on\n",
      "facilitation strategies, and outline future capabil-\n",
      "1\n",
      "arXiv:2503.01513v1  [cs.CL]  3 Mar 2025' metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2025-03-04T03:13:50+00:00', 'author': '', 'keywords': '', 'moddate': '2025-03-04T03:13:50+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'subject': '', 'title': '', 'trapped': '/False', 'source': 'uploads/24416b95-ccae-4a69-81cf-50c03382514d.pdf', 'total_pages': 17, 'page': 0, 'page_label': '1'}\n",
      "Loaded 22 pages from d8c8c918-8f5a-43c4-9f21-757758298fef.pdf\n",
      "\n",
      "\n",
      "page_content='Technology in Society 78 (2024) 102662\n",
      "Available online 17 July 2024\n",
      "0160-791X/© 2024 The Authors. Published by Elsevier Ltd. This is an open access article under the CC BY-NC-ND license (http://creativecommons.org/licenses/by-\n",
      "nc-nd/4.0/).\n",
      "Exploring collaborative decision-making: A quasi-experimental study of\n",
      "human and Generative AI interaction\n",
      "Xinyue Hao\n",
      "*\n",
      ", Emrah Demir , Daniel Eyers\n",
      "Logistics & Operations Management Section, Cardiff Business School, Cardiff University, Cardiff CF10 3EU, United Kingdom\n",
      "ARTICLE INFO\n",
      "Keywords:\n",
      "ChatGPT\n",
      "Artificial intelligence\n",
      "Human intuition\n",
      "Decision-making\n",
      "Cognitive biases\n",
      "ABSTRACT\n",
      "This paper explores the effects of integrating Generative Artificial Intelligence (GAI) into decision-making pro-\n",
      "cesses within organizations, employing a quasi-experimental pretest-posttest design. The study examines the\n",
      "synergistic interaction between Human Intelligence (HI) and GAI across four group decision-making scenarios\n",
      "within three global organizations renowned for their cutting-edge operational techniques. The research pro-\n",
      "gresses through several phases: identifying research problems, collecting baseline data on decision-making,\n",
      "implementing AI interventions, and evaluating the outcomes post-intervention to identify shifts in perfor-\n",
      "mance. The results demonstrate that GAI effectively reduces human cognitive burdens and mitigates heuristic\n",
      "biases by offering data-driven support and predictive analytics, grounded in System 2 reasoning. This is\n",
      "particularly valuable in complex situations characterized by unfamiliarity and information overload, where\n",
      "intuitive, System 1 thinking is less effective. However, the study also uncovers challenges related to GAI inte-\n",
      "gration, such as potential over-reliance on technology, intrinsic biases particularly ‘out-of-the-box ’ thinking\n",
      "without contextual creativity. To address these issues, this paper proposes an innovative strategic framework for\n",
      "HI-GAI collaboration that emphasizes transparency, accountability, and inclusiveness.\n",
      "1. Introduction\n",
      "The release of ChatGPT on November 30, 2022 [ 1 ], coincided with\n",
      "the aftermath of a global pandemic, was within a period characterized\n",
      "by significant societal and technological transformations. Before the\n",
      "introduction of Generative AI (GAI), ‘traditional AI ’ , which requires\n",
      "structured data for model construction and information processing,\n",
      "including neural networks, evolutionary algorithms, decision trees,\n",
      "random forests, support vector machines, and k-means clustering were\n",
      "already widespread [ 2 ]. Traditional AI was integrated into applications\n",
      "that influenced pricing, inventory management, logistic optimization,\n",
      "content recommendation etc., but were somewhat restricted in their\n",
      "functionality and had difficulties in directly interacting with users [ 3 ].\n",
      "In contrast, GAI technologies such as ChatGPT introduced a user inter-\n",
      "face that made AI both accessible and a regular part of daily technology\n",
      "use [ 4 ]. This made a significant shift towards direct human-AI collabo-\n",
      "ration [ 5 ]. This ease of use and direct interaction has ushered in a new\n",
      "era of machine-driven intelligence, where technological advances have\n",
      "outpaced organizational understanding of their effective management\n",
      "and exploitation.\n",
      "In the traditional paradigms of organizational decision-making,\n",
      "human intelligence (HI) whether individual or collective, is distin-\n",
      "guished by a blend of intuitive perception, emotional sensitivity, and\n",
      "cultural cognizance, that resonates across scenarios, from executing\n",
      "immediate, task-specific objectives [ 6 ] to strategizing for comprehen-\n",
      "sive, long-term aspirations [ 7 ]. These intrinsic human cognitive abilities\n",
      "inject creative and deep-seated insights into the strategic framework,\n",
      "thus equipping the organization with the fitness to adeptly steer through\n",
      "market fluctuations, competitive pressures, and technological ad-\n",
      "vancements [ 8 ]. Where teams must interact dynamically with constantly\n",
      "changing external variables, the comprehensive range of human cogni-\n",
      "tive skills is essential for plotting pathways through ambiguous situa-\n",
      "tions and capitalizing on the opportunities that such adaptability affords\n",
      "[ 9 ]. However, cognitive, and heuristic biases, essentially ‘rule of thumb ’\n",
      "or ‘mental shortcuts ’ evolved for information-processing efficiency [ 10 ],\n",
      "can sometimes be advantageous but often constrict perception and\n",
      "engender systematic errors in judgment, frequently leading to distorted\n",
      "reasoning and suboptimal decision-making outcomes [ 11 ]. High reli-\n",
      "ance on familiar biases can overshadow data-driven analysis. The latest\n",
      "iteration, GPT-4o ( “ o ” for “ omni ” ), expands on GPT-4 with 1.76 trillion\n",
      "* Corresponding author.\n",
      "E-mail address: haox2@cardiff.ac.uk (X. Hao).\n",
      "Contents lists available at ScienceDirect\n",
      "Technology in Society\n",
      "journal homep age: www.el sevier.com/l ocate/techso c\n",
      "https://doi.org/10.1016/j.techsoc.2024.102662\n",
      "Received 22 January 2024; Received in revised form 3 June 2024; Accepted 14 July 2024' metadata={'producer': 'Acrobat Distiller 8.1.0 (Windows)', 'creator': 'Elsevier', 'creationdate': '2024-07-19T14:48:15+00:00', 'crossmarkdomains[1]': 'elsevier.com', 'creationdate--text': '20th July 2024', 'robots': 'noindex', 'elsevierwebpdfspecifications': '7.0', 'moddate': '2024-07-20T09:27:48+00:00', 'doi': '10.1016/j.techsoc.2024.102662', 'keywords': 'ChatGPT,Artificial intelligence,Human intuition,Decision-making,Cognitive biases', 'title': 'Exploring collaborative decision-making: A quasi-experimental study of human and Generative AI interaction', 'subject': 'Technology in Society, 78 (2024) 102662. doi:10.1016/j.techsoc.2024.102662', 'crossmarkdomains[2]': 'sciencedirect.com', 'author': 'Xinyue Hao', 'source': 'uploads/d8c8c918-8f5a-43c4-9f21-757758298fef.pdf', 'total_pages': 22, 'page': 0, 'page_label': '1'}\n",
      "Loaded 25 pages from 39d35f10-36e7-4b6c-b650-f22f7ae3ae85.pdf\n",
      "\n",
      "\n",
      "page_content='Urban Planning\n",
      "2025 • Volume 10• Article 9165\n",
      "https://doi.org/10.17645/up.9165\n",
      "A R T I C L E Open Access Journal\n",
      "AI‐Supported Participatory Workshops: Middle‐Out Engagement\n",
      "for Crisis Events\n",
      "Martin Tomitsch1\n",
      " , Joel Fredericks2\n",
      " , Marius Hoggenmüller2\n",
      " , Alexandra Crosby3\n",
      " ,\n",
      "Adrian Wong2\n",
      " , Xinyan Yu2\n",
      " , and Weidong Huang1\n",
      "1 TransdisciplinarySchool,UniversityofTechnologySydney,Australia\n",
      "2 SchoolofArchitecture,DesignandPlanning,TheUniversityofSydney,Australia\n",
      "3 FacultyofDesign,ArchitectureandBuilding,UniversityofTechnologySydney,Australia\n",
      "Correspondence: MartinTomitsch(martin.tomitsch@uts.edu.au)\n",
      "Submitted: 9August2024 Accepted: 5November2024 Published: 27January2025\n",
      "Issue: This article is part of the issue “The Role of Participatory Planning and Design in Addressing the\n",
      "UN Sustainable Development Goals” edited by Hilary Davis (Swinburne University of Technology), Joel\n",
      "Fredericks(TheUniversityofSydney),MarcusFoth(QueenslandUniversityofTechnology),GlendaCaldwell\n",
      "(QueenslandUniversityofTechnology),andCallumParker(TheUniversityofSydney),fullyopenaccessat\n",
      "https://doi.org/10.17645/up.i394\n",
      "Abstract\n",
      "Consideringthelivedexperienceofcommunitiesiskeywhenmakingdecisionsincomplexscenarios,suchas\n",
      "preparingforandrespondingtocrisisevents.Thearticlereportsonthreeparticipatoryworkshops,which\n",
      "assigned community representative roles to workshop participants. Using role‐playing as a method,\n",
      "participantsweregiventhetaskofcollaboratingonmakingadecisionrelatingtoaspeculativecrisisscenario.\n",
      "Acrosstheworkshops,wecollecteddataaboutsimulatingamiddle‐outengagementapproachandtherole\n",
      "of artificial intelligence (AI) in enhancing collaboration, supporting decision‐making, and representing\n",
      "non‐humanactors.Thearticlemakesthreecontributionstoparticipatoryplanninganddesigninthecontext\n",
      "of the UN Sustainable Development Goals. First, it presents insights about the use of AI in enhancing\n",
      "collaboration and decision‐making in crisis event situations. Second, it discusses approaches for bringing\n",
      "more‐than‐human considerations into participatory planning and design. Third, it reflects on the value of\n",
      "role‐playingasawaytosimulateamiddle‐outengagementprocess,wherebyactorsfromthetopandthe\n",
      "bottomcollaboratetowardsmakinginformeddecisionsincomplexscenarios.Drawingonthefindingsfrom\n",
      "theworkshops,thearticlecriticallyreflectsonchallengesandrisksassociatedwithusingAIinparticipatory\n",
      "workshopsandcollaborativedecision‐making.\n",
      "Keywords\n",
      "artificialintelligence;communityengagement;conversationalagents;middle‐outengagement;non‐human\n",
      "personas;participatorydesign;participatoryplanning\n",
      "©2025bytheauthor(s),licensedunderaCreativeCommonsAttribution4.0InternationalLicense(CCBY). 1' metadata={'producer': 'xdvipdfmx (20240407)', 'creator': 'LaTeX with hyperref', 'creationdate': '2025-01-20T14:46:41+00:00', 'moddate': '2025-01-20T15:21:30+00:00', 'title': 'AI-Supported Participatory Workshops: Middle-Out Engagement for Crisis Events', 'keywords': 'artificial intelligence; community engagement; conversational agents; middle-out engagement; non-human personas; participatory design; participatory planning', 'author': 'Martin Tomitsch, Joel Fredericks, Marius Hoggenmüller, Alexandra Crosby, Adrian Wong, Xinyan Yu, and Weidong Huang', 'source': 'uploads/39d35f10-36e7-4b6c-b650-f22f7ae3ae85.pdf', 'total_pages': 25, 'page': 0, 'page_label': '1'}\n",
      "Loaded 14 pages from 3db9e072-c54b-448b-ac0c-054d0bb00bb1.pdf\n",
      "\n",
      "\n",
      "page_content='AI and the Future of Collaborative Work: Group Ideation with an\n",
      "LLM in a Virtual Canvas\n",
      "Jessica He\n",
      "IBM Research AI\n",
      "Seattle, USA\n",
      "jessicahe@ibm.com\n",
      "Stephanie Houde\n",
      "IBM Research AI\n",
      "Cambridge, USA\n",
      "Stephanie.Houde@ibm.com\n",
      "Gabriel Enrique Gonzalez\n",
      "IBM Argentina\n",
      "Necochea, Argentina\n",
      "gabriel.gonzalez@ibm.com\n",
      "Dario Andres Silva Moran\n",
      "IBM Argentina\n",
      "La Plata, Argentina\n",
      "dario.silva@ibm.com\n",
      "Steven I. Ross\n",
      "IBM Research AI\n",
      "Cambridge, USA\n",
      "steven_ross@us.ibm.com\n",
      "Michael Muller\n",
      "IBM Research AI\n",
      "Cambridge, USA\n",
      "michael_muller@us.ibm.com\n",
      "Justin D. Weisz\n",
      "IBM Research AI\n",
      "Yorktown Heights, USA\n",
      "jweisz@us.ibm.com\n",
      "ABSTRACT\n",
      "The introduction of generative AI into multi-user applications raises\n",
      "novel considerations for the future of collaborative work. How\n",
      "might collaborative work practices change? How might we incor-\n",
      "porate generative AI into shared tools with users’ needs at the\n",
      "forefront? We examine these questions in the context of a remote\n",
      "team conducting ideation tasks – an example of collaborative work\n",
      "enabled by a shared digital workspace. We conducted a user study\n",
      "with 17 professionals experienced with virtual group ideation work-\n",
      "shops. Our study examined their use of the Collaborative Canvas , a\n",
      "virtual canvas tool with integrated generative AI capabilities that\n",
      "we created as a probe. Participants saw value in using generative\n",
      "AI to assist with group facilitation and to augment perspectives\n",
      "and ideas. However, they worried about losing human perspectives\n",
      "and critical thinking, as well as reputational harms resulting from\n",
      "harmful AI outputs. Participants shared suggestions for appropriate\n",
      "ways to incorporate generative AI capabilities within multi-user\n",
      "applications and identified needs for transparency of content own-\n",
      "ership, private digital spaces, and specialized AI capabilities. Based\n",
      "on participants’ insights, we share implications and opportunities\n",
      "for the incorporation of generative AI into collaborative work in\n",
      "ways that place user needs at the forefront.\n",
      "CCS CONCEPTS\n",
      "• Human-centered computing →Empirical studies in HCI ;\n",
      "Empirical studies in collaborative and social computing ; •\n",
      "Computing methodologies →Artificial intelligence.\n",
      "This work is licensed under a Creative Commons Attribution-NonCommercial\n",
      "International 4.0 License.\n",
      "CHIWORK ’24, June 25–27, 2024, Newcastle upon Tyne, United Kingdom\n",
      "© 2024 Copyright held by the owner/author(s).\n",
      "ACM ISBN 979-8-4007-1017-9/24/06\n",
      "https://doi.org/10.1145/3663384.3663398\n",
      "KEYWORDS\n",
      "Group ideation, Brainstorming, Shared virtual canvas, Mixed initia-\n",
      "tive, Generative AI, Future of work\n",
      "ACM Reference Format:\n",
      "Jessica He, Stephanie Houde, Gabriel Enrique Gonzalez, Dario Andres Silva\n",
      "Moran, Steven I. Ross, Michael Muller, and Justin D. Weisz. 2024. AI and\n",
      "the Future of Collaborative Work: Group Ideation with an LLM in a Virtual\n",
      "Canvas. In Proceedings of the 3rd Annual Meeting of the Symposium on\n",
      "Human-Computer Interaction for Work (CHIWORK ’24), June 25–27, 2024,\n",
      "Newcastle upon Tyne, United Kingdom. ACM, New York, NY, USA, 14 pages.\n",
      "https://doi.org/10.1145/3663384.3663398\n",
      "1 INTRODUCTION\n",
      "Generative AI has the potential to automate tasks that were pre-\n",
      "viously thought to be exclusive to humans, raising questions of\n",
      "its impact on the future of work. Rapid advancements in gener-\n",
      "ative AI have already enabled its incorporation into professional\n",
      "work domains such as programming [ 95], research [ 1, 60], and\n",
      "design [41, 57, 113]. In these domains, generative AI can produce\n",
      "ideas, summaries, and suggestions that rival those produced by\n",
      "humans.\n",
      "In the past, many research studies on AI-augmented work have\n",
      "been configured such that one human works with a single AI agent\n",
      "(e.g., [55, 94, 119, 122]). Work by Farrell et al. [26] took an expanded\n",
      "view in which a human works with a back-end collection of AI\n",
      "agents, through a single front-end interface [26]. However, this view\n",
      "does not reflect the reality that work is often performed by groups\n",
      "of colleagues working together [104, 116, 127]. As advancements in\n",
      "generative AI make their way into collaborative domains, there is a\n",
      "need to shift our view to realistic work contexts in which multiple\n",
      "humans interact with each other along with AI agents.\n",
      "One indication of the rise of AI-supported group work is in the\n",
      "introduction of generative AI features to digital canvas tools such as\n",
      "Mural1, Miro2, and Microsoft Whiteboard3. These features include\n",
      "1Mural. https://mural.co\n",
      "2Miro. https://miro.com\n",
      "3Microsoft Whiteboard. https://whiteboard.microsoft.com' metadata={'producer': 'pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5; modified using iText 4.2.0 by 1T3XT', 'creator': 'LaTeX with acmart 2024/04/17 v2.07 Typesetting articles for the Association for Computing Machinery and hyperref 2023-02-07 v7.00v Hypertext links for LaTeX', 'creationdate': '2024-05-06T19:54:44+00:00', 'moddate': '2025-03-20T06:29:09-07:00', 'trapped': '/False', 'subject': '-  Human-centered computing  ->  Empirical studies in HCI.Empirical studies in collaborative and social computing.-  Computing methodologies  ->  Artificial intelligence.', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'title': 'AI and the Future of Collaborative Work: Group Ideation with an LLM in a Virtual Canvas', 'source': 'uploads/3db9e072-c54b-448b-ac0c-054d0bb00bb1.pdf', 'total_pages': 14, 'page': 0, 'page_label': '1'}\n",
      "Loaded 17 pages from 415279e5-46dd-4da8-95ed-56579a44e290.pdf\n",
      "\n",
      "\n",
      "page_content='Journal of Public Administration Research and Theory, 2023, 33, 153–169\n",
      "https://doi.org/10.1093/jopart/muac007\n",
      "Advance access publication 8 February 2022\n",
      "Article\n",
      "Human–AI Interactions in Public Sector Decision Making: \n",
      "“ Automation Bias” and “Selective Adherence” to \n",
      "Algorithmic Advice\n",
      "Saar Alon-Barkat,*,  Madalina Busuioc†,\n",
      "*University of Haifa, Israel\n",
      "†Vrije Universiteit Amsterdam, The Netherlands\n",
      "Address correspondence to the author at e.m.busuioc@vu.nl.\n",
      "Abstract \n",
      "Artificial intelligence algorithms are increasingly adopted as decisional aides by public bodies, with the promise of overcoming biases of human \n",
      "decision-makers. At the same time, they may introduce new biases in the human–algorithm interaction. Drawing on psychology and public \n",
      "administration literatures, we investigate two key biases: overreliance on algorithmic advice even in the face of “warning signals” from other \n",
      "sources (automation bias), and selective adoption of algorithmic advice when this corresponds to stereotypes (selective adherence). We assess \n",
      "these via three experimental studies conducted in the Netherlands: In study 1 (N = 605), we test automation bias by exploring participants’ \n",
      "adherence to an algorithmic prediction compared to an equivalent human-expert prediction. We do not find evidence for automation bias. In \n",
      "study 2 (N = 904), we replicate these findings, and also test selective adherence. We find a stronger propensity for adherence when the advice \n",
      "is aligned with group stereotypes, with no significant differences between algorithmic and human-expert advice. In study 3 (N = 1,345), we \n",
      "replicate our design with a sample of civil servants. This study was conducted shortly after a major scandal involving public authorities’ reliance \n",
      "on an algorithm with discriminatory outcomes (the “childcare benefits scandal”). The scandal is itself illustrative of our theory and patterns \n",
      "diagnosed empirically in our experiment, yet in our study 3, while supporting our prior findings as to automation bias, we do not find patterns of \n",
      "selective adherence. We suggest this is driven by bureaucrats’ enhanced awareness of discrimination and algorithmic biases in the aftermath of \n",
      "the scandal. We discuss the implications of our findings for public sector decision making in the age of automation. Overall, our study speaks to \n",
      "potential negative effects of automation of the administrative state for already vulnerable and disadvantaged citizens.\n",
      "Introduction\n",
      "Artificial intelligence (AI) algorithms are being widely adopted \n",
      "in the public sector across jurisdictions. Essentially a set of tools \n",
      "that display (or can even surpass) human-level performance \n",
      "on given tasks traditionally associated with human intelli-\n",
      "gence, AI algorithms are being relied upon in areas as varied as \n",
      "policing, welfare, criminal justice, healthcare, immigration, or \n",
      "education (Busuioc 2021; Calo and Citron 2021; Diakopoulos \n",
      "2014; Eubanks 2018; Engstrom et al. 2020; O’Neil 2016; \n",
      "Richardson, Schultz, and Crawford 2019; Veale and Brass \n",
      "2019; Yeung and Lodge 2019), increasingly permeating  \n",
      "non-routine and high-stakes aspects of bureaucratic work. The \n",
      "growing and deepening reliance on AI and machine learning \n",
      "technologies in the public sector has been diagnosed as “trans-\n",
      "formative” of public administrations (Bullock 2019; Vogl et al. \n",
      "2020; Young, Bullock, and Lecy 2019).\n",
      "These developments are driven by the promise of policy \n",
      "solutions that are potentially more effective, efficient, and \n",
      "low-cost. In addition, and importantly, algorithms are said to \n",
      "come with the “promise of neutrality,” in contrast to decision \n",
      "making based on human intuition, which involves biases and \n",
      "can result in discrimination. In other words, AI use in deci-\n",
      "sion making is said to hold the potential to help us overcome \n",
      "our cognitive biases and limitations. This has been an impor-\n",
      "tant driver for the adoption of such technologies in highly \n",
      "consequential public sector areas such as law enforcement or \n",
      "criminal justice: Predictive policing technologies, for instance, \n",
      "were propagated in the US context “as one answer to racially \n",
      "discriminatory policing, offering a seemingly race-neutral, ‘ob-\n",
      "jective’ justification for police targeting of poor communities” \n",
      "(Ferguson 2017, 5). Numerous other jurisdictions have \n",
      "followed suit with predictive technologies relied upon by po-\n",
      "lice forces in the United Kingdom, the Netherlands, Germany, \n",
      "among many others. Like rationales precipitated the adoption \n",
      "of predictive risk assessment systems in criminal justice, sim-\n",
      "ilarly in part in response to concerns with human bias and \n",
      "discrimination (Israni 2017), despite such systems themselves \n",
      "being flagged as sources of bias (Angwin et al. 2016).\n",
      "For a large part, AI algorithms currently serve as decisional \n",
      "aides to human decision-makers (“decision-support sys-\n",
      "tems”) in many bureaucratic contexts. This is especially so \n",
      "in highly consequential public sector areas, where “full au-\n",
      "tomation seems inappropriate or far off” (Edward and Veale \n",
      "2017, 45). Rather than making decisions on their own, al-\n",
      "gorithmic outputs—be they risk assessment scores used in \n",
      "criminal justice or the algorithm-generated “heat maps” of \n",
      "© The Author(s) 2022. Published by Oxford University Press on behalf of the Public Management Research Association.\n",
      "This is an Open Access article distributed under the terms of the Creative Commons Attribution-NonCommercial License (https://creativecommons.org/\n",
      "licenses/by-nc/4.0/), which permits non-commercial re-use, distribution, and reproduction in any medium, provided the original work is properly cited. For \n",
      "commercial re-use, please contact journals.permissions@oup.com\n",
      "We thank the three anonymous JPART reviewers for their extremely help-\n",
      "ful comments. We are also grateful to Dimiter Toshkov, Nadine Raaphorst, \n",
      "Joris van der Voet, Dana Vashdi, Sharon Gilad, Markus Tepe, Stephan \n",
      "Grimmelikhuijsen, Thijs de Boer, Benjamin Tidå, Omer Yair, and Aaron \n",
      "Swaving for their valuable comments and feedback in the process of devel-\n",
      "oping this project. We thank Luuk van Roozendaal for excellent research \n",
      "assistance.\n",
      "Downloaded from https://academic.oup.com/jpart/article/33/1/153/6524536 by guest on 21 March 2025' metadata={'producer': 'Adobe PDF Library 15.0; modified using iTextSharp 4.1.6 by 1T3XT', 'creator': 'Adobe InDesign 15.1 (Windows)', 'creationdate': '2022-12-23T18:23:16+05:30', 'trapped': '/False', 'moddate': '2025-03-21T10:34:28+00:00', 'source': 'uploads/415279e5-46dd-4da8-95ed-56579a44e290.pdf', 'total_pages': 17, 'page': 0, 'page_label': '153'}\n",
      "Loaded 15 pages from 4fac3e36-3e0b-4404-8f34-bffbd373fc68.pdf\n",
      "\n",
      "\n",
      "page_content='TYPE Review\n",
      "PUBLISHED /zero.tnum/six.tnum January /two.tnum/zero.tnum/two.tnum/five.tnum\n",
      "DOI /one.tnum/zero.tnum./three.tnum/three.tnum/eight.tnum/nine.tnum/fcomp./two.tnum/zero.tnum/two.tnum/four.tnum./one.tnum/five.tnum/two.tnum/one.tnum/zero.tnum/six.tnum/six.tnum\n",
      "OPEN ACCESS\n",
      "EDITED BY\n",
      "Stefan Kopp,\n",
      "Bielefeld University, Germany\n",
      "REVIEWED BY\n",
      "Styliani Kleanthous,\n",
      "Open University of Cyprus, Cyprus\n",
      "Milus˘e Balková,\n",
      "Institute of Technology and Business, Czechia\n",
      "*CORRESPONDENCE\n",
      "Mathias Unberath\n",
      "unberath@jhu.edu\n",
      "RECEIVED /zero.tnum/one.tnum November /two.tnum/zero.tnum/two.tnum/four.tnum\n",
      "ACCEPTED /zero.tnum/six.tnum December /two.tnum/zero.tnum/two.tnum/four.tnum\n",
      "PUBLISHED /zero.tnum/six.tnum January /two.tnum/zero.tnum/two.tnum/five.tnum\n",
      "CITATION\n",
      "Gomez C, Cho SM, Ke S, Huang C-M and\n",
      "Unberath M (/two.tnum/zero.tnum/two.tnum/five.tnum) Human-AI collaboration is\n",
      "not very collaborative yet: a taxonomy of\n",
      "interaction patterns in AI-assisted decision\n",
      "making from a systematic review.\n",
      "Front. Comput. Sci./six.tnum:/one.tnum/five.tnum/two.tnum/one.tnum/zero.tnum/six.tnum/six.tnum.\n",
      "doi: /one.tnum/zero.tnum./three.tnum/three.tnum/eight.tnum/nine.tnum/fcomp./two.tnum/zero.tnum/two.tnum/four.tnum./one.tnum/five.tnum/two.tnum/one.tnum/zero.tnum/six.tnum/six.tnum\n",
      "COPYRIGHT\n",
      "© /two.tnum/zero.tnum/two.tnum/five.tnum Gomez, Cho, Ke, Huang and\n",
      "Unberath. This is an open-access article\n",
      "distributed under the terms of the\n",
      "Creative\n",
      "Commons Attribution License (CC BY) . The\n",
      "use, distribution or reproduction in other\n",
      "forums is permitted, provided the original\n",
      "author(s) and the copyright owner(s) are\n",
      "credited and that the original publication in\n",
      "this journal is cited, in accordance with\n",
      "accepted academic practice. No use,\n",
      "distribution or reproduction is permitted\n",
      "which does not comply with these terms.\n",
      "Human-AI collaboration is not\n",
      "very collaborative yet: a\n",
      "taxonomy of interaction patterns\n",
      "in AI-assisted decision making\n",
      "from a systematic review\n",
      "Catalina Gomez, Sue Min Cho, Shichang Ke, Chien-Ming Huang\n",
      "and Mathias Unberath*\n",
      "Department of Computer Science, Johns Hopkins University, Baltim ore, MD, United States\n",
      "Leveraging Artiﬁcial Intelligence (AI) in decision support syst ems has\n",
      "disproportionately focused on technological advancements, ofte n overlooking\n",
      "the alignment between algorithmic outputs and human expectatio ns. A\n",
      "human-centered perspective attempts to alleviate this concern by designing AI\n",
      "solutions for seamless integration with existing processes. Determining what\n",
      "information AI should provide to aid humans is vital, a concept u nderscored by\n",
      "explainable AI’s eﬀorts to justify AI predictions. However, h ow the information\n",
      "is presented, e.g., the sequence of recommendations and solicit ation of\n",
      "interpretations, is equally crucial as complex interactions may e merge between\n",
      "humans and AI. While empirical studies have evaluated human-AI dynamics\n",
      "across domains, a common vocabulary for human-AI interaction prot ocols is\n",
      "lacking. To promote more deliberate consideration of interacti on designs, we\n",
      "introduce a taxonomy of interaction patterns that delineate v arious modes of\n",
      "human-AI interactivity. We summarize the results of a system atic review of\n",
      "AI-assisted decision making literature and identify trends and opportunities\n",
      "in existing interactions across application domains from /one.tnum/zero.tnum/five.tnum articles. We ﬁnd\n",
      "that current interactions are dominated by simplistic collabor ation paradigms,\n",
      "leading to little support for truly interactive functionality . Our taxonomy oﬀers a\n",
      "tool to understand interactivity with AI in decision-making and foster interaction\n",
      "designs for achieving clear communication, trustworthiness, and collaboration.\n",
      "KEYWORDS\n",
      "artiﬁcial intelligence, human-AI interaction, decision-ma king, interaction patterns,\n",
      "interactivity\n",
      "/one.tnum Introduction\n",
      "Advances in Artiﬁcial Intelligence (AI) developments open new possibilities for\n",
      "supporting human decision making across a wide variety of applications. Decision making\n",
      "tasks in a broad range of applications share a process that starts when evidence is presented\n",
      "before making a decision within discrete choices, usually with follow-up eﬀects. Within this\n",
      "framework, the decision-making process emerges as a scenario for human-AI teamwork\n",
      "where at a minimum two parties, i.e., the human and the AI, factor into ﬁnding a solution to\n",
      "the decision problem. The exact dynamics of how this collaboration occurs can vary from\n",
      "one situation to another, leading to multiple interaction options that range from simple\n",
      "Frontiers in Computer Science /zero.tnum/one.tnum frontiersin.org' metadata={'producer': 'dvips + MiKTeX GPL Ghostscript  9.0', 'creator': 'LaTeX with hyperref package + hypdvips', 'creationdate': '2024-12-26T12:14:21+05:30', 'subject': 'Gomez C, Cho SM, Ke S, Huang C-M and Unberath M (2025) Human-AI collaboration is not very collaborative yet: a taxonomy of interaction patterns in AI-assisted decision making from a systematic review. Front. Comput. Sci. 6:1521066. doi: 10.3389/fcomp.2024.1521066', 'author': 'Catalina Gomez', 'keywords': 'artificial intelligence; human-AI interaction; decision-making; interaction patterns; interactivity', 'moddate': '2024-12-26T12:33:06+05:30', 'title': 'Human-AI collaboration is not very collaborative yet: a taxonomy of interaction patterns in AI-assisted decision making from a systematic review', 'source': 'uploads/4fac3e36-3e0b-4404-8f34-bffbd373fc68.pdf', 'total_pages': 15, 'page': 0, 'page_label': '1'}\n",
      "Loaded 17 pages from ccbd7aa6-dbf1-4590-b9c5-b170ec4f7f39.pdf\n",
      "\n",
      "\n",
      "page_content='Journal of Public Administration Research and Theory, 2023, 33, 153–169\n",
      "https://doi.org/10.1093/jopart/muac007\n",
      "Advance access publication 8 February 2022\n",
      "Article\n",
      "Human–AI Interactions in Public Sector Decision Making: \n",
      "“ Automation Bias” and “Selective Adherence” to \n",
      "Algorithmic Advice\n",
      "Saar Alon-Barkat,*,  Madalina Busuioc†,\n",
      "*University of Haifa, Israel\n",
      "†Vrije Universiteit Amsterdam, The Netherlands\n",
      "Address correspondence to the author at e.m.busuioc@vu.nl.\n",
      "Abstract \n",
      "Artificial intelligence algorithms are increasingly adopted as decisional aides by public bodies, with the promise of overcoming biases of human \n",
      "decision-makers. At the same time, they may introduce new biases in the human–algorithm interaction. Drawing on psychology and public \n",
      "administration literatures, we investigate two key biases: overreliance on algorithmic advice even in the face of “warning signals” from other \n",
      "sources (automation bias), and selective adoption of algorithmic advice when this corresponds to stereotypes (selective adherence). We assess \n",
      "these via three experimental studies conducted in the Netherlands: In study 1 (N = 605), we test automation bias by exploring participants’ \n",
      "adherence to an algorithmic prediction compared to an equivalent human-expert prediction. We do not find evidence for automation bias. In \n",
      "study 2 (N = 904), we replicate these findings, and also test selective adherence. We find a stronger propensity for adherence when the advice \n",
      "is aligned with group stereotypes, with no significant differences between algorithmic and human-expert advice. In study 3 (N = 1,345), we \n",
      "replicate our design with a sample of civil servants. This study was conducted shortly after a major scandal involving public authorities’ reliance \n",
      "on an algorithm with discriminatory outcomes (the “childcare benefits scandal”). The scandal is itself illustrative of our theory and patterns \n",
      "diagnosed empirically in our experiment, yet in our study 3, while supporting our prior findings as to automation bias, we do not find patterns of \n",
      "selective adherence. We suggest this is driven by bureaucrats’ enhanced awareness of discrimination and algorithmic biases in the aftermath of \n",
      "the scandal. We discuss the implications of our findings for public sector decision making in the age of automation. Overall, our study speaks to \n",
      "potential negative effects of automation of the administrative state for already vulnerable and disadvantaged citizens.\n",
      "Introduction\n",
      "Artificial intelligence (AI) algorithms are being widely adopted \n",
      "in the public sector across jurisdictions. Essentially a set of tools \n",
      "that display (or can even surpass) human-level performance \n",
      "on given tasks traditionally associated with human intelli-\n",
      "gence, AI algorithms are being relied upon in areas as varied as \n",
      "policing, welfare, criminal justice, healthcare, immigration, or \n",
      "education (Busuioc 2021; Calo and Citron 2021; Diakopoulos \n",
      "2014; Eubanks 2018; Engstrom et al. 2020; O’Neil 2016; \n",
      "Richardson, Schultz, and Crawford 2019; Veale and Brass \n",
      "2019; Yeung and Lodge 2019), increasingly permeating  \n",
      "non-routine and high-stakes aspects of bureaucratic work. The \n",
      "growing and deepening reliance on AI and machine learning \n",
      "technologies in the public sector has been diagnosed as “trans-\n",
      "formative” of public administrations (Bullock 2019; Vogl et al. \n",
      "2020; Young, Bullock, and Lecy 2019).\n",
      "These developments are driven by the promise of policy \n",
      "solutions that are potentially more effective, efficient, and \n",
      "low-cost. In addition, and importantly, algorithms are said to \n",
      "come with the “promise of neutrality,” in contrast to decision \n",
      "making based on human intuition, which involves biases and \n",
      "can result in discrimination. In other words, AI use in deci-\n",
      "sion making is said to hold the potential to help us overcome \n",
      "our cognitive biases and limitations. This has been an impor-\n",
      "tant driver for the adoption of such technologies in highly \n",
      "consequential public sector areas such as law enforcement or \n",
      "criminal justice: Predictive policing technologies, for instance, \n",
      "were propagated in the US context “as one answer to racially \n",
      "discriminatory policing, offering a seemingly race-neutral, ‘ob-\n",
      "jective’ justification for police targeting of poor communities” \n",
      "(Ferguson 2017, 5). Numerous other jurisdictions have \n",
      "followed suit with predictive technologies relied upon by po-\n",
      "lice forces in the United Kingdom, the Netherlands, Germany, \n",
      "among many others. Like rationales precipitated the adoption \n",
      "of predictive risk assessment systems in criminal justice, sim-\n",
      "ilarly in part in response to concerns with human bias and \n",
      "discrimination (Israni 2017), despite such systems themselves \n",
      "being flagged as sources of bias (Angwin et al. 2016).\n",
      "For a large part, AI algorithms currently serve as decisional \n",
      "aides to human decision-makers (“decision-support sys-\n",
      "tems”) in many bureaucratic contexts. This is especially so \n",
      "in highly consequential public sector areas, where “full au-\n",
      "tomation seems inappropriate or far off” (Edward and Veale \n",
      "2017, 45). Rather than making decisions on their own, al-\n",
      "gorithmic outputs—be they risk assessment scores used in \n",
      "criminal justice or the algorithm-generated “heat maps” of \n",
      "© The Author(s) 2022. Published by Oxford University Press on behalf of the Public Management Research Association.\n",
      "This is an Open Access article distributed under the terms of the Creative Commons Attribution-NonCommercial License (https://creativecommons.org/\n",
      "licenses/by-nc/4.0/), which permits non-commercial re-use, distribution, and reproduction in any medium, provided the original work is properly cited. For \n",
      "commercial re-use, please contact journals.permissions@oup.com\n",
      "We thank the three anonymous JPART reviewers for their extremely help-\n",
      "ful comments. We are also grateful to Dimiter Toshkov, Nadine Raaphorst, \n",
      "Joris van der Voet, Dana Vashdi, Sharon Gilad, Markus Tepe, Stephan \n",
      "Grimmelikhuijsen, Thijs de Boer, Benjamin Tidå, Omer Yair, and Aaron \n",
      "Swaving for their valuable comments and feedback in the process of devel-\n",
      "oping this project. We thank Luuk van Roozendaal for excellent research \n",
      "assistance.\n",
      "Downloaded from https://academic.oup.com/jpart/article/33/1/153/6524536 by guest on 21 March 2025' metadata={'producer': 'Adobe PDF Library 15.0; modified using iTextSharp 4.1.6 by 1T3XT', 'creator': 'Adobe InDesign 15.1 (Windows)', 'creationdate': '2022-12-23T18:23:16+05:30', 'trapped': '/False', 'moddate': '2025-03-21T10:34:28+00:00', 'source': 'uploads/ccbd7aa6-dbf1-4590-b9c5-b170ec4f7f39.pdf', 'total_pages': 17, 'page': 0, 'page_label': '153'}\n",
      "Loaded 26 pages from 4cc9a7ec-f730-4227-bc07-fdfe9550b4e4.pdf\n",
      "\n",
      "\n",
      "page_content='LM Agents for Coordinating Multi-User Information Gathering\n",
      "Harsh Jhamtani, Jacob Andreas, Benjamin Van Durme\n",
      "Microsoft\n",
      "{hjhamtani,jaandrea,ben.vandurme}@microsoft.com\n",
      "Abstract\n",
      "This paper introduces PEOPLE JOIN , a bench-\n",
      "mark for evaluating LM-mediated collaborative\n",
      "problem solving. Given a user request, PEO-\n",
      "PLE JOIN agents must identify teammates who\n",
      "might be able to assist, converse with these\n",
      "teammates to gather information, and finally\n",
      "compile a useful answer or summary for the\n",
      "original user. PEOPLE JOIN comprises two eval-\n",
      "uation domains: PEOPLE JOIN -QA, focused on\n",
      "questions about tabular data, and PEOPLE JOIN -\n",
      "DOCCREATION , focused on document creation\n",
      "tasks. The two domains are adapted from ex-\n",
      "isting NLP benchmarks for database question\n",
      "answering and multi-document summarization;\n",
      "here, however, the information needed to com-\n",
      "plete these tasks is distributed across synthetic\n",
      "“organizations” of 2–20 users, simulating natu-\n",
      "ral multi-user collaboration scenarios. We im-\n",
      "plemented several popular LM agent architec-\n",
      "tures, evaluating their accuracy and efficiency\n",
      "at completing tasks, and highlight new research\n",
      "questions that can be studied using PEOPLE -\n",
      "JOIN .1\n",
      "1 Introduction\n",
      "In today’s fast-paced and interconnected world,\n",
      "effective collaboration is essential for achieving\n",
      "complex tasks and making informed decisions\n",
      "(Papachristou et al., 2023; Gemp et al., 2024).\n",
      "Many decision-making, content creation, and\n",
      "information-gathering tasks require collecting in-\n",
      "formation from multiple people. For example,\n",
      "preparing a list of interns across teams in an or-\n",
      "ganization by reaching out to the leader of each\n",
      "team; preparing a newsletter for project updates\n",
      "might necessitate coordinating with multiple con-\n",
      "tributors; identifying a suitable time to meet might\n",
      "require several rounds of negotiations (Lin et al.,\n",
      "2024). Identifying what information is available,\n",
      "1Code and data can be found at https://github.com/\n",
      "microsoft/peoplejoin/\n",
      "judiciously determining who to contact, asking pre-\n",
      "cise questions, and compiling research results can\n",
      "be a challenging and time-consuming process—\n",
      "especially when real-time interaction between team\n",
      "members is difficult to coordinate.\n",
      "At the same time, recent large language mod-\n",
      "els (LLMs), such as GPT-4 (OpenAI, 2023), Phi-3\n",
      "(Abdin et al., 2024), LLaMa (Touvron et al., 2023),\n",
      "and Gemini (Team et al., 2023), are becoming a cru-\n",
      "cial building block in developing automated agents\n",
      "that can assist human users with complex tasks\n",
      "(Xi et al., 2023; Wang et al., 2024; Butler et al.,\n",
      "2023). These tasks include chat applications for\n",
      "assisting individual users with searching and sum-\n",
      "marizing information (such as in Microsoft Copilot\n",
      "Chat2), and even supporting these users in work-\n",
      "place decision-making (Butler et al., 2023; Kim\n",
      "and Hsu, 2024). Could these agents be extended to\n",
      "improve collaboration among multiple users?\n",
      "In this paper, we introduce PEOPLE JOIN , an\n",
      "evaluation framework for studying effectiveness\n",
      "of LLM-powered agents to assist with multi-user\n",
      "collaboration tasks. Each PEOPLE JOIN task takes\n",
      "place within a fictitious organization with 2–20\n",
      "employees, some of whom possess a collection of\n",
      "documents necessary to solve some task. One of\n",
      "the users (the initiating user) communicates the\n",
      "task to an agent (Fig. 1). Agents have direct ac-\n",
      "cess to the initiating user’s documents, and can\n",
      "engage in conversations with other users to gather\n",
      "relevant information. They must rely on limited\n",
      "descriptions of other users, and potentially previ-\n",
      "ous interactions, to determine who to contact for a\n",
      "given task. PEOPLE JOIN comprises two families\n",
      "of tasks: PEOPLE JOIN -QA and PEOPLE JOIN -\n",
      "DOCCREATION , derived from the SPIDER (Yu\n",
      "et al., 2018) and MULTINEWS (Fabbri et al., 2019)\n",
      "datasets respectively. It evaluates agents’ ability\n",
      "to answer questions involving complex relational\n",
      "2https://copilot.microsoft.com/\n",
      "arXiv:2502.12328v1  [cs.CL]  17 Feb 2025' metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2025-02-19T01:08:14+00:00', 'author': '', 'keywords': '', 'moddate': '2025-02-19T01:08:14+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'subject': '', 'title': '', 'trapped': '/False', 'source': 'uploads/4cc9a7ec-f730-4227-bc07-fdfe9550b4e4.pdf', 'total_pages': 26, 'page': 0, 'page_label': '1'}\n",
      "Loaded 14 pages from 8bf9f5ed-8ec2-4004-ac9e-f754b8da2d93.pdf\n",
      "\n",
      "\n",
      "page_content='See discussions, stats, and author profiles for this publication at: https://www.researchgate.net/publication/384228166\n",
      "How large language models can reshape collective intelligence\n",
      "Article  in   Nature Human Behaviour · September 2024\n",
      "DOI: 10.1038/s41562-024-01959-9\n",
      "CITATIONS\n",
      "27\n",
      "READS\n",
      "3,000\n",
      "28 authors, including:\n",
      "Jason Burton\n",
      "Copenhagen Business School\n",
      "11 PUBLICATIONS   646 CITATIONS   \n",
      "SEE PROFILE\n",
      "Ezequiel Lopez-Lopez\n",
      "Max Planck Institute for Human Development\n",
      "5 PUBLICATIONS   28 CITATIONS   \n",
      "SEE PROFILE\n",
      "Zoe Rahwan\n",
      "Max Planck Institute for Human Development\n",
      "13 PUBLICATIONS   115 CITATIONS   \n",
      "SEE PROFILE\n",
      "Samuel Aeschbach\n",
      "University of Basel\n",
      "8 PUBLICATIONS   103 CITATIONS   \n",
      "SEE PROFILE\n",
      "All content following this page was uploaded by Taha Yasseri on 25 September 2024.\n",
      "The user has requested enhancement of the downloaded file.' metadata={'producer': 'PyPDF', 'creator': 'Springer', 'creationdate': '2024-09-16T16:43:21+05:30', 'author': 'Jason W. Burton', 'crossmarkdomains[1]': 'springer.com', 'crossmarkdomains[2]': 'springerlink.com', 'keywords': '', 'moddate': '2024-09-16T16:44:15+05:30', 'subject': 'Nature Human Behaviour, doi:10.1038/s41562-024-01959-9', 'title': 'How large language models can reshape collective intelligence', 'doi': '10.1038/s41562-024-01959-9', 'rgid': 'PB:384228166_AS:11431281279985736@1727266110169', 'source': 'uploads/8bf9f5ed-8ec2-4004-ac9e-f754b8da2d93.pdf', 'total_pages': 14, 'page': 0, 'page_label': '1'}\n",
      "Loaded 17 pages from 0e37f6b9-f2cd-47e8-8112-a5d157408925.pdf\n",
      "\n",
      "\n",
      "page_content='Journal of Public Administration Research and Theory, 2023, 33, 153–169\n",
      "https://doi.org/10.1093/jopart/muac007\n",
      "Advance access publication 8 February 2022\n",
      "Article\n",
      "Human–AI Interactions in Public Sector Decision Making: \n",
      "“ Automation Bias” and “Selective Adherence” to \n",
      "Algorithmic Advice\n",
      "Saar Alon-Barkat,*,  Madalina Busuioc†,\n",
      "*University of Haifa, Israel\n",
      "†Vrije Universiteit Amsterdam, The Netherlands\n",
      "Address correspondence to the author at e.m.busuioc@vu.nl.\n",
      "Abstract \n",
      "Artificial intelligence algorithms are increasingly adopted as decisional aides by public bodies, with the promise of overcoming biases of human \n",
      "decision-makers. At the same time, they may introduce new biases in the human–algorithm interaction. Drawing on psychology and public \n",
      "administration literatures, we investigate two key biases: overreliance on algorithmic advice even in the face of “warning signals” from other \n",
      "sources (automation bias), and selective adoption of algorithmic advice when this corresponds to stereotypes (selective adherence). We assess \n",
      "these via three experimental studies conducted in the Netherlands: In study 1 (N = 605), we test automation bias by exploring participants’ \n",
      "adherence to an algorithmic prediction compared to an equivalent human-expert prediction. We do not find evidence for automation bias. In \n",
      "study 2 (N = 904), we replicate these findings, and also test selective adherence. We find a stronger propensity for adherence when the advice \n",
      "is aligned with group stereotypes, with no significant differences between algorithmic and human-expert advice. In study 3 (N = 1,345), we \n",
      "replicate our design with a sample of civil servants. This study was conducted shortly after a major scandal involving public authorities’ reliance \n",
      "on an algorithm with discriminatory outcomes (the “childcare benefits scandal”). The scandal is itself illustrative of our theory and patterns \n",
      "diagnosed empirically in our experiment, yet in our study 3, while supporting our prior findings as to automation bias, we do not find patterns of \n",
      "selective adherence. We suggest this is driven by bureaucrats’ enhanced awareness of discrimination and algorithmic biases in the aftermath of \n",
      "the scandal. We discuss the implications of our findings for public sector decision making in the age of automation. Overall, our study speaks to \n",
      "potential negative effects of automation of the administrative state for already vulnerable and disadvantaged citizens.\n",
      "Introduction\n",
      "Artificial intelligence (AI) algorithms are being widely adopted \n",
      "in the public sector across jurisdictions. Essentially a set of tools \n",
      "that display (or can even surpass) human-level performance \n",
      "on given tasks traditionally associated with human intelli-\n",
      "gence, AI algorithms are being relied upon in areas as varied as \n",
      "policing, welfare, criminal justice, healthcare, immigration, or \n",
      "education (Busuioc 2021; Calo and Citron 2021; Diakopoulos \n",
      "2014; Eubanks 2018; Engstrom et al. 2020; O’Neil 2016; \n",
      "Richardson, Schultz, and Crawford 2019; Veale and Brass \n",
      "2019; Yeung and Lodge 2019), increasingly permeating  \n",
      "non-routine and high-stakes aspects of bureaucratic work. The \n",
      "growing and deepening reliance on AI and machine learning \n",
      "technologies in the public sector has been diagnosed as “trans-\n",
      "formative” of public administrations (Bullock 2019; Vogl et al. \n",
      "2020; Young, Bullock, and Lecy 2019).\n",
      "These developments are driven by the promise of policy \n",
      "solutions that are potentially more effective, efficient, and \n",
      "low-cost. In addition, and importantly, algorithms are said to \n",
      "come with the “promise of neutrality,” in contrast to decision \n",
      "making based on human intuition, which involves biases and \n",
      "can result in discrimination. In other words, AI use in deci-\n",
      "sion making is said to hold the potential to help us overcome \n",
      "our cognitive biases and limitations. This has been an impor-\n",
      "tant driver for the adoption of such technologies in highly \n",
      "consequential public sector areas such as law enforcement or \n",
      "criminal justice: Predictive policing technologies, for instance, \n",
      "were propagated in the US context “as one answer to racially \n",
      "discriminatory policing, offering a seemingly race-neutral, ‘ob-\n",
      "jective’ justification for police targeting of poor communities” \n",
      "(Ferguson 2017, 5). Numerous other jurisdictions have \n",
      "followed suit with predictive technologies relied upon by po-\n",
      "lice forces in the United Kingdom, the Netherlands, Germany, \n",
      "among many others. Like rationales precipitated the adoption \n",
      "of predictive risk assessment systems in criminal justice, sim-\n",
      "ilarly in part in response to concerns with human bias and \n",
      "discrimination (Israni 2017), despite such systems themselves \n",
      "being flagged as sources of bias (Angwin et al. 2016).\n",
      "For a large part, AI algorithms currently serve as decisional \n",
      "aides to human decision-makers (“decision-support sys-\n",
      "tems”) in many bureaucratic contexts. This is especially so \n",
      "in highly consequential public sector areas, where “full au-\n",
      "tomation seems inappropriate or far off” (Edward and Veale \n",
      "2017, 45). Rather than making decisions on their own, al-\n",
      "gorithmic outputs—be they risk assessment scores used in \n",
      "criminal justice or the algorithm-generated “heat maps” of \n",
      "© The Author(s) 2022. Published by Oxford University Press on behalf of the Public Management Research Association.\n",
      "This is an Open Access article distributed under the terms of the Creative Commons Attribution-NonCommercial License (https://creativecommons.org/\n",
      "licenses/by-nc/4.0/), which permits non-commercial re-use, distribution, and reproduction in any medium, provided the original work is properly cited. For \n",
      "commercial re-use, please contact journals.permissions@oup.com\n",
      "We thank the three anonymous JPART reviewers for their extremely help-\n",
      "ful comments. We are also grateful to Dimiter Toshkov, Nadine Raaphorst, \n",
      "Joris van der Voet, Dana Vashdi, Sharon Gilad, Markus Tepe, Stephan \n",
      "Grimmelikhuijsen, Thijs de Boer, Benjamin Tidå, Omer Yair, and Aaron \n",
      "Swaving for their valuable comments and feedback in the process of devel-\n",
      "oping this project. We thank Luuk van Roozendaal for excellent research \n",
      "assistance.\n",
      "Downloaded from https://academic.oup.com/jpart/article/33/1/153/6524536 by guest on 21 March 2025' metadata={'producer': 'Adobe PDF Library 15.0; modified using iTextSharp 4.1.6 by 1T3XT', 'creator': 'Adobe InDesign 15.1 (Windows)', 'creationdate': '2022-12-23T18:23:16+05:30', 'trapped': '/False', 'moddate': '2025-03-21T10:34:28+00:00', 'source': 'uploads/0e37f6b9-f2cd-47e8-8112-a5d157408925.pdf', 'total_pages': 17, 'page': 0, 'page_label': '153'}\n",
      "Loaded 25 pages from 3f817ad1-52b1-4940-81ea-4508d68d036f.pdf\n",
      "\n",
      "\n",
      "page_content='Urban Planning\n",
      "2025 • Volume 10• Article 9165\n",
      "https://doi.org/10.17645/up.9165\n",
      "A R T I C L E Open Access Journal\n",
      "AI‐Supported Participatory Workshops: Middle‐Out Engagement\n",
      "for Crisis Events\n",
      "Martin Tomitsch1\n",
      " , Joel Fredericks2\n",
      " , Marius Hoggenmüller2\n",
      " , Alexandra Crosby3\n",
      " ,\n",
      "Adrian Wong2\n",
      " , Xinyan Yu2\n",
      " , and Weidong Huang1\n",
      "1 TransdisciplinarySchool,UniversityofTechnologySydney,Australia\n",
      "2 SchoolofArchitecture,DesignandPlanning,TheUniversityofSydney,Australia\n",
      "3 FacultyofDesign,ArchitectureandBuilding,UniversityofTechnologySydney,Australia\n",
      "Correspondence: MartinTomitsch(martin.tomitsch@uts.edu.au)\n",
      "Submitted: 9August2024 Accepted: 5November2024 Published: 27January2025\n",
      "Issue: This article is part of the issue “The Role of Participatory Planning and Design in Addressing the\n",
      "UN Sustainable Development Goals” edited by Hilary Davis (Swinburne University of Technology), Joel\n",
      "Fredericks(TheUniversityofSydney),MarcusFoth(QueenslandUniversityofTechnology),GlendaCaldwell\n",
      "(QueenslandUniversityofTechnology),andCallumParker(TheUniversityofSydney),fullyopenaccessat\n",
      "https://doi.org/10.17645/up.i394\n",
      "Abstract\n",
      "Consideringthelivedexperienceofcommunitiesiskeywhenmakingdecisionsincomplexscenarios,suchas\n",
      "preparingforandrespondingtocrisisevents.Thearticlereportsonthreeparticipatoryworkshops,which\n",
      "assigned community representative roles to workshop participants. Using role‐playing as a method,\n",
      "participantsweregiventhetaskofcollaboratingonmakingadecisionrelatingtoaspeculativecrisisscenario.\n",
      "Acrosstheworkshops,wecollecteddataaboutsimulatingamiddle‐outengagementapproachandtherole\n",
      "of artificial intelligence (AI) in enhancing collaboration, supporting decision‐making, and representing\n",
      "non‐humanactors.Thearticlemakesthreecontributionstoparticipatoryplanninganddesigninthecontext\n",
      "of the UN Sustainable Development Goals. First, it presents insights about the use of AI in enhancing\n",
      "collaboration and decision‐making in crisis event situations. Second, it discusses approaches for bringing\n",
      "more‐than‐human considerations into participatory planning and design. Third, it reflects on the value of\n",
      "role‐playingasawaytosimulateamiddle‐outengagementprocess,wherebyactorsfromthetopandthe\n",
      "bottomcollaboratetowardsmakinginformeddecisionsincomplexscenarios.Drawingonthefindingsfrom\n",
      "theworkshops,thearticlecriticallyreflectsonchallengesandrisksassociatedwithusingAIinparticipatory\n",
      "workshopsandcollaborativedecision‐making.\n",
      "Keywords\n",
      "artificialintelligence;communityengagement;conversationalagents;middle‐outengagement;non‐human\n",
      "personas;participatorydesign;participatoryplanning\n",
      "©2025bytheauthor(s),licensedunderaCreativeCommonsAttribution4.0InternationalLicense(CCBY). 1' metadata={'producer': 'xdvipdfmx (20240407)', 'creator': 'LaTeX with hyperref', 'creationdate': '2025-01-20T14:46:41+00:00', 'moddate': '2025-01-20T15:21:30+00:00', 'title': 'AI-Supported Participatory Workshops: Middle-Out Engagement for Crisis Events', 'keywords': 'artificial intelligence; community engagement; conversational agents; middle-out engagement; non-human personas; participatory design; participatory planning', 'author': 'Martin Tomitsch, Joel Fredericks, Marius Hoggenmüller, Alexandra Crosby, Adrian Wong, Xinyan Yu, and Weidong Huang', 'source': 'uploads/3f817ad1-52b1-4940-81ea-4508d68d036f.pdf', 'total_pages': 25, 'page': 0, 'page_label': '1'}\n",
      "Loaded 16 pages from d8b986ad-cdf9-4ca7-abe1-399a5e060cf0.pdf\n",
      "\n",
      "\n",
      "page_content='Vol.:(0123456789)\n",
      "Discover Artificial Intelligence             (2022) 2:7  | https://doi.org/10.1007/s44163-022-00023-7\n",
      "1 3\n",
      "Discover Artificial Intelligence\n",
      "Perspective\n",
      "AI‑powered narrative building for facilitating public participation \n",
      "and engagement\n",
      "Fernando Marmolejo‑Ramos1 · Thomas Workman2 · Clint Walker2 · Don Lenihan3 · Sarah Moulds4 · Juan C. Correa5 · \n",
      "Anca M. Hanea6 · Belona Sonna7\n",
      "Received: 22 January 2022 / Accepted: 17 March 2022\n",
      "© The Author(s) 2022   OPEN\n",
      "Abstract\n",
      "Algorithms, data, and AI (ADA) technologies permeate most societies worldwide because of their proven benefits in \n",
      "different areas of life. Governments are the entities in charge of harnessing the benefits of ADA technologies above and \n",
      "beyond providing government services digitally. ADA technologies have the potential to transform the way govern-\n",
      "ments develop and deliver services to citizens, and the way citizens engage with their governments. Conventional public \n",
      "engagement strategies employed by governments have limited both the quality and diversity of deliberation between \n",
      "the citizen and their governments, and the potential for ADA technologies to be employed to improve the experience \n",
      "for both governments and the citizens they serve. In this article we argue that ADA technologies can improve the qual-\n",
      "ity, scope, and reach of public engagement by governments, particularly when coupled with other strategies to ensure \n",
      "legitimacy and accessibility among a broad range of communities and other stakeholders. In particular, we explore the \n",
      "role “narrative building” (NB) can play in facilitating public engagement through the use of ADA technologies. We describe \n",
      "a theoretical implementation of NB enhanced by adding natural language processing, expert knowledge elicitation, \n",
      "and semantic differential rating scales capabilities to increase gains in scale and reach. The theoretical implementation \n",
      "focuses on the public’s opinion on ADA-related technologies, and it derives implications for ethical governance.\n",
      "Keywords Narrative building · Artificial intelligence · Governance · Public affairs · Natural language processing · Expert \n",
      "knowledge elicitation\n",
      " * Fernando Marmolejo-Ramos, fernando.marmolejo-ramos@unisa.edu.au | 1Centre for Change and Complexity in Learning, The \n",
      "University of South Australia, Adelaide, SA 5000, Australia. 2Converlens Pty Ltd AU, Melbourne, Australia. 3Middle Ground Policy Research \n",
      "CA, Ottawa, Canada. 4UniSA Justice & Society, The University of South Australia, Adelaide, Australia. 5CESA Business School, Bogotá, \n",
      "Colombia. 6Ecosystem and Forest Sciences, University of Melbourne, Melbourne, Australia. 7African Institute for Mathematical Sciences, \n",
      "Kigali, Rwanda.' metadata={'producer': 'Acrobat Distiller 10.1.8 (Windows); modified using iText® 5.3.5 ©2000-2012 1T3XT BVBA (SPRINGER SBM; licensed version)', 'creator': 'Springer', 'creationdate': '2022-03-30T21:11:42+05:30', 'keywords': 'Narrative building,Artificial intelligence,Governance,Public affairs,Natural language processing,Expert knowledge elicitation', 'crossmarkdomains[1]': 'springer.com', 'moddate': '2022-03-30T23:33:13+02:00', 'crossmarkmajorversiondate': '2010-04-23', 'subject': 'Discover Artificial Intelligence, https://doi.org/10.1007/s44163-022-00023-7', 'author': 'Fernando Marmolejo-Ramos', 'title': 'AI-powered narrative building for facilitating public participation and engagement', 'crossmarkdomainexclusive': 'true', 'robots': 'noindex', 'doi': '10.1007/s44163-022-00023-7', 'crossmarkdomains[2]': 'springerlink.com', 'source': 'uploads/d8b986ad-cdf9-4ca7-abe1-399a5e060cf0.pdf', 'total_pages': 16, 'page': 0, 'page_label': '1'}\n",
      "Loaded 16 pages from ecd5a270-40f5-4d12-a4b7-199fb6644842.pdf\n",
      "\n",
      "\n",
      "page_content='Vol.:(0123456789)\n",
      "Discover Artificial Intelligence             (2022) 2:7  | https://doi.org/10.1007/s44163-022-00023-7\n",
      "1 3\n",
      "Discover Artificial Intelligence\n",
      "Perspective\n",
      "AI‑powered narrative building for facilitating public participation \n",
      "and engagement\n",
      "Fernando Marmolejo‑Ramos1 · Thomas Workman2 · Clint Walker2 · Don Lenihan3 · Sarah Moulds4 · Juan C. Correa5 · \n",
      "Anca M. Hanea6 · Belona Sonna7\n",
      "Received: 22 January 2022 / Accepted: 17 March 2022\n",
      "© The Author(s) 2022   OPEN\n",
      "Abstract\n",
      "Algorithms, data, and AI (ADA) technologies permeate most societies worldwide because of their proven benefits in \n",
      "different areas of life. Governments are the entities in charge of harnessing the benefits of ADA technologies above and \n",
      "beyond providing government services digitally. ADA technologies have the potential to transform the way govern-\n",
      "ments develop and deliver services to citizens, and the way citizens engage with their governments. Conventional public \n",
      "engagement strategies employed by governments have limited both the quality and diversity of deliberation between \n",
      "the citizen and their governments, and the potential for ADA technologies to be employed to improve the experience \n",
      "for both governments and the citizens they serve. In this article we argue that ADA technologies can improve the qual-\n",
      "ity, scope, and reach of public engagement by governments, particularly when coupled with other strategies to ensure \n",
      "legitimacy and accessibility among a broad range of communities and other stakeholders. In particular, we explore the \n",
      "role “narrative building” (NB) can play in facilitating public engagement through the use of ADA technologies. We describe \n",
      "a theoretical implementation of NB enhanced by adding natural language processing, expert knowledge elicitation, \n",
      "and semantic differential rating scales capabilities to increase gains in scale and reach. The theoretical implementation \n",
      "focuses on the public’s opinion on ADA-related technologies, and it derives implications for ethical governance.\n",
      "Keywords Narrative building · Artificial intelligence · Governance · Public affairs · Natural language processing · Expert \n",
      "knowledge elicitation\n",
      " * Fernando Marmolejo-Ramos, fernando.marmolejo-ramos@unisa.edu.au | 1Centre for Change and Complexity in Learning, The \n",
      "University of South Australia, Adelaide, SA 5000, Australia. 2Converlens Pty Ltd AU, Melbourne, Australia. 3Middle Ground Policy Research \n",
      "CA, Ottawa, Canada. 4UniSA Justice & Society, The University of South Australia, Adelaide, Australia. 5CESA Business School, Bogotá, \n",
      "Colombia. 6Ecosystem and Forest Sciences, University of Melbourne, Melbourne, Australia. 7African Institute for Mathematical Sciences, \n",
      "Kigali, Rwanda.' metadata={'producer': 'Acrobat Distiller 10.1.8 (Windows); modified using iText® 5.3.5 ©2000-2012 1T3XT BVBA (SPRINGER SBM; licensed version)', 'creator': 'Springer', 'creationdate': '2022-03-30T21:11:42+05:30', 'keywords': 'Narrative building,Artificial intelligence,Governance,Public affairs,Natural language processing,Expert knowledge elicitation', 'crossmarkdomains[1]': 'springer.com', 'moddate': '2022-03-30T23:33:13+02:00', 'crossmarkmajorversiondate': '2010-04-23', 'subject': 'Discover Artificial Intelligence, https://doi.org/10.1007/s44163-022-00023-7', 'author': 'Fernando Marmolejo-Ramos', 'title': 'AI-powered narrative building for facilitating public participation and engagement', 'crossmarkdomainexclusive': 'true', 'robots': 'noindex', 'doi': '10.1007/s44163-022-00023-7', 'crossmarkdomains[2]': 'springerlink.com', 'source': 'uploads/ecd5a270-40f5-4d12-a4b7-199fb6644842.pdf', 'total_pages': 16, 'page': 0, 'page_label': '1'}\n",
      "Loaded 5 pages from 477fef2a-5692-46f2-8db8-b988e30e67d6.pdf\n",
      "\n",
      "\n",
      "page_content='Amplifying Minority Voices: AI-Mediated Devil’s Advocate\n",
      "System for Inclusive Group Decision-Making\n",
      "Soohwan Lee∗\n",
      "Department of Design, UNIST\n",
      "Ulsan, Republic of Korea\n",
      "soohwanlee@unist.ac.kr\n",
      "Mingyu Kim∗\n",
      "Department of Design, UNIST\n",
      "Ulsan, Republic of Korea\n",
      "gyu7991@unist.ac.kr\n",
      "Seoyeong Hwang\n",
      "Department of Design, UNIST\n",
      "Ulsan, Republic of Korea\n",
      "hseoyeong@unist.ac.kr\n",
      "Dajung Kim\n",
      "Department of Design, UNIST\n",
      "Ulsan, Republic of Korea\n",
      "dajungkim@unist.ac.kr\n",
      "Kyungho Lee\n",
      "Department of Design, UNIST\n",
      "Ulsan, Republic of Korea\n",
      "kyungho@unist.ac.kr\n",
      "T h e  M a j o r i t y  ( ≥ 3 )\n",
      "w i t h  H i g h  P o w e r\n",
      "T h e  M i n o r i t y\n",
      "w i t h  L o w  P o w e r\n",
      "C o m p l i a n c e\n",
      "L L M - p o w e r e d\n",
      "D e v i l ’ s  A d v o c a t e\n",
      "S o c i a l\n",
      "I n f l u e n c e\n",
      "Figure 1: Mitigating Social Influence with an LLM-powered Devil’s Advocate. Minority members often conform to majority\n",
      "opinions due to social pressure. Our system allows minorities to share different opinions with an LLM-powered Devil’s Advocate,\n",
      "which reframes and presents them as its own. This increases psychological safety, mitigates bias, and fosters critical discussion.\n",
      "Abstract\n",
      "Group decision-making often benefits from diverse perspectives, yet\n",
      "power imbalances and social influence can stifle minority opinions\n",
      "and compromise outcomes. This prequel introduces an AI-mediated\n",
      "communication system that leverages the Large Language Model\n",
      "to serve as a devil’s advocate, representing underrepresented view-\n",
      "points without exposing minority members’ identities. Rooted in\n",
      "persuasive communication strategies and anonymity, the system\n",
      "aims to improve psychological safety and foster more inclusive\n",
      "decision-making. Our multi-agent architecture, which consists of\n",
      "∗Equally contributed to this work.\n",
      "Permission to make digital or hard copies of all or part of this work for personal or\n",
      "classroom use is granted without fee provided that copies are not made or distributed\n",
      "for profit or commercial advantage and that copies bear this notice and the full citation\n",
      "on the first page. Copyrights for third-party components of this work must be honored.\n",
      "For all other uses, contact the owner/author(s).\n",
      "IUI Companion ’25, March 24–27, 2025, Cagliari, Italy\n",
      "© 2025 Copyright held by the owner/author(s).\n",
      "ACM ISBN 979-8-4007-1409-2/25/03\n",
      "https://doi.org/10.1145/3708557.3716334\n",
      "a summary agent, conversation agent, AI duplicate checker, and\n",
      "paraphrase agent, encourages the group’s critical thinking while\n",
      "reducing repetitive outputs. We acknowledge that reliance on text-\n",
      "based communication and fixed intervention timings may limit\n",
      "adaptability, indicating pathways for refinement. By focusing on\n",
      "the representation of minority viewpoints anonymously in power-\n",
      "imbalanced settings, this approach highlights how AI-driven meth-\n",
      "ods can evolve to support more divergent and inclusive group\n",
      "decision-making.\n",
      "CCS Concepts\n",
      "• Human-centered computing → Collaborative interaction;\n",
      "Collaborative and social computing systems and tools .\n",
      "Keywords\n",
      "AI-mediated Communication; AI-assisted Decision-making, Group\n",
      "Dynamics, Social Influence, Compliance, LLM\n",
      "arXiv:2502.06251v1  [cs.HC]  10 Feb 2025' metadata={'producer': 'pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'creator': 'LaTeX with acmart 2024/05/27 v2.08 Typesetting articles for the Association for Computing Machinery and hyperref 2023-04-22 v7.00x Hypertext links for LaTeX', 'creationdate': '2025-02-11T02:22:50+00:00', 'moddate': '2025-02-11T02:22:50+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'subject': '-  Human-centered computing  ->  Collaborative interaction.Collaborative and social computing systems and tools.', 'title': \"Amplifying Minority Voices: AI-Mediated Devil's Advocate System for Inclusive Group Decision-Making\", 'trapped': '/False', 'source': 'uploads/477fef2a-5692-46f2-8db8-b988e30e67d6.pdf', 'total_pages': 5, 'page': 0, 'page_label': '1'}\n",
      "Loaded 14 pages from af4ed2a6-fdb4-47b7-8e70-a4862c28bc62.pdf\n",
      "\n",
      "\n",
      "page_content='AI and the Future of Collaborative Work: Group Ideation with an\n",
      "LLM in a Virtual Canvas\n",
      "Jessica He\n",
      "IBM Research AI\n",
      "Seattle, USA\n",
      "jessicahe@ibm.com\n",
      "Stephanie Houde\n",
      "IBM Research AI\n",
      "Cambridge, USA\n",
      "Stephanie.Houde@ibm.com\n",
      "Gabriel Enrique Gonzalez\n",
      "IBM Argentina\n",
      "Necochea, Argentina\n",
      "gabriel.gonzalez@ibm.com\n",
      "Dario Andres Silva Moran\n",
      "IBM Argentina\n",
      "La Plata, Argentina\n",
      "dario.silva@ibm.com\n",
      "Steven I. Ross\n",
      "IBM Research AI\n",
      "Cambridge, USA\n",
      "steven_ross@us.ibm.com\n",
      "Michael Muller\n",
      "IBM Research AI\n",
      "Cambridge, USA\n",
      "michael_muller@us.ibm.com\n",
      "Justin D. Weisz\n",
      "IBM Research AI\n",
      "Yorktown Heights, USA\n",
      "jweisz@us.ibm.com\n",
      "ABSTRACT\n",
      "The introduction of generative AI into multi-user applications raises\n",
      "novel considerations for the future of collaborative work. How\n",
      "might collaborative work practices change? How might we incor-\n",
      "porate generative AI into shared tools with users’ needs at the\n",
      "forefront? We examine these questions in the context of a remote\n",
      "team conducting ideation tasks – an example of collaborative work\n",
      "enabled by a shared digital workspace. We conducted a user study\n",
      "with 17 professionals experienced with virtual group ideation work-\n",
      "shops. Our study examined their use of the Collaborative Canvas , a\n",
      "virtual canvas tool with integrated generative AI capabilities that\n",
      "we created as a probe. Participants saw value in using generative\n",
      "AI to assist with group facilitation and to augment perspectives\n",
      "and ideas. However, they worried about losing human perspectives\n",
      "and critical thinking, as well as reputational harms resulting from\n",
      "harmful AI outputs. Participants shared suggestions for appropriate\n",
      "ways to incorporate generative AI capabilities within multi-user\n",
      "applications and identified needs for transparency of content own-\n",
      "ership, private digital spaces, and specialized AI capabilities. Based\n",
      "on participants’ insights, we share implications and opportunities\n",
      "for the incorporation of generative AI into collaborative work in\n",
      "ways that place user needs at the forefront.\n",
      "CCS CONCEPTS\n",
      "• Human-centered computing →Empirical studies in HCI ;\n",
      "Empirical studies in collaborative and social computing ; •\n",
      "Computing methodologies →Artificial intelligence.\n",
      "This work is licensed under a Creative Commons Attribution-NonCommercial\n",
      "International 4.0 License.\n",
      "CHIWORK ’24, June 25–27, 2024, Newcastle upon Tyne, United Kingdom\n",
      "© 2024 Copyright held by the owner/author(s).\n",
      "ACM ISBN 979-8-4007-1017-9/24/06\n",
      "https://doi.org/10.1145/3663384.3663398\n",
      "KEYWORDS\n",
      "Group ideation, Brainstorming, Shared virtual canvas, Mixed initia-\n",
      "tive, Generative AI, Future of work\n",
      "ACM Reference Format:\n",
      "Jessica He, Stephanie Houde, Gabriel Enrique Gonzalez, Dario Andres Silva\n",
      "Moran, Steven I. Ross, Michael Muller, and Justin D. Weisz. 2024. AI and\n",
      "the Future of Collaborative Work: Group Ideation with an LLM in a Virtual\n",
      "Canvas. In Proceedings of the 3rd Annual Meeting of the Symposium on\n",
      "Human-Computer Interaction for Work (CHIWORK ’24), June 25–27, 2024,\n",
      "Newcastle upon Tyne, United Kingdom. ACM, New York, NY, USA, 14 pages.\n",
      "https://doi.org/10.1145/3663384.3663398\n",
      "1 INTRODUCTION\n",
      "Generative AI has the potential to automate tasks that were pre-\n",
      "viously thought to be exclusive to humans, raising questions of\n",
      "its impact on the future of work. Rapid advancements in gener-\n",
      "ative AI have already enabled its incorporation into professional\n",
      "work domains such as programming [ 95], research [ 1, 60], and\n",
      "design [41, 57, 113]. In these domains, generative AI can produce\n",
      "ideas, summaries, and suggestions that rival those produced by\n",
      "humans.\n",
      "In the past, many research studies on AI-augmented work have\n",
      "been configured such that one human works with a single AI agent\n",
      "(e.g., [55, 94, 119, 122]). Work by Farrell et al. [26] took an expanded\n",
      "view in which a human works with a back-end collection of AI\n",
      "agents, through a single front-end interface [26]. However, this view\n",
      "does not reflect the reality that work is often performed by groups\n",
      "of colleagues working together [104, 116, 127]. As advancements in\n",
      "generative AI make their way into collaborative domains, there is a\n",
      "need to shift our view to realistic work contexts in which multiple\n",
      "humans interact with each other along with AI agents.\n",
      "One indication of the rise of AI-supported group work is in the\n",
      "introduction of generative AI features to digital canvas tools such as\n",
      "Mural1, Miro2, and Microsoft Whiteboard3. These features include\n",
      "1Mural. https://mural.co\n",
      "2Miro. https://miro.com\n",
      "3Microsoft Whiteboard. https://whiteboard.microsoft.com' metadata={'producer': 'pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5; modified using iText 4.2.0 by 1T3XT', 'creator': 'LaTeX with acmart 2024/04/17 v2.07 Typesetting articles for the Association for Computing Machinery and hyperref 2023-02-07 v7.00v Hypertext links for LaTeX', 'creationdate': '2024-05-06T19:54:44+00:00', 'moddate': '2025-03-20T06:29:09-07:00', 'trapped': '/False', 'subject': '-  Human-centered computing  ->  Empirical studies in HCI.Empirical studies in collaborative and social computing.-  Computing methodologies  ->  Artificial intelligence.', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'title': 'AI and the Future of Collaborative Work: Group Ideation with an LLM in a Virtual Canvas', 'source': 'uploads/af4ed2a6-fdb4-47b7-8e70-a4862c28bc62.pdf', 'total_pages': 14, 'page': 0, 'page_label': '1'}\n",
      "Loaded 22 pages from 1c195e0c-61ca-438e-b139-783bff70ab4b.pdf\n",
      "\n",
      "\n",
      "page_content='Technology in Society 78 (2024) 102662\n",
      "Available online 17 July 2024\n",
      "0160-791X/© 2024 The Authors. Published by Elsevier Ltd. This is an open access article under the CC BY-NC-ND license (http://creativecommons.org/licenses/by-\n",
      "nc-nd/4.0/).\n",
      "Exploring collaborative decision-making: A quasi-experimental study of\n",
      "human and Generative AI interaction\n",
      "Xinyue Hao\n",
      "*\n",
      ", Emrah Demir , Daniel Eyers\n",
      "Logistics & Operations Management Section, Cardiff Business School, Cardiff University, Cardiff CF10 3EU, United Kingdom\n",
      "ARTICLE INFO\n",
      "Keywords:\n",
      "ChatGPT\n",
      "Artificial intelligence\n",
      "Human intuition\n",
      "Decision-making\n",
      "Cognitive biases\n",
      "ABSTRACT\n",
      "This paper explores the effects of integrating Generative Artificial Intelligence (GAI) into decision-making pro-\n",
      "cesses within organizations, employing a quasi-experimental pretest-posttest design. The study examines the\n",
      "synergistic interaction between Human Intelligence (HI) and GAI across four group decision-making scenarios\n",
      "within three global organizations renowned for their cutting-edge operational techniques. The research pro-\n",
      "gresses through several phases: identifying research problems, collecting baseline data on decision-making,\n",
      "implementing AI interventions, and evaluating the outcomes post-intervention to identify shifts in perfor-\n",
      "mance. The results demonstrate that GAI effectively reduces human cognitive burdens and mitigates heuristic\n",
      "biases by offering data-driven support and predictive analytics, grounded in System 2 reasoning. This is\n",
      "particularly valuable in complex situations characterized by unfamiliarity and information overload, where\n",
      "intuitive, System 1 thinking is less effective. However, the study also uncovers challenges related to GAI inte-\n",
      "gration, such as potential over-reliance on technology, intrinsic biases particularly ‘out-of-the-box ’ thinking\n",
      "without contextual creativity. To address these issues, this paper proposes an innovative strategic framework for\n",
      "HI-GAI collaboration that emphasizes transparency, accountability, and inclusiveness.\n",
      "1. Introduction\n",
      "The release of ChatGPT on November 30, 2022 [ 1 ], coincided with\n",
      "the aftermath of a global pandemic, was within a period characterized\n",
      "by significant societal and technological transformations. Before the\n",
      "introduction of Generative AI (GAI), ‘traditional AI ’ , which requires\n",
      "structured data for model construction and information processing,\n",
      "including neural networks, evolutionary algorithms, decision trees,\n",
      "random forests, support vector machines, and k-means clustering were\n",
      "already widespread [ 2 ]. Traditional AI was integrated into applications\n",
      "that influenced pricing, inventory management, logistic optimization,\n",
      "content recommendation etc., but were somewhat restricted in their\n",
      "functionality and had difficulties in directly interacting with users [ 3 ].\n",
      "In contrast, GAI technologies such as ChatGPT introduced a user inter-\n",
      "face that made AI both accessible and a regular part of daily technology\n",
      "use [ 4 ]. This made a significant shift towards direct human-AI collabo-\n",
      "ration [ 5 ]. This ease of use and direct interaction has ushered in a new\n",
      "era of machine-driven intelligence, where technological advances have\n",
      "outpaced organizational understanding of their effective management\n",
      "and exploitation.\n",
      "In the traditional paradigms of organizational decision-making,\n",
      "human intelligence (HI) whether individual or collective, is distin-\n",
      "guished by a blend of intuitive perception, emotional sensitivity, and\n",
      "cultural cognizance, that resonates across scenarios, from executing\n",
      "immediate, task-specific objectives [ 6 ] to strategizing for comprehen-\n",
      "sive, long-term aspirations [ 7 ]. These intrinsic human cognitive abilities\n",
      "inject creative and deep-seated insights into the strategic framework,\n",
      "thus equipping the organization with the fitness to adeptly steer through\n",
      "market fluctuations, competitive pressures, and technological ad-\n",
      "vancements [ 8 ]. Where teams must interact dynamically with constantly\n",
      "changing external variables, the comprehensive range of human cogni-\n",
      "tive skills is essential for plotting pathways through ambiguous situa-\n",
      "tions and capitalizing on the opportunities that such adaptability affords\n",
      "[ 9 ]. However, cognitive, and heuristic biases, essentially ‘rule of thumb ’\n",
      "or ‘mental shortcuts ’ evolved for information-processing efficiency [ 10 ],\n",
      "can sometimes be advantageous but often constrict perception and\n",
      "engender systematic errors in judgment, frequently leading to distorted\n",
      "reasoning and suboptimal decision-making outcomes [ 11 ]. High reli-\n",
      "ance on familiar biases can overshadow data-driven analysis. The latest\n",
      "iteration, GPT-4o ( “ o ” for “ omni ” ), expands on GPT-4 with 1.76 trillion\n",
      "* Corresponding author.\n",
      "E-mail address: haox2@cardiff.ac.uk (X. Hao).\n",
      "Contents lists available at ScienceDirect\n",
      "Technology in Society\n",
      "journal homep age: www.el sevier.com/l ocate/techso c\n",
      "https://doi.org/10.1016/j.techsoc.2024.102662\n",
      "Received 22 January 2024; Received in revised form 3 June 2024; Accepted 14 July 2024' metadata={'producer': 'Acrobat Distiller 8.1.0 (Windows)', 'creator': 'Elsevier', 'creationdate': '2024-07-19T14:48:15+00:00', 'crossmarkdomains[1]': 'elsevier.com', 'creationdate--text': '20th July 2024', 'robots': 'noindex', 'elsevierwebpdfspecifications': '7.0', 'moddate': '2024-07-20T09:27:48+00:00', 'doi': '10.1016/j.techsoc.2024.102662', 'keywords': 'ChatGPT,Artificial intelligence,Human intuition,Decision-making,Cognitive biases', 'title': 'Exploring collaborative decision-making: A quasi-experimental study of human and Generative AI interaction', 'subject': 'Technology in Society, 78 (2024) 102662. doi:10.1016/j.techsoc.2024.102662', 'crossmarkdomains[2]': 'sciencedirect.com', 'author': 'Xinyue Hao', 'source': 'uploads/1c195e0c-61ca-438e-b139-783bff70ab4b.pdf', 'total_pages': 22, 'page': 0, 'page_label': '1'}\n",
      "Loaded 17 pages from fb231ae5-21ff-47a1-be36-9d3fb70c21dd.pdf\n",
      "\n",
      "\n",
      "page_content='Journal of Public Administration Research and Theory, 2023, 33, 153–169\n",
      "https://doi.org/10.1093/jopart/muac007\n",
      "Advance access publication 8 February 2022\n",
      "Article\n",
      "Human–AI Interactions in Public Sector Decision Making: \n",
      "“ Automation Bias” and “Selective Adherence” to \n",
      "Algorithmic Advice\n",
      "Saar Alon-Barkat,*,  Madalina Busuioc†,\n",
      "*University of Haifa, Israel\n",
      "†Vrije Universiteit Amsterdam, The Netherlands\n",
      "Address correspondence to the author at e.m.busuioc@vu.nl.\n",
      "Abstract \n",
      "Artificial intelligence algorithms are increasingly adopted as decisional aides by public bodies, with the promise of overcoming biases of human \n",
      "decision-makers. At the same time, they may introduce new biases in the human–algorithm interaction. Drawing on psychology and public \n",
      "administration literatures, we investigate two key biases: overreliance on algorithmic advice even in the face of “warning signals” from other \n",
      "sources (automation bias), and selective adoption of algorithmic advice when this corresponds to stereotypes (selective adherence). We assess \n",
      "these via three experimental studies conducted in the Netherlands: In study 1 (N = 605), we test automation bias by exploring participants’ \n",
      "adherence to an algorithmic prediction compared to an equivalent human-expert prediction. We do not find evidence for automation bias. In \n",
      "study 2 (N = 904), we replicate these findings, and also test selective adherence. We find a stronger propensity for adherence when the advice \n",
      "is aligned with group stereotypes, with no significant differences between algorithmic and human-expert advice. In study 3 (N = 1,345), we \n",
      "replicate our design with a sample of civil servants. This study was conducted shortly after a major scandal involving public authorities’ reliance \n",
      "on an algorithm with discriminatory outcomes (the “childcare benefits scandal”). The scandal is itself illustrative of our theory and patterns \n",
      "diagnosed empirically in our experiment, yet in our study 3, while supporting our prior findings as to automation bias, we do not find patterns of \n",
      "selective adherence. We suggest this is driven by bureaucrats’ enhanced awareness of discrimination and algorithmic biases in the aftermath of \n",
      "the scandal. We discuss the implications of our findings for public sector decision making in the age of automation. Overall, our study speaks to \n",
      "potential negative effects of automation of the administrative state for already vulnerable and disadvantaged citizens.\n",
      "Introduction\n",
      "Artificial intelligence (AI) algorithms are being widely adopted \n",
      "in the public sector across jurisdictions. Essentially a set of tools \n",
      "that display (or can even surpass) human-level performance \n",
      "on given tasks traditionally associated with human intelli-\n",
      "gence, AI algorithms are being relied upon in areas as varied as \n",
      "policing, welfare, criminal justice, healthcare, immigration, or \n",
      "education (Busuioc 2021; Calo and Citron 2021; Diakopoulos \n",
      "2014; Eubanks 2018; Engstrom et al. 2020; O’Neil 2016; \n",
      "Richardson, Schultz, and Crawford 2019; Veale and Brass \n",
      "2019; Yeung and Lodge 2019), increasingly permeating  \n",
      "non-routine and high-stakes aspects of bureaucratic work. The \n",
      "growing and deepening reliance on AI and machine learning \n",
      "technologies in the public sector has been diagnosed as “trans-\n",
      "formative” of public administrations (Bullock 2019; Vogl et al. \n",
      "2020; Young, Bullock, and Lecy 2019).\n",
      "These developments are driven by the promise of policy \n",
      "solutions that are potentially more effective, efficient, and \n",
      "low-cost. In addition, and importantly, algorithms are said to \n",
      "come with the “promise of neutrality,” in contrast to decision \n",
      "making based on human intuition, which involves biases and \n",
      "can result in discrimination. In other words, AI use in deci-\n",
      "sion making is said to hold the potential to help us overcome \n",
      "our cognitive biases and limitations. This has been an impor-\n",
      "tant driver for the adoption of such technologies in highly \n",
      "consequential public sector areas such as law enforcement or \n",
      "criminal justice: Predictive policing technologies, for instance, \n",
      "were propagated in the US context “as one answer to racially \n",
      "discriminatory policing, offering a seemingly race-neutral, ‘ob-\n",
      "jective’ justification for police targeting of poor communities” \n",
      "(Ferguson 2017, 5). Numerous other jurisdictions have \n",
      "followed suit with predictive technologies relied upon by po-\n",
      "lice forces in the United Kingdom, the Netherlands, Germany, \n",
      "among many others. Like rationales precipitated the adoption \n",
      "of predictive risk assessment systems in criminal justice, sim-\n",
      "ilarly in part in response to concerns with human bias and \n",
      "discrimination (Israni 2017), despite such systems themselves \n",
      "being flagged as sources of bias (Angwin et al. 2016).\n",
      "For a large part, AI algorithms currently serve as decisional \n",
      "aides to human decision-makers (“decision-support sys-\n",
      "tems”) in many bureaucratic contexts. This is especially so \n",
      "in highly consequential public sector areas, where “full au-\n",
      "tomation seems inappropriate or far off” (Edward and Veale \n",
      "2017, 45). Rather than making decisions on their own, al-\n",
      "gorithmic outputs—be they risk assessment scores used in \n",
      "criminal justice or the algorithm-generated “heat maps” of \n",
      "© The Author(s) 2022. Published by Oxford University Press on behalf of the Public Management Research Association.\n",
      "This is an Open Access article distributed under the terms of the Creative Commons Attribution-NonCommercial License (https://creativecommons.org/\n",
      "licenses/by-nc/4.0/), which permits non-commercial re-use, distribution, and reproduction in any medium, provided the original work is properly cited. For \n",
      "commercial re-use, please contact journals.permissions@oup.com\n",
      "We thank the three anonymous JPART reviewers for their extremely help-\n",
      "ful comments. We are also grateful to Dimiter Toshkov, Nadine Raaphorst, \n",
      "Joris van der Voet, Dana Vashdi, Sharon Gilad, Markus Tepe, Stephan \n",
      "Grimmelikhuijsen, Thijs de Boer, Benjamin Tidå, Omer Yair, and Aaron \n",
      "Swaving for their valuable comments and feedback in the process of devel-\n",
      "oping this project. We thank Luuk van Roozendaal for excellent research \n",
      "assistance.\n",
      "Downloaded from https://academic.oup.com/jpart/article/33/1/153/6524536 by guest on 21 March 2025' metadata={'producer': 'Adobe PDF Library 15.0; modified using iTextSharp 4.1.6 by 1T3XT', 'creator': 'Adobe InDesign 15.1 (Windows)', 'creationdate': '2022-12-23T18:23:16+05:30', 'trapped': '/False', 'moddate': '2025-03-21T10:34:28+00:00', 'source': 'uploads/fb231ae5-21ff-47a1-be36-9d3fb70c21dd.pdf', 'total_pages': 17, 'page': 0, 'page_label': '153'}\n",
      "Loaded 14 pages from 59a363d5-59f9-42de-a934-b463e7975ffd.pdf\n",
      "\n",
      "\n",
      "page_content='AI and the Future of Collaborative Work: Group Ideation with an\n",
      "LLM in a Virtual Canvas\n",
      "Jessica He\n",
      "IBM Research AI\n",
      "Seattle, USA\n",
      "jessicahe@ibm.com\n",
      "Stephanie Houde\n",
      "IBM Research AI\n",
      "Cambridge, USA\n",
      "Stephanie.Houde@ibm.com\n",
      "Gabriel Enrique Gonzalez\n",
      "IBM Argentina\n",
      "Necochea, Argentina\n",
      "gabriel.gonzalez@ibm.com\n",
      "Dario Andres Silva Moran\n",
      "IBM Argentina\n",
      "La Plata, Argentina\n",
      "dario.silva@ibm.com\n",
      "Steven I. Ross\n",
      "IBM Research AI\n",
      "Cambridge, USA\n",
      "steven_ross@us.ibm.com\n",
      "Michael Muller\n",
      "IBM Research AI\n",
      "Cambridge, USA\n",
      "michael_muller@us.ibm.com\n",
      "Justin D. Weisz\n",
      "IBM Research AI\n",
      "Yorktown Heights, USA\n",
      "jweisz@us.ibm.com\n",
      "ABSTRACT\n",
      "The introduction of generative AI into multi-user applications raises\n",
      "novel considerations for the future of collaborative work. How\n",
      "might collaborative work practices change? How might we incor-\n",
      "porate generative AI into shared tools with users’ needs at the\n",
      "forefront? We examine these questions in the context of a remote\n",
      "team conducting ideation tasks – an example of collaborative work\n",
      "enabled by a shared digital workspace. We conducted a user study\n",
      "with 17 professionals experienced with virtual group ideation work-\n",
      "shops. Our study examined their use of the Collaborative Canvas , a\n",
      "virtual canvas tool with integrated generative AI capabilities that\n",
      "we created as a probe. Participants saw value in using generative\n",
      "AI to assist with group facilitation and to augment perspectives\n",
      "and ideas. However, they worried about losing human perspectives\n",
      "and critical thinking, as well as reputational harms resulting from\n",
      "harmful AI outputs. Participants shared suggestions for appropriate\n",
      "ways to incorporate generative AI capabilities within multi-user\n",
      "applications and identified needs for transparency of content own-\n",
      "ership, private digital spaces, and specialized AI capabilities. Based\n",
      "on participants’ insights, we share implications and opportunities\n",
      "for the incorporation of generative AI into collaborative work in\n",
      "ways that place user needs at the forefront.\n",
      "CCS CONCEPTS\n",
      "• Human-centered computing →Empirical studies in HCI ;\n",
      "Empirical studies in collaborative and social computing ; •\n",
      "Computing methodologies →Artificial intelligence.\n",
      "This work is licensed under a Creative Commons Attribution-NonCommercial\n",
      "International 4.0 License.\n",
      "CHIWORK ’24, June 25–27, 2024, Newcastle upon Tyne, United Kingdom\n",
      "© 2024 Copyright held by the owner/author(s).\n",
      "ACM ISBN 979-8-4007-1017-9/24/06\n",
      "https://doi.org/10.1145/3663384.3663398\n",
      "KEYWORDS\n",
      "Group ideation, Brainstorming, Shared virtual canvas, Mixed initia-\n",
      "tive, Generative AI, Future of work\n",
      "ACM Reference Format:\n",
      "Jessica He, Stephanie Houde, Gabriel Enrique Gonzalez, Dario Andres Silva\n",
      "Moran, Steven I. Ross, Michael Muller, and Justin D. Weisz. 2024. AI and\n",
      "the Future of Collaborative Work: Group Ideation with an LLM in a Virtual\n",
      "Canvas. In Proceedings of the 3rd Annual Meeting of the Symposium on\n",
      "Human-Computer Interaction for Work (CHIWORK ’24), June 25–27, 2024,\n",
      "Newcastle upon Tyne, United Kingdom. ACM, New York, NY, USA, 14 pages.\n",
      "https://doi.org/10.1145/3663384.3663398\n",
      "1 INTRODUCTION\n",
      "Generative AI has the potential to automate tasks that were pre-\n",
      "viously thought to be exclusive to humans, raising questions of\n",
      "its impact on the future of work. Rapid advancements in gener-\n",
      "ative AI have already enabled its incorporation into professional\n",
      "work domains such as programming [ 95], research [ 1, 60], and\n",
      "design [41, 57, 113]. In these domains, generative AI can produce\n",
      "ideas, summaries, and suggestions that rival those produced by\n",
      "humans.\n",
      "In the past, many research studies on AI-augmented work have\n",
      "been configured such that one human works with a single AI agent\n",
      "(e.g., [55, 94, 119, 122]). Work by Farrell et al. [26] took an expanded\n",
      "view in which a human works with a back-end collection of AI\n",
      "agents, through a single front-end interface [26]. However, this view\n",
      "does not reflect the reality that work is often performed by groups\n",
      "of colleagues working together [104, 116, 127]. As advancements in\n",
      "generative AI make their way into collaborative domains, there is a\n",
      "need to shift our view to realistic work contexts in which multiple\n",
      "humans interact with each other along with AI agents.\n",
      "One indication of the rise of AI-supported group work is in the\n",
      "introduction of generative AI features to digital canvas tools such as\n",
      "Mural1, Miro2, and Microsoft Whiteboard3. These features include\n",
      "1Mural. https://mural.co\n",
      "2Miro. https://miro.com\n",
      "3Microsoft Whiteboard. https://whiteboard.microsoft.com' metadata={'producer': 'pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5; modified using iText 4.2.0 by 1T3XT', 'creator': 'LaTeX with acmart 2024/04/17 v2.07 Typesetting articles for the Association for Computing Machinery and hyperref 2023-02-07 v7.00v Hypertext links for LaTeX', 'creationdate': '2024-05-06T19:54:44+00:00', 'moddate': '2025-03-20T06:29:09-07:00', 'trapped': '/False', 'subject': '-  Human-centered computing  ->  Empirical studies in HCI.Empirical studies in collaborative and social computing.-  Computing methodologies  ->  Artificial intelligence.', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'title': 'AI and the Future of Collaborative Work: Group Ideation with an LLM in a Virtual Canvas', 'source': 'uploads/59a363d5-59f9-42de-a934-b463e7975ffd.pdf', 'total_pages': 14, 'page': 0, 'page_label': '1'}\n",
      "Loaded 22 pages from 7f5bf4f2-21f1-4fd9-8f96-96223b9c1112.pdf\n",
      "\n",
      "\n",
      "page_content='Technology in Society 78 (2024) 102662\n",
      "Available online 17 July 2024\n",
      "0160-791X/© 2024 The Authors. Published by Elsevier Ltd. This is an open access article under the CC BY-NC-ND license (http://creativecommons.org/licenses/by-\n",
      "nc-nd/4.0/).\n",
      "Exploring collaborative decision-making: A quasi-experimental study of\n",
      "human and Generative AI interaction\n",
      "Xinyue Hao\n",
      "*\n",
      ", Emrah Demir , Daniel Eyers\n",
      "Logistics & Operations Management Section, Cardiff Business School, Cardiff University, Cardiff CF10 3EU, United Kingdom\n",
      "ARTICLE INFO\n",
      "Keywords:\n",
      "ChatGPT\n",
      "Artificial intelligence\n",
      "Human intuition\n",
      "Decision-making\n",
      "Cognitive biases\n",
      "ABSTRACT\n",
      "This paper explores the effects of integrating Generative Artificial Intelligence (GAI) into decision-making pro-\n",
      "cesses within organizations, employing a quasi-experimental pretest-posttest design. The study examines the\n",
      "synergistic interaction between Human Intelligence (HI) and GAI across four group decision-making scenarios\n",
      "within three global organizations renowned for their cutting-edge operational techniques. The research pro-\n",
      "gresses through several phases: identifying research problems, collecting baseline data on decision-making,\n",
      "implementing AI interventions, and evaluating the outcomes post-intervention to identify shifts in perfor-\n",
      "mance. The results demonstrate that GAI effectively reduces human cognitive burdens and mitigates heuristic\n",
      "biases by offering data-driven support and predictive analytics, grounded in System 2 reasoning. This is\n",
      "particularly valuable in complex situations characterized by unfamiliarity and information overload, where\n",
      "intuitive, System 1 thinking is less effective. However, the study also uncovers challenges related to GAI inte-\n",
      "gration, such as potential over-reliance on technology, intrinsic biases particularly ‘out-of-the-box ’ thinking\n",
      "without contextual creativity. To address these issues, this paper proposes an innovative strategic framework for\n",
      "HI-GAI collaboration that emphasizes transparency, accountability, and inclusiveness.\n",
      "1. Introduction\n",
      "The release of ChatGPT on November 30, 2022 [ 1 ], coincided with\n",
      "the aftermath of a global pandemic, was within a period characterized\n",
      "by significant societal and technological transformations. Before the\n",
      "introduction of Generative AI (GAI), ‘traditional AI ’ , which requires\n",
      "structured data for model construction and information processing,\n",
      "including neural networks, evolutionary algorithms, decision trees,\n",
      "random forests, support vector machines, and k-means clustering were\n",
      "already widespread [ 2 ]. Traditional AI was integrated into applications\n",
      "that influenced pricing, inventory management, logistic optimization,\n",
      "content recommendation etc., but were somewhat restricted in their\n",
      "functionality and had difficulties in directly interacting with users [ 3 ].\n",
      "In contrast, GAI technologies such as ChatGPT introduced a user inter-\n",
      "face that made AI both accessible and a regular part of daily technology\n",
      "use [ 4 ]. This made a significant shift towards direct human-AI collabo-\n",
      "ration [ 5 ]. This ease of use and direct interaction has ushered in a new\n",
      "era of machine-driven intelligence, where technological advances have\n",
      "outpaced organizational understanding of their effective management\n",
      "and exploitation.\n",
      "In the traditional paradigms of organizational decision-making,\n",
      "human intelligence (HI) whether individual or collective, is distin-\n",
      "guished by a blend of intuitive perception, emotional sensitivity, and\n",
      "cultural cognizance, that resonates across scenarios, from executing\n",
      "immediate, task-specific objectives [ 6 ] to strategizing for comprehen-\n",
      "sive, long-term aspirations [ 7 ]. These intrinsic human cognitive abilities\n",
      "inject creative and deep-seated insights into the strategic framework,\n",
      "thus equipping the organization with the fitness to adeptly steer through\n",
      "market fluctuations, competitive pressures, and technological ad-\n",
      "vancements [ 8 ]. Where teams must interact dynamically with constantly\n",
      "changing external variables, the comprehensive range of human cogni-\n",
      "tive skills is essential for plotting pathways through ambiguous situa-\n",
      "tions and capitalizing on the opportunities that such adaptability affords\n",
      "[ 9 ]. However, cognitive, and heuristic biases, essentially ‘rule of thumb ’\n",
      "or ‘mental shortcuts ’ evolved for information-processing efficiency [ 10 ],\n",
      "can sometimes be advantageous but often constrict perception and\n",
      "engender systematic errors in judgment, frequently leading to distorted\n",
      "reasoning and suboptimal decision-making outcomes [ 11 ]. High reli-\n",
      "ance on familiar biases can overshadow data-driven analysis. The latest\n",
      "iteration, GPT-4o ( “ o ” for “ omni ” ), expands on GPT-4 with 1.76 trillion\n",
      "* Corresponding author.\n",
      "E-mail address: haox2@cardiff.ac.uk (X. Hao).\n",
      "Contents lists available at ScienceDirect\n",
      "Technology in Society\n",
      "journal homep age: www.el sevier.com/l ocate/techso c\n",
      "https://doi.org/10.1016/j.techsoc.2024.102662\n",
      "Received 22 January 2024; Received in revised form 3 June 2024; Accepted 14 July 2024' metadata={'producer': 'Acrobat Distiller 8.1.0 (Windows)', 'creator': 'Elsevier', 'creationdate': '2024-07-19T14:48:15+00:00', 'crossmarkdomains[1]': 'elsevier.com', 'creationdate--text': '20th July 2024', 'robots': 'noindex', 'elsevierwebpdfspecifications': '7.0', 'moddate': '2024-07-20T09:27:48+00:00', 'doi': '10.1016/j.techsoc.2024.102662', 'keywords': 'ChatGPT,Artificial intelligence,Human intuition,Decision-making,Cognitive biases', 'title': 'Exploring collaborative decision-making: A quasi-experimental study of human and Generative AI interaction', 'subject': 'Technology in Society, 78 (2024) 102662. doi:10.1016/j.techsoc.2024.102662', 'crossmarkdomains[2]': 'sciencedirect.com', 'author': 'Xinyue Hao', 'source': 'uploads/7f5bf4f2-21f1-4fd9-8f96-96223b9c1112.pdf', 'total_pages': 22, 'page': 0, 'page_label': '1'}\n",
      "Loaded 25 pages from 077f6293-0bcf-48dc-9b9d-a6166857e3c1.pdf\n",
      "\n",
      "\n",
      "page_content='Urban Planning\n",
      "2025 • Volume 10• Article 9165\n",
      "https://doi.org/10.17645/up.9165\n",
      "A R T I C L E Open Access Journal\n",
      "AI‐Supported Participatory Workshops: Middle‐Out Engagement\n",
      "for Crisis Events\n",
      "Martin Tomitsch1\n",
      " , Joel Fredericks2\n",
      " , Marius Hoggenmüller2\n",
      " , Alexandra Crosby3\n",
      " ,\n",
      "Adrian Wong2\n",
      " , Xinyan Yu2\n",
      " , and Weidong Huang1\n",
      "1 TransdisciplinarySchool,UniversityofTechnologySydney,Australia\n",
      "2 SchoolofArchitecture,DesignandPlanning,TheUniversityofSydney,Australia\n",
      "3 FacultyofDesign,ArchitectureandBuilding,UniversityofTechnologySydney,Australia\n",
      "Correspondence: MartinTomitsch(martin.tomitsch@uts.edu.au)\n",
      "Submitted: 9August2024 Accepted: 5November2024 Published: 27January2025\n",
      "Issue: This article is part of the issue “The Role of Participatory Planning and Design in Addressing the\n",
      "UN Sustainable Development Goals” edited by Hilary Davis (Swinburne University of Technology), Joel\n",
      "Fredericks(TheUniversityofSydney),MarcusFoth(QueenslandUniversityofTechnology),GlendaCaldwell\n",
      "(QueenslandUniversityofTechnology),andCallumParker(TheUniversityofSydney),fullyopenaccessat\n",
      "https://doi.org/10.17645/up.i394\n",
      "Abstract\n",
      "Consideringthelivedexperienceofcommunitiesiskeywhenmakingdecisionsincomplexscenarios,suchas\n",
      "preparingforandrespondingtocrisisevents.Thearticlereportsonthreeparticipatoryworkshops,which\n",
      "assigned community representative roles to workshop participants. Using role‐playing as a method,\n",
      "participantsweregiventhetaskofcollaboratingonmakingadecisionrelatingtoaspeculativecrisisscenario.\n",
      "Acrosstheworkshops,wecollecteddataaboutsimulatingamiddle‐outengagementapproachandtherole\n",
      "of artificial intelligence (AI) in enhancing collaboration, supporting decision‐making, and representing\n",
      "non‐humanactors.Thearticlemakesthreecontributionstoparticipatoryplanninganddesigninthecontext\n",
      "of the UN Sustainable Development Goals. First, it presents insights about the use of AI in enhancing\n",
      "collaboration and decision‐making in crisis event situations. Second, it discusses approaches for bringing\n",
      "more‐than‐human considerations into participatory planning and design. Third, it reflects on the value of\n",
      "role‐playingasawaytosimulateamiddle‐outengagementprocess,wherebyactorsfromthetopandthe\n",
      "bottomcollaboratetowardsmakinginformeddecisionsincomplexscenarios.Drawingonthefindingsfrom\n",
      "theworkshops,thearticlecriticallyreflectsonchallengesandrisksassociatedwithusingAIinparticipatory\n",
      "workshopsandcollaborativedecision‐making.\n",
      "Keywords\n",
      "artificialintelligence;communityengagement;conversationalagents;middle‐outengagement;non‐human\n",
      "personas;participatorydesign;participatoryplanning\n",
      "©2025bytheauthor(s),licensedunderaCreativeCommonsAttribution4.0InternationalLicense(CCBY). 1' metadata={'producer': 'xdvipdfmx (20240407)', 'creator': 'LaTeX with hyperref', 'creationdate': '2025-01-20T14:46:41+00:00', 'moddate': '2025-01-20T15:21:30+00:00', 'title': 'AI-Supported Participatory Workshops: Middle-Out Engagement for Crisis Events', 'keywords': 'artificial intelligence; community engagement; conversational agents; middle-out engagement; non-human personas; participatory design; participatory planning', 'author': 'Martin Tomitsch, Joel Fredericks, Marius Hoggenmüller, Alexandra Crosby, Adrian Wong, Xinyan Yu, and Weidong Huang', 'source': 'uploads/077f6293-0bcf-48dc-9b9d-a6166857e3c1.pdf', 'total_pages': 25, 'page': 0, 'page_label': '1'}\n",
      "Loaded 26 pages from 5abea51a-c849-49ef-b206-ebd17f831a3b.pdf\n",
      "\n",
      "\n",
      "page_content='LM Agents for Coordinating Multi-User Information Gathering\n",
      "Harsh Jhamtani, Jacob Andreas, Benjamin Van Durme\n",
      "Microsoft\n",
      "{hjhamtani,jaandrea,ben.vandurme}@microsoft.com\n",
      "Abstract\n",
      "This paper introduces PEOPLE JOIN , a bench-\n",
      "mark for evaluating LM-mediated collaborative\n",
      "problem solving. Given a user request, PEO-\n",
      "PLE JOIN agents must identify teammates who\n",
      "might be able to assist, converse with these\n",
      "teammates to gather information, and finally\n",
      "compile a useful answer or summary for the\n",
      "original user. PEOPLE JOIN comprises two eval-\n",
      "uation domains: PEOPLE JOIN -QA, focused on\n",
      "questions about tabular data, and PEOPLE JOIN -\n",
      "DOCCREATION , focused on document creation\n",
      "tasks. The two domains are adapted from ex-\n",
      "isting NLP benchmarks for database question\n",
      "answering and multi-document summarization;\n",
      "here, however, the information needed to com-\n",
      "plete these tasks is distributed across synthetic\n",
      "“organizations” of 2–20 users, simulating natu-\n",
      "ral multi-user collaboration scenarios. We im-\n",
      "plemented several popular LM agent architec-\n",
      "tures, evaluating their accuracy and efficiency\n",
      "at completing tasks, and highlight new research\n",
      "questions that can be studied using PEOPLE -\n",
      "JOIN .1\n",
      "1 Introduction\n",
      "In today’s fast-paced and interconnected world,\n",
      "effective collaboration is essential for achieving\n",
      "complex tasks and making informed decisions\n",
      "(Papachristou et al., 2023; Gemp et al., 2024).\n",
      "Many decision-making, content creation, and\n",
      "information-gathering tasks require collecting in-\n",
      "formation from multiple people. For example,\n",
      "preparing a list of interns across teams in an or-\n",
      "ganization by reaching out to the leader of each\n",
      "team; preparing a newsletter for project updates\n",
      "might necessitate coordinating with multiple con-\n",
      "tributors; identifying a suitable time to meet might\n",
      "require several rounds of negotiations (Lin et al.,\n",
      "2024). Identifying what information is available,\n",
      "1Code and data can be found at https://github.com/\n",
      "microsoft/peoplejoin/\n",
      "judiciously determining who to contact, asking pre-\n",
      "cise questions, and compiling research results can\n",
      "be a challenging and time-consuming process—\n",
      "especially when real-time interaction between team\n",
      "members is difficult to coordinate.\n",
      "At the same time, recent large language mod-\n",
      "els (LLMs), such as GPT-4 (OpenAI, 2023), Phi-3\n",
      "(Abdin et al., 2024), LLaMa (Touvron et al., 2023),\n",
      "and Gemini (Team et al., 2023), are becoming a cru-\n",
      "cial building block in developing automated agents\n",
      "that can assist human users with complex tasks\n",
      "(Xi et al., 2023; Wang et al., 2024; Butler et al.,\n",
      "2023). These tasks include chat applications for\n",
      "assisting individual users with searching and sum-\n",
      "marizing information (such as in Microsoft Copilot\n",
      "Chat2), and even supporting these users in work-\n",
      "place decision-making (Butler et al., 2023; Kim\n",
      "and Hsu, 2024). Could these agents be extended to\n",
      "improve collaboration among multiple users?\n",
      "In this paper, we introduce PEOPLE JOIN , an\n",
      "evaluation framework for studying effectiveness\n",
      "of LLM-powered agents to assist with multi-user\n",
      "collaboration tasks. Each PEOPLE JOIN task takes\n",
      "place within a fictitious organization with 2–20\n",
      "employees, some of whom possess a collection of\n",
      "documents necessary to solve some task. One of\n",
      "the users (the initiating user) communicates the\n",
      "task to an agent (Fig. 1). Agents have direct ac-\n",
      "cess to the initiating user’s documents, and can\n",
      "engage in conversations with other users to gather\n",
      "relevant information. They must rely on limited\n",
      "descriptions of other users, and potentially previ-\n",
      "ous interactions, to determine who to contact for a\n",
      "given task. PEOPLE JOIN comprises two families\n",
      "of tasks: PEOPLE JOIN -QA and PEOPLE JOIN -\n",
      "DOCCREATION , derived from the SPIDER (Yu\n",
      "et al., 2018) and MULTINEWS (Fabbri et al., 2019)\n",
      "datasets respectively. It evaluates agents’ ability\n",
      "to answer questions involving complex relational\n",
      "2https://copilot.microsoft.com/\n",
      "arXiv:2502.12328v1  [cs.CL]  17 Feb 2025' metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2025-02-19T01:08:14+00:00', 'author': '', 'keywords': '', 'moddate': '2025-02-19T01:08:14+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'subject': '', 'title': '', 'trapped': '/False', 'source': 'uploads/5abea51a-c849-49ef-b206-ebd17f831a3b.pdf', 'total_pages': 26, 'page': 0, 'page_label': '1'}\n",
      "Loaded 25 pages from e8f3a248-4894-4c63-8d68-f3c706daa977.pdf\n",
      "\n",
      "\n",
      "page_content='Urban Planning\n",
      "2025 • Volume 10• Article 9165\n",
      "https://doi.org/10.17645/up.9165\n",
      "A R T I C L E Open Access Journal\n",
      "AI‐Supported Participatory Workshops: Middle‐Out Engagement\n",
      "for Crisis Events\n",
      "Martin Tomitsch1\n",
      " , Joel Fredericks2\n",
      " , Marius Hoggenmüller2\n",
      " , Alexandra Crosby3\n",
      " ,\n",
      "Adrian Wong2\n",
      " , Xinyan Yu2\n",
      " , and Weidong Huang1\n",
      "1 TransdisciplinarySchool,UniversityofTechnologySydney,Australia\n",
      "2 SchoolofArchitecture,DesignandPlanning,TheUniversityofSydney,Australia\n",
      "3 FacultyofDesign,ArchitectureandBuilding,UniversityofTechnologySydney,Australia\n",
      "Correspondence: MartinTomitsch(martin.tomitsch@uts.edu.au)\n",
      "Submitted: 9August2024 Accepted: 5November2024 Published: 27January2025\n",
      "Issue: This article is part of the issue “The Role of Participatory Planning and Design in Addressing the\n",
      "UN Sustainable Development Goals” edited by Hilary Davis (Swinburne University of Technology), Joel\n",
      "Fredericks(TheUniversityofSydney),MarcusFoth(QueenslandUniversityofTechnology),GlendaCaldwell\n",
      "(QueenslandUniversityofTechnology),andCallumParker(TheUniversityofSydney),fullyopenaccessat\n",
      "https://doi.org/10.17645/up.i394\n",
      "Abstract\n",
      "Consideringthelivedexperienceofcommunitiesiskeywhenmakingdecisionsincomplexscenarios,suchas\n",
      "preparingforandrespondingtocrisisevents.Thearticlereportsonthreeparticipatoryworkshops,which\n",
      "assigned community representative roles to workshop participants. Using role‐playing as a method,\n",
      "participantsweregiventhetaskofcollaboratingonmakingadecisionrelatingtoaspeculativecrisisscenario.\n",
      "Acrosstheworkshops,wecollecteddataaboutsimulatingamiddle‐outengagementapproachandtherole\n",
      "of artificial intelligence (AI) in enhancing collaboration, supporting decision‐making, and representing\n",
      "non‐humanactors.Thearticlemakesthreecontributionstoparticipatoryplanninganddesigninthecontext\n",
      "of the UN Sustainable Development Goals. First, it presents insights about the use of AI in enhancing\n",
      "collaboration and decision‐making in crisis event situations. Second, it discusses approaches for bringing\n",
      "more‐than‐human considerations into participatory planning and design. Third, it reflects on the value of\n",
      "role‐playingasawaytosimulateamiddle‐outengagementprocess,wherebyactorsfromthetopandthe\n",
      "bottomcollaboratetowardsmakinginformeddecisionsincomplexscenarios.Drawingonthefindingsfrom\n",
      "theworkshops,thearticlecriticallyreflectsonchallengesandrisksassociatedwithusingAIinparticipatory\n",
      "workshopsandcollaborativedecision‐making.\n",
      "Keywords\n",
      "artificialintelligence;communityengagement;conversationalagents;middle‐outengagement;non‐human\n",
      "personas;participatorydesign;participatoryplanning\n",
      "©2025bytheauthor(s),licensedunderaCreativeCommonsAttribution4.0InternationalLicense(CCBY). 1' metadata={'producer': 'xdvipdfmx (20240407)', 'creator': 'LaTeX with hyperref', 'creationdate': '2025-01-20T14:46:41+00:00', 'moddate': '2025-01-20T15:21:30+00:00', 'title': 'AI-Supported Participatory Workshops: Middle-Out Engagement for Crisis Events', 'keywords': 'artificial intelligence; community engagement; conversational agents; middle-out engagement; non-human personas; participatory design; participatory planning', 'author': 'Martin Tomitsch, Joel Fredericks, Marius Hoggenmüller, Alexandra Crosby, Adrian Wong, Xinyan Yu, and Weidong Huang', 'source': 'uploads/e8f3a248-4894-4c63-8d68-f3c706daa977.pdf', 'total_pages': 25, 'page': 0, 'page_label': '1'}\n",
      "Loaded 5 pages from 03594917-2c03-4036-9239-105e24b7402c.pdf\n",
      "\n",
      "\n",
      "page_content='Amplifying Minority Voices: AI-Mediated Devil’s Advocate\n",
      "System for Inclusive Group Decision-Making\n",
      "Soohwan Lee∗\n",
      "Department of Design, UNIST\n",
      "Ulsan, Republic of Korea\n",
      "soohwanlee@unist.ac.kr\n",
      "Mingyu Kim∗\n",
      "Department of Design, UNIST\n",
      "Ulsan, Republic of Korea\n",
      "gyu7991@unist.ac.kr\n",
      "Seoyeong Hwang\n",
      "Department of Design, UNIST\n",
      "Ulsan, Republic of Korea\n",
      "hseoyeong@unist.ac.kr\n",
      "Dajung Kim\n",
      "Department of Design, UNIST\n",
      "Ulsan, Republic of Korea\n",
      "dajungkim@unist.ac.kr\n",
      "Kyungho Lee\n",
      "Department of Design, UNIST\n",
      "Ulsan, Republic of Korea\n",
      "kyungho@unist.ac.kr\n",
      "T h e  M a j o r i t y  ( ≥ 3 )\n",
      "w i t h  H i g h  P o w e r\n",
      "T h e  M i n o r i t y\n",
      "w i t h  L o w  P o w e r\n",
      "C o m p l i a n c e\n",
      "L L M - p o w e r e d\n",
      "D e v i l ’ s  A d v o c a t e\n",
      "S o c i a l\n",
      "I n f l u e n c e\n",
      "Figure 1: Mitigating Social Influence with an LLM-powered Devil’s Advocate. Minority members often conform to majority\n",
      "opinions due to social pressure. Our system allows minorities to share different opinions with an LLM-powered Devil’s Advocate,\n",
      "which reframes and presents them as its own. This increases psychological safety, mitigates bias, and fosters critical discussion.\n",
      "Abstract\n",
      "Group decision-making often benefits from diverse perspectives, yet\n",
      "power imbalances and social influence can stifle minority opinions\n",
      "and compromise outcomes. This prequel introduces an AI-mediated\n",
      "communication system that leverages the Large Language Model\n",
      "to serve as a devil’s advocate, representing underrepresented view-\n",
      "points without exposing minority members’ identities. Rooted in\n",
      "persuasive communication strategies and anonymity, the system\n",
      "aims to improve psychological safety and foster more inclusive\n",
      "decision-making. Our multi-agent architecture, which consists of\n",
      "∗Equally contributed to this work.\n",
      "Permission to make digital or hard copies of all or part of this work for personal or\n",
      "classroom use is granted without fee provided that copies are not made or distributed\n",
      "for profit or commercial advantage and that copies bear this notice and the full citation\n",
      "on the first page. Copyrights for third-party components of this work must be honored.\n",
      "For all other uses, contact the owner/author(s).\n",
      "IUI Companion ’25, March 24–27, 2025, Cagliari, Italy\n",
      "© 2025 Copyright held by the owner/author(s).\n",
      "ACM ISBN 979-8-4007-1409-2/25/03\n",
      "https://doi.org/10.1145/3708557.3716334\n",
      "a summary agent, conversation agent, AI duplicate checker, and\n",
      "paraphrase agent, encourages the group’s critical thinking while\n",
      "reducing repetitive outputs. We acknowledge that reliance on text-\n",
      "based communication and fixed intervention timings may limit\n",
      "adaptability, indicating pathways for refinement. By focusing on\n",
      "the representation of minority viewpoints anonymously in power-\n",
      "imbalanced settings, this approach highlights how AI-driven meth-\n",
      "ods can evolve to support more divergent and inclusive group\n",
      "decision-making.\n",
      "CCS Concepts\n",
      "• Human-centered computing → Collaborative interaction;\n",
      "Collaborative and social computing systems and tools .\n",
      "Keywords\n",
      "AI-mediated Communication; AI-assisted Decision-making, Group\n",
      "Dynamics, Social Influence, Compliance, LLM\n",
      "arXiv:2502.06251v1  [cs.HC]  10 Feb 2025' metadata={'producer': 'pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'creator': 'LaTeX with acmart 2024/05/27 v2.08 Typesetting articles for the Association for Computing Machinery and hyperref 2023-04-22 v7.00x Hypertext links for LaTeX', 'creationdate': '2025-02-11T02:22:50+00:00', 'moddate': '2025-02-11T02:22:50+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'subject': '-  Human-centered computing  ->  Collaborative interaction.Collaborative and social computing systems and tools.', 'title': \"Amplifying Minority Voices: AI-Mediated Devil's Advocate System for Inclusive Group Decision-Making\", 'trapped': '/False', 'source': 'uploads/03594917-2c03-4036-9239-105e24b7402c.pdf', 'total_pages': 5, 'page': 0, 'page_label': '1'}\n",
      "Loaded 22 pages from 27cd7ac1-94d4-4412-b535-27e696b84e33.pdf\n",
      "\n",
      "\n",
      "page_content='Technology in Society 78 (2024) 102662\n",
      "Available online 17 July 2024\n",
      "0160-791X/© 2024 The Authors. Published by Elsevier Ltd. This is an open access article under the CC BY-NC-ND license (http://creativecommons.org/licenses/by-\n",
      "nc-nd/4.0/).\n",
      "Exploring collaborative decision-making: A quasi-experimental study of\n",
      "human and Generative AI interaction\n",
      "Xinyue Hao\n",
      "*\n",
      ", Emrah Demir , Daniel Eyers\n",
      "Logistics & Operations Management Section, Cardiff Business School, Cardiff University, Cardiff CF10 3EU, United Kingdom\n",
      "ARTICLE INFO\n",
      "Keywords:\n",
      "ChatGPT\n",
      "Artificial intelligence\n",
      "Human intuition\n",
      "Decision-making\n",
      "Cognitive biases\n",
      "ABSTRACT\n",
      "This paper explores the effects of integrating Generative Artificial Intelligence (GAI) into decision-making pro-\n",
      "cesses within organizations, employing a quasi-experimental pretest-posttest design. The study examines the\n",
      "synergistic interaction between Human Intelligence (HI) and GAI across four group decision-making scenarios\n",
      "within three global organizations renowned for their cutting-edge operational techniques. The research pro-\n",
      "gresses through several phases: identifying research problems, collecting baseline data on decision-making,\n",
      "implementing AI interventions, and evaluating the outcomes post-intervention to identify shifts in perfor-\n",
      "mance. The results demonstrate that GAI effectively reduces human cognitive burdens and mitigates heuristic\n",
      "biases by offering data-driven support and predictive analytics, grounded in System 2 reasoning. This is\n",
      "particularly valuable in complex situations characterized by unfamiliarity and information overload, where\n",
      "intuitive, System 1 thinking is less effective. However, the study also uncovers challenges related to GAI inte-\n",
      "gration, such as potential over-reliance on technology, intrinsic biases particularly ‘out-of-the-box ’ thinking\n",
      "without contextual creativity. To address these issues, this paper proposes an innovative strategic framework for\n",
      "HI-GAI collaboration that emphasizes transparency, accountability, and inclusiveness.\n",
      "1. Introduction\n",
      "The release of ChatGPT on November 30, 2022 [ 1 ], coincided with\n",
      "the aftermath of a global pandemic, was within a period characterized\n",
      "by significant societal and technological transformations. Before the\n",
      "introduction of Generative AI (GAI), ‘traditional AI ’ , which requires\n",
      "structured data for model construction and information processing,\n",
      "including neural networks, evolutionary algorithms, decision trees,\n",
      "random forests, support vector machines, and k-means clustering were\n",
      "already widespread [ 2 ]. Traditional AI was integrated into applications\n",
      "that influenced pricing, inventory management, logistic optimization,\n",
      "content recommendation etc., but were somewhat restricted in their\n",
      "functionality and had difficulties in directly interacting with users [ 3 ].\n",
      "In contrast, GAI technologies such as ChatGPT introduced a user inter-\n",
      "face that made AI both accessible and a regular part of daily technology\n",
      "use [ 4 ]. This made a significant shift towards direct human-AI collabo-\n",
      "ration [ 5 ]. This ease of use and direct interaction has ushered in a new\n",
      "era of machine-driven intelligence, where technological advances have\n",
      "outpaced organizational understanding of their effective management\n",
      "and exploitation.\n",
      "In the traditional paradigms of organizational decision-making,\n",
      "human intelligence (HI) whether individual or collective, is distin-\n",
      "guished by a blend of intuitive perception, emotional sensitivity, and\n",
      "cultural cognizance, that resonates across scenarios, from executing\n",
      "immediate, task-specific objectives [ 6 ] to strategizing for comprehen-\n",
      "sive, long-term aspirations [ 7 ]. These intrinsic human cognitive abilities\n",
      "inject creative and deep-seated insights into the strategic framework,\n",
      "thus equipping the organization with the fitness to adeptly steer through\n",
      "market fluctuations, competitive pressures, and technological ad-\n",
      "vancements [ 8 ]. Where teams must interact dynamically with constantly\n",
      "changing external variables, the comprehensive range of human cogni-\n",
      "tive skills is essential for plotting pathways through ambiguous situa-\n",
      "tions and capitalizing on the opportunities that such adaptability affords\n",
      "[ 9 ]. However, cognitive, and heuristic biases, essentially ‘rule of thumb ’\n",
      "or ‘mental shortcuts ’ evolved for information-processing efficiency [ 10 ],\n",
      "can sometimes be advantageous but often constrict perception and\n",
      "engender systematic errors in judgment, frequently leading to distorted\n",
      "reasoning and suboptimal decision-making outcomes [ 11 ]. High reli-\n",
      "ance on familiar biases can overshadow data-driven analysis. The latest\n",
      "iteration, GPT-4o ( “ o ” for “ omni ” ), expands on GPT-4 with 1.76 trillion\n",
      "* Corresponding author.\n",
      "E-mail address: haox2@cardiff.ac.uk (X. Hao).\n",
      "Contents lists available at ScienceDirect\n",
      "Technology in Society\n",
      "journal homep age: www.el sevier.com/l ocate/techso c\n",
      "https://doi.org/10.1016/j.techsoc.2024.102662\n",
      "Received 22 January 2024; Received in revised form 3 June 2024; Accepted 14 July 2024' metadata={'producer': 'Acrobat Distiller 8.1.0 (Windows)', 'creator': 'Elsevier', 'creationdate': '2024-07-19T14:48:15+00:00', 'crossmarkdomains[1]': 'elsevier.com', 'creationdate--text': '20th July 2024', 'robots': 'noindex', 'elsevierwebpdfspecifications': '7.0', 'moddate': '2024-07-20T09:27:48+00:00', 'doi': '10.1016/j.techsoc.2024.102662', 'keywords': 'ChatGPT,Artificial intelligence,Human intuition,Decision-making,Cognitive biases', 'title': 'Exploring collaborative decision-making: A quasi-experimental study of human and Generative AI interaction', 'subject': 'Technology in Society, 78 (2024) 102662. doi:10.1016/j.techsoc.2024.102662', 'crossmarkdomains[2]': 'sciencedirect.com', 'author': 'Xinyue Hao', 'source': 'uploads/27cd7ac1-94d4-4412-b535-27e696b84e33.pdf', 'total_pages': 22, 'page': 0, 'page_label': '1'}\n",
      "Loaded 22 pages from b44314ac-9c4f-4a4a-b51c-10c760ae6905.pdf\n",
      "\n",
      "\n",
      "page_content='Technology in Society 78 (2024) 102662\n",
      "Available online 17 July 2024\n",
      "0160-791X/© 2024 The Authors. Published by Elsevier Ltd. This is an open access article under the CC BY-NC-ND license (http://creativecommons.org/licenses/by-\n",
      "nc-nd/4.0/).\n",
      "Exploring collaborative decision-making: A quasi-experimental study of\n",
      "human and Generative AI interaction\n",
      "Xinyue Hao\n",
      "*\n",
      ", Emrah Demir , Daniel Eyers\n",
      "Logistics & Operations Management Section, Cardiff Business School, Cardiff University, Cardiff CF10 3EU, United Kingdom\n",
      "ARTICLE INFO\n",
      "Keywords:\n",
      "ChatGPT\n",
      "Artificial intelligence\n",
      "Human intuition\n",
      "Decision-making\n",
      "Cognitive biases\n",
      "ABSTRACT\n",
      "This paper explores the effects of integrating Generative Artificial Intelligence (GAI) into decision-making pro-\n",
      "cesses within organizations, employing a quasi-experimental pretest-posttest design. The study examines the\n",
      "synergistic interaction between Human Intelligence (HI) and GAI across four group decision-making scenarios\n",
      "within three global organizations renowned for their cutting-edge operational techniques. The research pro-\n",
      "gresses through several phases: identifying research problems, collecting baseline data on decision-making,\n",
      "implementing AI interventions, and evaluating the outcomes post-intervention to identify shifts in perfor-\n",
      "mance. The results demonstrate that GAI effectively reduces human cognitive burdens and mitigates heuristic\n",
      "biases by offering data-driven support and predictive analytics, grounded in System 2 reasoning. This is\n",
      "particularly valuable in complex situations characterized by unfamiliarity and information overload, where\n",
      "intuitive, System 1 thinking is less effective. However, the study also uncovers challenges related to GAI inte-\n",
      "gration, such as potential over-reliance on technology, intrinsic biases particularly ‘out-of-the-box ’ thinking\n",
      "without contextual creativity. To address these issues, this paper proposes an innovative strategic framework for\n",
      "HI-GAI collaboration that emphasizes transparency, accountability, and inclusiveness.\n",
      "1. Introduction\n",
      "The release of ChatGPT on November 30, 2022 [ 1 ], coincided with\n",
      "the aftermath of a global pandemic, was within a period characterized\n",
      "by significant societal and technological transformations. Before the\n",
      "introduction of Generative AI (GAI), ‘traditional AI ’ , which requires\n",
      "structured data for model construction and information processing,\n",
      "including neural networks, evolutionary algorithms, decision trees,\n",
      "random forests, support vector machines, and k-means clustering were\n",
      "already widespread [ 2 ]. Traditional AI was integrated into applications\n",
      "that influenced pricing, inventory management, logistic optimization,\n",
      "content recommendation etc., but were somewhat restricted in their\n",
      "functionality and had difficulties in directly interacting with users [ 3 ].\n",
      "In contrast, GAI technologies such as ChatGPT introduced a user inter-\n",
      "face that made AI both accessible and a regular part of daily technology\n",
      "use [ 4 ]. This made a significant shift towards direct human-AI collabo-\n",
      "ration [ 5 ]. This ease of use and direct interaction has ushered in a new\n",
      "era of machine-driven intelligence, where technological advances have\n",
      "outpaced organizational understanding of their effective management\n",
      "and exploitation.\n",
      "In the traditional paradigms of organizational decision-making,\n",
      "human intelligence (HI) whether individual or collective, is distin-\n",
      "guished by a blend of intuitive perception, emotional sensitivity, and\n",
      "cultural cognizance, that resonates across scenarios, from executing\n",
      "immediate, task-specific objectives [ 6 ] to strategizing for comprehen-\n",
      "sive, long-term aspirations [ 7 ]. These intrinsic human cognitive abilities\n",
      "inject creative and deep-seated insights into the strategic framework,\n",
      "thus equipping the organization with the fitness to adeptly steer through\n",
      "market fluctuations, competitive pressures, and technological ad-\n",
      "vancements [ 8 ]. Where teams must interact dynamically with constantly\n",
      "changing external variables, the comprehensive range of human cogni-\n",
      "tive skills is essential for plotting pathways through ambiguous situa-\n",
      "tions and capitalizing on the opportunities that such adaptability affords\n",
      "[ 9 ]. However, cognitive, and heuristic biases, essentially ‘rule of thumb ’\n",
      "or ‘mental shortcuts ’ evolved for information-processing efficiency [ 10 ],\n",
      "can sometimes be advantageous but often constrict perception and\n",
      "engender systematic errors in judgment, frequently leading to distorted\n",
      "reasoning and suboptimal decision-making outcomes [ 11 ]. High reli-\n",
      "ance on familiar biases can overshadow data-driven analysis. The latest\n",
      "iteration, GPT-4o ( “ o ” for “ omni ” ), expands on GPT-4 with 1.76 trillion\n",
      "* Corresponding author.\n",
      "E-mail address: haox2@cardiff.ac.uk (X. Hao).\n",
      "Contents lists available at ScienceDirect\n",
      "Technology in Society\n",
      "journal homep age: www.el sevier.com/l ocate/techso c\n",
      "https://doi.org/10.1016/j.techsoc.2024.102662\n",
      "Received 22 January 2024; Received in revised form 3 June 2024; Accepted 14 July 2024' metadata={'producer': 'Acrobat Distiller 8.1.0 (Windows)', 'creator': 'Elsevier', 'creationdate': '2024-07-19T14:48:15+00:00', 'crossmarkdomains[1]': 'elsevier.com', 'creationdate--text': '20th July 2024', 'robots': 'noindex', 'elsevierwebpdfspecifications': '7.0', 'moddate': '2024-07-20T09:27:48+00:00', 'doi': '10.1016/j.techsoc.2024.102662', 'keywords': 'ChatGPT,Artificial intelligence,Human intuition,Decision-making,Cognitive biases', 'title': 'Exploring collaborative decision-making: A quasi-experimental study of human and Generative AI interaction', 'subject': 'Technology in Society, 78 (2024) 102662. doi:10.1016/j.techsoc.2024.102662', 'crossmarkdomains[2]': 'sciencedirect.com', 'author': 'Xinyue Hao', 'source': 'uploads/b44314ac-9c4f-4a4a-b51c-10c760ae6905.pdf', 'total_pages': 22, 'page': 0, 'page_label': '1'}\n",
      "Loaded 25 pages from 128296f0-c0e9-4f7c-87a7-39899959c09f.pdf\n",
      "\n",
      "\n",
      "page_content='Urban Planning\n",
      "2025 • Volume 10• Article 9165\n",
      "https://doi.org/10.17645/up.9165\n",
      "A R T I C L E Open Access Journal\n",
      "AI‐Supported Participatory Workshops: Middle‐Out Engagement\n",
      "for Crisis Events\n",
      "Martin Tomitsch1\n",
      " , Joel Fredericks2\n",
      " , Marius Hoggenmüller2\n",
      " , Alexandra Crosby3\n",
      " ,\n",
      "Adrian Wong2\n",
      " , Xinyan Yu2\n",
      " , and Weidong Huang1\n",
      "1 TransdisciplinarySchool,UniversityofTechnologySydney,Australia\n",
      "2 SchoolofArchitecture,DesignandPlanning,TheUniversityofSydney,Australia\n",
      "3 FacultyofDesign,ArchitectureandBuilding,UniversityofTechnologySydney,Australia\n",
      "Correspondence: MartinTomitsch(martin.tomitsch@uts.edu.au)\n",
      "Submitted: 9August2024 Accepted: 5November2024 Published: 27January2025\n",
      "Issue: This article is part of the issue “The Role of Participatory Planning and Design in Addressing the\n",
      "UN Sustainable Development Goals” edited by Hilary Davis (Swinburne University of Technology), Joel\n",
      "Fredericks(TheUniversityofSydney),MarcusFoth(QueenslandUniversityofTechnology),GlendaCaldwell\n",
      "(QueenslandUniversityofTechnology),andCallumParker(TheUniversityofSydney),fullyopenaccessat\n",
      "https://doi.org/10.17645/up.i394\n",
      "Abstract\n",
      "Consideringthelivedexperienceofcommunitiesiskeywhenmakingdecisionsincomplexscenarios,suchas\n",
      "preparingforandrespondingtocrisisevents.Thearticlereportsonthreeparticipatoryworkshops,which\n",
      "assigned community representative roles to workshop participants. Using role‐playing as a method,\n",
      "participantsweregiventhetaskofcollaboratingonmakingadecisionrelatingtoaspeculativecrisisscenario.\n",
      "Acrosstheworkshops,wecollecteddataaboutsimulatingamiddle‐outengagementapproachandtherole\n",
      "of artificial intelligence (AI) in enhancing collaboration, supporting decision‐making, and representing\n",
      "non‐humanactors.Thearticlemakesthreecontributionstoparticipatoryplanninganddesigninthecontext\n",
      "of the UN Sustainable Development Goals. First, it presents insights about the use of AI in enhancing\n",
      "collaboration and decision‐making in crisis event situations. Second, it discusses approaches for bringing\n",
      "more‐than‐human considerations into participatory planning and design. Third, it reflects on the value of\n",
      "role‐playingasawaytosimulateamiddle‐outengagementprocess,wherebyactorsfromthetopandthe\n",
      "bottomcollaboratetowardsmakinginformeddecisionsincomplexscenarios.Drawingonthefindingsfrom\n",
      "theworkshops,thearticlecriticallyreflectsonchallengesandrisksassociatedwithusingAIinparticipatory\n",
      "workshopsandcollaborativedecision‐making.\n",
      "Keywords\n",
      "artificialintelligence;communityengagement;conversationalagents;middle‐outengagement;non‐human\n",
      "personas;participatorydesign;participatoryplanning\n",
      "©2025bytheauthor(s),licensedunderaCreativeCommonsAttribution4.0InternationalLicense(CCBY). 1' metadata={'producer': 'xdvipdfmx (20240407)', 'creator': 'LaTeX with hyperref', 'creationdate': '2025-01-20T14:46:41+00:00', 'moddate': '2025-01-20T15:21:30+00:00', 'title': 'AI-Supported Participatory Workshops: Middle-Out Engagement for Crisis Events', 'keywords': 'artificial intelligence; community engagement; conversational agents; middle-out engagement; non-human personas; participatory design; participatory planning', 'author': 'Martin Tomitsch, Joel Fredericks, Marius Hoggenmüller, Alexandra Crosby, Adrian Wong, Xinyan Yu, and Weidong Huang', 'source': 'uploads/128296f0-c0e9-4f7c-87a7-39899959c09f.pdf', 'total_pages': 25, 'page': 0, 'page_label': '1'}\n",
      "Loaded 17 pages from e7775e6f-b4f6-4b1d-9d45-d40c25f43e08.pdf\n",
      "\n",
      "\n",
      "page_content='Evaluation and Facilitation of Online Discussions in the LLM Era:\n",
      "A Survey\n",
      "Katerina Korre†⋆ , Dimitris Tsirmpas†‡ , Nikos Gkoumas† , Emma Cabalé♢\n",
      "Dionysios Kontarinis†, Danai Myrtzani‡ , Theodoros Evgeniou♠\n",
      "Ion Androutsopoulos‡†, John Pavlopoulos‡†\n",
      "†Archimedes/Athena RC, Greece (n.goumas@athenarc.gr, denniskont@gmail.com)\n",
      "‡Athens University of Economics and Business, Greece ({dim.tsirmpas,dan.myrtzani,ion,annis}@aueb.gr)\n",
      "♢École Normale Supérieure Paris-Saclay, France (emma.cabale@ens-paris-saclay.fr)\n",
      "♠INSEAD, Technology and Business, France (theodoros.evgeniou@insead.edu)\n",
      "⋆Università di Bologna, Italy (aikaterini.korre2@unibo.it)\n",
      "Abstract\n",
      "We present a survey of methods for assessing\n",
      "and enhancing the quality of online discussions,\n",
      "focusing on the potential of Large Language\n",
      "Models (LLMs). While online discourses aim,\n",
      "at least in theory, to foster mutual understand-\n",
      "ing, they often devolve into harmful exchanges,\n",
      "such as hate speech, threatening social cohe-\n",
      "sion and democratic values. Recent advance-\n",
      "ments in LLMs enable facilitation agents that\n",
      "not only moderate content, but also actively\n",
      "improve the quality of interactions. Our sur-\n",
      "vey synthesizes ideas from Natural Language\n",
      "Processing (NLP) and Social Sciences to pro-\n",
      "vide (a) a new taxonomy on discussion quality\n",
      "evaluation, (b) an overview of intervention and\n",
      "facilitation strategies, along with a new taxon-\n",
      "omy on conversation facilitation datasets, (c) an\n",
      "LLM-oriented roadmap of good practices and\n",
      "future research directions, from technological\n",
      "and societal perspectives.\n",
      "1 Introduction\n",
      "Discussions, especially of complex or controver-\n",
      "sial topics, are a cornerstone of collective decision-\n",
      "making (Burton et al., 2024). In contrast to initial\n",
      "hopes of promoting mutual understanding (Rhein-\n",
      "gold, 2000), online discussions (especially in social\n",
      "media) often degenerate into hate speech, personal\n",
      "attacks, promoting conspiracy theories or propa-\n",
      "ganda – to the extent that they can even be con-\n",
      "sidered a threat to social cohesion and democracy\n",
      "(Tucker et al., 2018; Mathew et al., 2019).\n",
      "Natural Language Processing ( NLP) and\n",
      "Machine Learning (ML) can potentially help im-\n",
      "prove the quality of online discussions. For exam-\n",
      "ple, automatic classifiers (Bang et al., 2023; Molina\n",
      "and Sundar, 2022) are already being used to help or\n",
      "even replace human moderators, by flagging posts\n",
      "that violate the law or policies of online discussion\n",
      "fora (Saeidi et al., 2021).\n",
      "Social Science provides theories and applica-\n",
      "tions for the facilitation of a discussion, but in\n",
      "specific contexts, such as teaching/learning (Man-\n",
      "sour, 2024) or clinical discussions (Gelula, 1997),\n",
      "without much research conducted for thread-like\n",
      "discussions.\n",
      "Improving the quality of online discussions pre-\n",
      "supposes being able to define and measure discus-\n",
      "sion quality. Here, work from Social Science, but\n",
      "also Argument Mining (AM) (Lapesa et al., 2024),\n",
      "can again provide several ideas on dimensions (as-\n",
      "pects) of discussion quality, such as logical co-\n",
      "hesion and constructiveness, as well as ideas on\n",
      "methods to measure quality along each dimension.\n",
      "This paper surveys research from Social Sci-\n",
      "ence and relevant NLP areas (e.g., AM, Senti-\n",
      "ment Analysis, Toxicity Detection), focusing on\n",
      "how Large Language Models (LLMs) can facilitate\n",
      "human discussions—similar to human facilitators\n",
      "(Kahane, 2013). While prior studies have explored\n",
      "LLM-facilitated discussions (Burton et al., 2024;\n",
      "Aher et al., 2023; Beck et al., 2024; Schroeder\n",
      "et al., 2024; Small et al., 2023; Cho et al., 2024),\n",
      "their connection to Social Science remains underex-\n",
      "plored. In this survey, we include methods from So-\n",
      "cial Science (e.g., linguistics) when discussing ap-\n",
      "proaches for evaluating online discussions, as well\n",
      "as when exploring intervention strategies (e.g., fa-\n",
      "cilitative tactics). LLM-based facilitation again pre-\n",
      "supposes defining and evaluating discussion qual-\n",
      "ity. This is even more necessary in the case of\n",
      "LLMs, because of their rapid deployment, poten-\n",
      "tial biases, and long-term societal consequences.\n",
      "Without continuous and thorough assessment, we\n",
      "risk implementing LLM-based facilitation systems\n",
      "that may be ineffective, biased, or even harmful,\n",
      "before their full implications are understood.\n",
      "Therefore, we survey discussion evaluation as-\n",
      "pects and their feasibility with LLMs, introducing\n",
      "a new taxonomy inspired by deliberation studies.\n",
      "We map tasks suited for ML models, LLMs, and\n",
      "humans, aggregate multidimensional insights on\n",
      "facilitation strategies, and outline future capabil-\n",
      "1\n",
      "arXiv:2503.01513v1  [cs.CL]  3 Mar 2025' metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2025-03-04T03:13:50+00:00', 'author': '', 'keywords': '', 'moddate': '2025-03-04T03:13:50+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'subject': '', 'title': '', 'trapped': '/False', 'source': 'uploads/e7775e6f-b4f6-4b1d-9d45-d40c25f43e08.pdf', 'total_pages': 17, 'page': 0, 'page_label': '1'}\n",
      "Loaded 16 pages from 1780365f-e241-4675-9a7a-b5a577e3f293.pdf\n",
      "\n",
      "\n",
      "page_content='Vol.:(0123456789)\n",
      "Discover Artificial Intelligence             (2022) 2:7  | https://doi.org/10.1007/s44163-022-00023-7\n",
      "1 3\n",
      "Discover Artificial Intelligence\n",
      "Perspective\n",
      "AI‑powered narrative building for facilitating public participation \n",
      "and engagement\n",
      "Fernando Marmolejo‑Ramos1 · Thomas Workman2 · Clint Walker2 · Don Lenihan3 · Sarah Moulds4 · Juan C. Correa5 · \n",
      "Anca M. Hanea6 · Belona Sonna7\n",
      "Received: 22 January 2022 / Accepted: 17 March 2022\n",
      "© The Author(s) 2022   OPEN\n",
      "Abstract\n",
      "Algorithms, data, and AI (ADA) technologies permeate most societies worldwide because of their proven benefits in \n",
      "different areas of life. Governments are the entities in charge of harnessing the benefits of ADA technologies above and \n",
      "beyond providing government services digitally. ADA technologies have the potential to transform the way govern-\n",
      "ments develop and deliver services to citizens, and the way citizens engage with their governments. Conventional public \n",
      "engagement strategies employed by governments have limited both the quality and diversity of deliberation between \n",
      "the citizen and their governments, and the potential for ADA technologies to be employed to improve the experience \n",
      "for both governments and the citizens they serve. In this article we argue that ADA technologies can improve the qual-\n",
      "ity, scope, and reach of public engagement by governments, particularly when coupled with other strategies to ensure \n",
      "legitimacy and accessibility among a broad range of communities and other stakeholders. In particular, we explore the \n",
      "role “narrative building” (NB) can play in facilitating public engagement through the use of ADA technologies. We describe \n",
      "a theoretical implementation of NB enhanced by adding natural language processing, expert knowledge elicitation, \n",
      "and semantic differential rating scales capabilities to increase gains in scale and reach. The theoretical implementation \n",
      "focuses on the public’s opinion on ADA-related technologies, and it derives implications for ethical governance.\n",
      "Keywords Narrative building · Artificial intelligence · Governance · Public affairs · Natural language processing · Expert \n",
      "knowledge elicitation\n",
      " * Fernando Marmolejo-Ramos, fernando.marmolejo-ramos@unisa.edu.au | 1Centre for Change and Complexity in Learning, The \n",
      "University of South Australia, Adelaide, SA 5000, Australia. 2Converlens Pty Ltd AU, Melbourne, Australia. 3Middle Ground Policy Research \n",
      "CA, Ottawa, Canada. 4UniSA Justice & Society, The University of South Australia, Adelaide, Australia. 5CESA Business School, Bogotá, \n",
      "Colombia. 6Ecosystem and Forest Sciences, University of Melbourne, Melbourne, Australia. 7African Institute for Mathematical Sciences, \n",
      "Kigali, Rwanda.' metadata={'producer': 'Acrobat Distiller 10.1.8 (Windows); modified using iText® 5.3.5 ©2000-2012 1T3XT BVBA (SPRINGER SBM; licensed version)', 'creator': 'Springer', 'creationdate': '2022-03-30T21:11:42+05:30', 'keywords': 'Narrative building,Artificial intelligence,Governance,Public affairs,Natural language processing,Expert knowledge elicitation', 'crossmarkdomains[1]': 'springer.com', 'moddate': '2022-03-30T23:33:13+02:00', 'crossmarkmajorversiondate': '2010-04-23', 'subject': 'Discover Artificial Intelligence, https://doi.org/10.1007/s44163-022-00023-7', 'author': 'Fernando Marmolejo-Ramos', 'title': 'AI-powered narrative building for facilitating public participation and engagement', 'crossmarkdomainexclusive': 'true', 'robots': 'noindex', 'doi': '10.1007/s44163-022-00023-7', 'crossmarkdomains[2]': 'springerlink.com', 'source': 'uploads/1780365f-e241-4675-9a7a-b5a577e3f293.pdf', 'total_pages': 16, 'page': 0, 'page_label': '1'}\n",
      "Loaded 26 pages from 8cad0171-3df6-4b3e-b87b-b3ac22e5d94b.pdf\n",
      "\n",
      "\n",
      "page_content='LM Agents for Coordinating Multi-User Information Gathering\n",
      "Harsh Jhamtani, Jacob Andreas, Benjamin Van Durme\n",
      "Microsoft\n",
      "{hjhamtani,jaandrea,ben.vandurme}@microsoft.com\n",
      "Abstract\n",
      "This paper introduces PEOPLE JOIN , a bench-\n",
      "mark for evaluating LM-mediated collaborative\n",
      "problem solving. Given a user request, PEO-\n",
      "PLE JOIN agents must identify teammates who\n",
      "might be able to assist, converse with these\n",
      "teammates to gather information, and finally\n",
      "compile a useful answer or summary for the\n",
      "original user. PEOPLE JOIN comprises two eval-\n",
      "uation domains: PEOPLE JOIN -QA, focused on\n",
      "questions about tabular data, and PEOPLE JOIN -\n",
      "DOCCREATION , focused on document creation\n",
      "tasks. The two domains are adapted from ex-\n",
      "isting NLP benchmarks for database question\n",
      "answering and multi-document summarization;\n",
      "here, however, the information needed to com-\n",
      "plete these tasks is distributed across synthetic\n",
      "“organizations” of 2–20 users, simulating natu-\n",
      "ral multi-user collaboration scenarios. We im-\n",
      "plemented several popular LM agent architec-\n",
      "tures, evaluating their accuracy and efficiency\n",
      "at completing tasks, and highlight new research\n",
      "questions that can be studied using PEOPLE -\n",
      "JOIN .1\n",
      "1 Introduction\n",
      "In today’s fast-paced and interconnected world,\n",
      "effective collaboration is essential for achieving\n",
      "complex tasks and making informed decisions\n",
      "(Papachristou et al., 2023; Gemp et al., 2024).\n",
      "Many decision-making, content creation, and\n",
      "information-gathering tasks require collecting in-\n",
      "formation from multiple people. For example,\n",
      "preparing a list of interns across teams in an or-\n",
      "ganization by reaching out to the leader of each\n",
      "team; preparing a newsletter for project updates\n",
      "might necessitate coordinating with multiple con-\n",
      "tributors; identifying a suitable time to meet might\n",
      "require several rounds of negotiations (Lin et al.,\n",
      "2024). Identifying what information is available,\n",
      "1Code and data can be found at https://github.com/\n",
      "microsoft/peoplejoin/\n",
      "judiciously determining who to contact, asking pre-\n",
      "cise questions, and compiling research results can\n",
      "be a challenging and time-consuming process—\n",
      "especially when real-time interaction between team\n",
      "members is difficult to coordinate.\n",
      "At the same time, recent large language mod-\n",
      "els (LLMs), such as GPT-4 (OpenAI, 2023), Phi-3\n",
      "(Abdin et al., 2024), LLaMa (Touvron et al., 2023),\n",
      "and Gemini (Team et al., 2023), are becoming a cru-\n",
      "cial building block in developing automated agents\n",
      "that can assist human users with complex tasks\n",
      "(Xi et al., 2023; Wang et al., 2024; Butler et al.,\n",
      "2023). These tasks include chat applications for\n",
      "assisting individual users with searching and sum-\n",
      "marizing information (such as in Microsoft Copilot\n",
      "Chat2), and even supporting these users in work-\n",
      "place decision-making (Butler et al., 2023; Kim\n",
      "and Hsu, 2024). Could these agents be extended to\n",
      "improve collaboration among multiple users?\n",
      "In this paper, we introduce PEOPLE JOIN , an\n",
      "evaluation framework for studying effectiveness\n",
      "of LLM-powered agents to assist with multi-user\n",
      "collaboration tasks. Each PEOPLE JOIN task takes\n",
      "place within a fictitious organization with 2–20\n",
      "employees, some of whom possess a collection of\n",
      "documents necessary to solve some task. One of\n",
      "the users (the initiating user) communicates the\n",
      "task to an agent (Fig. 1). Agents have direct ac-\n",
      "cess to the initiating user’s documents, and can\n",
      "engage in conversations with other users to gather\n",
      "relevant information. They must rely on limited\n",
      "descriptions of other users, and potentially previ-\n",
      "ous interactions, to determine who to contact for a\n",
      "given task. PEOPLE JOIN comprises two families\n",
      "of tasks: PEOPLE JOIN -QA and PEOPLE JOIN -\n",
      "DOCCREATION , derived from the SPIDER (Yu\n",
      "et al., 2018) and MULTINEWS (Fabbri et al., 2019)\n",
      "datasets respectively. It evaluates agents’ ability\n",
      "to answer questions involving complex relational\n",
      "2https://copilot.microsoft.com/\n",
      "arXiv:2502.12328v1  [cs.CL]  17 Feb 2025' metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2025-02-19T01:08:14+00:00', 'author': '', 'keywords': '', 'moddate': '2025-02-19T01:08:14+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'subject': '', 'title': '', 'trapped': '/False', 'source': 'uploads/8cad0171-3df6-4b3e-b87b-b3ac22e5d94b.pdf', 'total_pages': 26, 'page': 0, 'page_label': '1'}\n",
      "Loaded 14 pages from 9316c73a-5ad0-4e85-bf04-c7bf9886c4bc.pdf\n",
      "\n",
      "\n",
      "page_content='AI and the Future of Collaborative Work: Group Ideation with an\n",
      "LLM in a Virtual Canvas\n",
      "Jessica He\n",
      "IBM Research AI\n",
      "Seattle, USA\n",
      "jessicahe@ibm.com\n",
      "Stephanie Houde\n",
      "IBM Research AI\n",
      "Cambridge, USA\n",
      "Stephanie.Houde@ibm.com\n",
      "Gabriel Enrique Gonzalez\n",
      "IBM Argentina\n",
      "Necochea, Argentina\n",
      "gabriel.gonzalez@ibm.com\n",
      "Dario Andres Silva Moran\n",
      "IBM Argentina\n",
      "La Plata, Argentina\n",
      "dario.silva@ibm.com\n",
      "Steven I. Ross\n",
      "IBM Research AI\n",
      "Cambridge, USA\n",
      "steven_ross@us.ibm.com\n",
      "Michael Muller\n",
      "IBM Research AI\n",
      "Cambridge, USA\n",
      "michael_muller@us.ibm.com\n",
      "Justin D. Weisz\n",
      "IBM Research AI\n",
      "Yorktown Heights, USA\n",
      "jweisz@us.ibm.com\n",
      "ABSTRACT\n",
      "The introduction of generative AI into multi-user applications raises\n",
      "novel considerations for the future of collaborative work. How\n",
      "might collaborative work practices change? How might we incor-\n",
      "porate generative AI into shared tools with users’ needs at the\n",
      "forefront? We examine these questions in the context of a remote\n",
      "team conducting ideation tasks – an example of collaborative work\n",
      "enabled by a shared digital workspace. We conducted a user study\n",
      "with 17 professionals experienced with virtual group ideation work-\n",
      "shops. Our study examined their use of the Collaborative Canvas , a\n",
      "virtual canvas tool with integrated generative AI capabilities that\n",
      "we created as a probe. Participants saw value in using generative\n",
      "AI to assist with group facilitation and to augment perspectives\n",
      "and ideas. However, they worried about losing human perspectives\n",
      "and critical thinking, as well as reputational harms resulting from\n",
      "harmful AI outputs. Participants shared suggestions for appropriate\n",
      "ways to incorporate generative AI capabilities within multi-user\n",
      "applications and identified needs for transparency of content own-\n",
      "ership, private digital spaces, and specialized AI capabilities. Based\n",
      "on participants’ insights, we share implications and opportunities\n",
      "for the incorporation of generative AI into collaborative work in\n",
      "ways that place user needs at the forefront.\n",
      "CCS CONCEPTS\n",
      "• Human-centered computing →Empirical studies in HCI ;\n",
      "Empirical studies in collaborative and social computing ; •\n",
      "Computing methodologies →Artificial intelligence.\n",
      "This work is licensed under a Creative Commons Attribution-NonCommercial\n",
      "International 4.0 License.\n",
      "CHIWORK ’24, June 25–27, 2024, Newcastle upon Tyne, United Kingdom\n",
      "© 2024 Copyright held by the owner/author(s).\n",
      "ACM ISBN 979-8-4007-1017-9/24/06\n",
      "https://doi.org/10.1145/3663384.3663398\n",
      "KEYWORDS\n",
      "Group ideation, Brainstorming, Shared virtual canvas, Mixed initia-\n",
      "tive, Generative AI, Future of work\n",
      "ACM Reference Format:\n",
      "Jessica He, Stephanie Houde, Gabriel Enrique Gonzalez, Dario Andres Silva\n",
      "Moran, Steven I. Ross, Michael Muller, and Justin D. Weisz. 2024. AI and\n",
      "the Future of Collaborative Work: Group Ideation with an LLM in a Virtual\n",
      "Canvas. In Proceedings of the 3rd Annual Meeting of the Symposium on\n",
      "Human-Computer Interaction for Work (CHIWORK ’24), June 25–27, 2024,\n",
      "Newcastle upon Tyne, United Kingdom. ACM, New York, NY, USA, 14 pages.\n",
      "https://doi.org/10.1145/3663384.3663398\n",
      "1 INTRODUCTION\n",
      "Generative AI has the potential to automate tasks that were pre-\n",
      "viously thought to be exclusive to humans, raising questions of\n",
      "its impact on the future of work. Rapid advancements in gener-\n",
      "ative AI have already enabled its incorporation into professional\n",
      "work domains such as programming [ 95], research [ 1, 60], and\n",
      "design [41, 57, 113]. In these domains, generative AI can produce\n",
      "ideas, summaries, and suggestions that rival those produced by\n",
      "humans.\n",
      "In the past, many research studies on AI-augmented work have\n",
      "been configured such that one human works with a single AI agent\n",
      "(e.g., [55, 94, 119, 122]). Work by Farrell et al. [26] took an expanded\n",
      "view in which a human works with a back-end collection of AI\n",
      "agents, through a single front-end interface [26]. However, this view\n",
      "does not reflect the reality that work is often performed by groups\n",
      "of colleagues working together [104, 116, 127]. As advancements in\n",
      "generative AI make their way into collaborative domains, there is a\n",
      "need to shift our view to realistic work contexts in which multiple\n",
      "humans interact with each other along with AI agents.\n",
      "One indication of the rise of AI-supported group work is in the\n",
      "introduction of generative AI features to digital canvas tools such as\n",
      "Mural1, Miro2, and Microsoft Whiteboard3. These features include\n",
      "1Mural. https://mural.co\n",
      "2Miro. https://miro.com\n",
      "3Microsoft Whiteboard. https://whiteboard.microsoft.com' metadata={'producer': 'pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5; modified using iText 4.2.0 by 1T3XT', 'creator': 'LaTeX with acmart 2024/04/17 v2.07 Typesetting articles for the Association for Computing Machinery and hyperref 2023-02-07 v7.00v Hypertext links for LaTeX', 'creationdate': '2024-05-06T19:54:44+00:00', 'moddate': '2025-03-20T06:29:09-07:00', 'trapped': '/False', 'subject': '-  Human-centered computing  ->  Empirical studies in HCI.Empirical studies in collaborative and social computing.-  Computing methodologies  ->  Artificial intelligence.', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'title': 'AI and the Future of Collaborative Work: Group Ideation with an LLM in a Virtual Canvas', 'source': 'uploads/9316c73a-5ad0-4e85-bf04-c7bf9886c4bc.pdf', 'total_pages': 14, 'page': 0, 'page_label': '1'}\n",
      "Loaded 17 pages from d4c11bfb-0cd0-4df6-8324-ef33ad36fad2.pdf\n",
      "\n",
      "\n",
      "page_content='Evaluation and Facilitation of Online Discussions in the LLM Era:\n",
      "A Survey\n",
      "Katerina Korre†⋆ , Dimitris Tsirmpas†‡ , Nikos Gkoumas† , Emma Cabalé♢\n",
      "Dionysios Kontarinis†, Danai Myrtzani‡ , Theodoros Evgeniou♠\n",
      "Ion Androutsopoulos‡†, John Pavlopoulos‡†\n",
      "†Archimedes/Athena RC, Greece (n.goumas@athenarc.gr, denniskont@gmail.com)\n",
      "‡Athens University of Economics and Business, Greece ({dim.tsirmpas,dan.myrtzani,ion,annis}@aueb.gr)\n",
      "♢École Normale Supérieure Paris-Saclay, France (emma.cabale@ens-paris-saclay.fr)\n",
      "♠INSEAD, Technology and Business, France (theodoros.evgeniou@insead.edu)\n",
      "⋆Università di Bologna, Italy (aikaterini.korre2@unibo.it)\n",
      "Abstract\n",
      "We present a survey of methods for assessing\n",
      "and enhancing the quality of online discussions,\n",
      "focusing on the potential of Large Language\n",
      "Models (LLMs). While online discourses aim,\n",
      "at least in theory, to foster mutual understand-\n",
      "ing, they often devolve into harmful exchanges,\n",
      "such as hate speech, threatening social cohe-\n",
      "sion and democratic values. Recent advance-\n",
      "ments in LLMs enable facilitation agents that\n",
      "not only moderate content, but also actively\n",
      "improve the quality of interactions. Our sur-\n",
      "vey synthesizes ideas from Natural Language\n",
      "Processing (NLP) and Social Sciences to pro-\n",
      "vide (a) a new taxonomy on discussion quality\n",
      "evaluation, (b) an overview of intervention and\n",
      "facilitation strategies, along with a new taxon-\n",
      "omy on conversation facilitation datasets, (c) an\n",
      "LLM-oriented roadmap of good practices and\n",
      "future research directions, from technological\n",
      "and societal perspectives.\n",
      "1 Introduction\n",
      "Discussions, especially of complex or controver-\n",
      "sial topics, are a cornerstone of collective decision-\n",
      "making (Burton et al., 2024). In contrast to initial\n",
      "hopes of promoting mutual understanding (Rhein-\n",
      "gold, 2000), online discussions (especially in social\n",
      "media) often degenerate into hate speech, personal\n",
      "attacks, promoting conspiracy theories or propa-\n",
      "ganda – to the extent that they can even be con-\n",
      "sidered a threat to social cohesion and democracy\n",
      "(Tucker et al., 2018; Mathew et al., 2019).\n",
      "Natural Language Processing ( NLP) and\n",
      "Machine Learning (ML) can potentially help im-\n",
      "prove the quality of online discussions. For exam-\n",
      "ple, automatic classifiers (Bang et al., 2023; Molina\n",
      "and Sundar, 2022) are already being used to help or\n",
      "even replace human moderators, by flagging posts\n",
      "that violate the law or policies of online discussion\n",
      "fora (Saeidi et al., 2021).\n",
      "Social Science provides theories and applica-\n",
      "tions for the facilitation of a discussion, but in\n",
      "specific contexts, such as teaching/learning (Man-\n",
      "sour, 2024) or clinical discussions (Gelula, 1997),\n",
      "without much research conducted for thread-like\n",
      "discussions.\n",
      "Improving the quality of online discussions pre-\n",
      "supposes being able to define and measure discus-\n",
      "sion quality. Here, work from Social Science, but\n",
      "also Argument Mining (AM) (Lapesa et al., 2024),\n",
      "can again provide several ideas on dimensions (as-\n",
      "pects) of discussion quality, such as logical co-\n",
      "hesion and constructiveness, as well as ideas on\n",
      "methods to measure quality along each dimension.\n",
      "This paper surveys research from Social Sci-\n",
      "ence and relevant NLP areas (e.g., AM, Senti-\n",
      "ment Analysis, Toxicity Detection), focusing on\n",
      "how Large Language Models (LLMs) can facilitate\n",
      "human discussions—similar to human facilitators\n",
      "(Kahane, 2013). While prior studies have explored\n",
      "LLM-facilitated discussions (Burton et al., 2024;\n",
      "Aher et al., 2023; Beck et al., 2024; Schroeder\n",
      "et al., 2024; Small et al., 2023; Cho et al., 2024),\n",
      "their connection to Social Science remains underex-\n",
      "plored. In this survey, we include methods from So-\n",
      "cial Science (e.g., linguistics) when discussing ap-\n",
      "proaches for evaluating online discussions, as well\n",
      "as when exploring intervention strategies (e.g., fa-\n",
      "cilitative tactics). LLM-based facilitation again pre-\n",
      "supposes defining and evaluating discussion qual-\n",
      "ity. This is even more necessary in the case of\n",
      "LLMs, because of their rapid deployment, poten-\n",
      "tial biases, and long-term societal consequences.\n",
      "Without continuous and thorough assessment, we\n",
      "risk implementing LLM-based facilitation systems\n",
      "that may be ineffective, biased, or even harmful,\n",
      "before their full implications are understood.\n",
      "Therefore, we survey discussion evaluation as-\n",
      "pects and their feasibility with LLMs, introducing\n",
      "a new taxonomy inspired by deliberation studies.\n",
      "We map tasks suited for ML models, LLMs, and\n",
      "humans, aggregate multidimensional insights on\n",
      "facilitation strategies, and outline future capabil-\n",
      "1\n",
      "arXiv:2503.01513v1  [cs.CL]  3 Mar 2025' metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2025-03-04T03:13:50+00:00', 'author': '', 'keywords': '', 'moddate': '2025-03-04T03:13:50+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'subject': '', 'title': '', 'trapped': '/False', 'source': 'uploads/d4c11bfb-0cd0-4df6-8324-ef33ad36fad2.pdf', 'total_pages': 17, 'page': 0, 'page_label': '1'}\n",
      "Loaded 15 pages from a7fa0b9a-9b3e-4dd1-91bb-b02ee5d95d8a.pdf\n",
      "\n",
      "\n",
      "page_content='TYPE Review\n",
      "PUBLISHED /zero.tnum/six.tnum January /two.tnum/zero.tnum/two.tnum/five.tnum\n",
      "DOI /one.tnum/zero.tnum./three.tnum/three.tnum/eight.tnum/nine.tnum/fcomp./two.tnum/zero.tnum/two.tnum/four.tnum./one.tnum/five.tnum/two.tnum/one.tnum/zero.tnum/six.tnum/six.tnum\n",
      "OPEN ACCESS\n",
      "EDITED BY\n",
      "Stefan Kopp,\n",
      "Bielefeld University, Germany\n",
      "REVIEWED BY\n",
      "Styliani Kleanthous,\n",
      "Open University of Cyprus, Cyprus\n",
      "Milus˘e Balková,\n",
      "Institute of Technology and Business, Czechia\n",
      "*CORRESPONDENCE\n",
      "Mathias Unberath\n",
      "unberath@jhu.edu\n",
      "RECEIVED /zero.tnum/one.tnum November /two.tnum/zero.tnum/two.tnum/four.tnum\n",
      "ACCEPTED /zero.tnum/six.tnum December /two.tnum/zero.tnum/two.tnum/four.tnum\n",
      "PUBLISHED /zero.tnum/six.tnum January /two.tnum/zero.tnum/two.tnum/five.tnum\n",
      "CITATION\n",
      "Gomez C, Cho SM, Ke S, Huang C-M and\n",
      "Unberath M (/two.tnum/zero.tnum/two.tnum/five.tnum) Human-AI collaboration is\n",
      "not very collaborative yet: a taxonomy of\n",
      "interaction patterns in AI-assisted decision\n",
      "making from a systematic review.\n",
      "Front. Comput. Sci./six.tnum:/one.tnum/five.tnum/two.tnum/one.tnum/zero.tnum/six.tnum/six.tnum.\n",
      "doi: /one.tnum/zero.tnum./three.tnum/three.tnum/eight.tnum/nine.tnum/fcomp./two.tnum/zero.tnum/two.tnum/four.tnum./one.tnum/five.tnum/two.tnum/one.tnum/zero.tnum/six.tnum/six.tnum\n",
      "COPYRIGHT\n",
      "© /two.tnum/zero.tnum/two.tnum/five.tnum Gomez, Cho, Ke, Huang and\n",
      "Unberath. This is an open-access article\n",
      "distributed under the terms of the\n",
      "Creative\n",
      "Commons Attribution License (CC BY) . The\n",
      "use, distribution or reproduction in other\n",
      "forums is permitted, provided the original\n",
      "author(s) and the copyright owner(s) are\n",
      "credited and that the original publication in\n",
      "this journal is cited, in accordance with\n",
      "accepted academic practice. No use,\n",
      "distribution or reproduction is permitted\n",
      "which does not comply with these terms.\n",
      "Human-AI collaboration is not\n",
      "very collaborative yet: a\n",
      "taxonomy of interaction patterns\n",
      "in AI-assisted decision making\n",
      "from a systematic review\n",
      "Catalina Gomez, Sue Min Cho, Shichang Ke, Chien-Ming Huang\n",
      "and Mathias Unberath*\n",
      "Department of Computer Science, Johns Hopkins University, Baltim ore, MD, United States\n",
      "Leveraging Artiﬁcial Intelligence (AI) in decision support syst ems has\n",
      "disproportionately focused on technological advancements, ofte n overlooking\n",
      "the alignment between algorithmic outputs and human expectatio ns. A\n",
      "human-centered perspective attempts to alleviate this concern by designing AI\n",
      "solutions for seamless integration with existing processes. Determining what\n",
      "information AI should provide to aid humans is vital, a concept u nderscored by\n",
      "explainable AI’s eﬀorts to justify AI predictions. However, h ow the information\n",
      "is presented, e.g., the sequence of recommendations and solicit ation of\n",
      "interpretations, is equally crucial as complex interactions may e merge between\n",
      "humans and AI. While empirical studies have evaluated human-AI dynamics\n",
      "across domains, a common vocabulary for human-AI interaction prot ocols is\n",
      "lacking. To promote more deliberate consideration of interacti on designs, we\n",
      "introduce a taxonomy of interaction patterns that delineate v arious modes of\n",
      "human-AI interactivity. We summarize the results of a system atic review of\n",
      "AI-assisted decision making literature and identify trends and opportunities\n",
      "in existing interactions across application domains from /one.tnum/zero.tnum/five.tnum articles. We ﬁnd\n",
      "that current interactions are dominated by simplistic collabor ation paradigms,\n",
      "leading to little support for truly interactive functionality . Our taxonomy oﬀers a\n",
      "tool to understand interactivity with AI in decision-making and foster interaction\n",
      "designs for achieving clear communication, trustworthiness, and collaboration.\n",
      "KEYWORDS\n",
      "artiﬁcial intelligence, human-AI interaction, decision-ma king, interaction patterns,\n",
      "interactivity\n",
      "/one.tnum Introduction\n",
      "Advances in Artiﬁcial Intelligence (AI) developments open new possibilities for\n",
      "supporting human decision making across a wide variety of applications. Decision making\n",
      "tasks in a broad range of applications share a process that starts when evidence is presented\n",
      "before making a decision within discrete choices, usually with follow-up eﬀects. Within this\n",
      "framework, the decision-making process emerges as a scenario for human-AI teamwork\n",
      "where at a minimum two parties, i.e., the human and the AI, factor into ﬁnding a solution to\n",
      "the decision problem. The exact dynamics of how this collaboration occurs can vary from\n",
      "one situation to another, leading to multiple interaction options that range from simple\n",
      "Frontiers in Computer Science /zero.tnum/one.tnum frontiersin.org' metadata={'producer': 'dvips + MiKTeX GPL Ghostscript  9.0', 'creator': 'LaTeX with hyperref package + hypdvips', 'creationdate': '2024-12-26T12:14:21+05:30', 'subject': 'Gomez C, Cho SM, Ke S, Huang C-M and Unberath M (2025) Human-AI collaboration is not very collaborative yet: a taxonomy of interaction patterns in AI-assisted decision making from a systematic review. Front. Comput. Sci. 6:1521066. doi: 10.3389/fcomp.2024.1521066', 'author': 'Catalina Gomez', 'keywords': 'artificial intelligence; human-AI interaction; decision-making; interaction patterns; interactivity', 'moddate': '2024-12-26T12:33:06+05:30', 'title': 'Human-AI collaboration is not very collaborative yet: a taxonomy of interaction patterns in AI-assisted decision making from a systematic review', 'source': 'uploads/a7fa0b9a-9b3e-4dd1-91bb-b02ee5d95d8a.pdf', 'total_pages': 15, 'page': 0, 'page_label': '1'}\n",
      "Loaded 15 pages from 27218388-957d-4c2b-8aa3-e5cc2355faa8.pdf\n",
      "\n",
      "\n",
      "page_content='TYPE Review\n",
      "PUBLISHED /zero.tnum/six.tnum January /two.tnum/zero.tnum/two.tnum/five.tnum\n",
      "DOI /one.tnum/zero.tnum./three.tnum/three.tnum/eight.tnum/nine.tnum/fcomp./two.tnum/zero.tnum/two.tnum/four.tnum./one.tnum/five.tnum/two.tnum/one.tnum/zero.tnum/six.tnum/six.tnum\n",
      "OPEN ACCESS\n",
      "EDITED BY\n",
      "Stefan Kopp,\n",
      "Bielefeld University, Germany\n",
      "REVIEWED BY\n",
      "Styliani Kleanthous,\n",
      "Open University of Cyprus, Cyprus\n",
      "Milus˘e Balková,\n",
      "Institute of Technology and Business, Czechia\n",
      "*CORRESPONDENCE\n",
      "Mathias Unberath\n",
      "unberath@jhu.edu\n",
      "RECEIVED /zero.tnum/one.tnum November /two.tnum/zero.tnum/two.tnum/four.tnum\n",
      "ACCEPTED /zero.tnum/six.tnum December /two.tnum/zero.tnum/two.tnum/four.tnum\n",
      "PUBLISHED /zero.tnum/six.tnum January /two.tnum/zero.tnum/two.tnum/five.tnum\n",
      "CITATION\n",
      "Gomez C, Cho SM, Ke S, Huang C-M and\n",
      "Unberath M (/two.tnum/zero.tnum/two.tnum/five.tnum) Human-AI collaboration is\n",
      "not very collaborative yet: a taxonomy of\n",
      "interaction patterns in AI-assisted decision\n",
      "making from a systematic review.\n",
      "Front. Comput. Sci./six.tnum:/one.tnum/five.tnum/two.tnum/one.tnum/zero.tnum/six.tnum/six.tnum.\n",
      "doi: /one.tnum/zero.tnum./three.tnum/three.tnum/eight.tnum/nine.tnum/fcomp./two.tnum/zero.tnum/two.tnum/four.tnum./one.tnum/five.tnum/two.tnum/one.tnum/zero.tnum/six.tnum/six.tnum\n",
      "COPYRIGHT\n",
      "© /two.tnum/zero.tnum/two.tnum/five.tnum Gomez, Cho, Ke, Huang and\n",
      "Unberath. This is an open-access article\n",
      "distributed under the terms of the\n",
      "Creative\n",
      "Commons Attribution License (CC BY) . The\n",
      "use, distribution or reproduction in other\n",
      "forums is permitted, provided the original\n",
      "author(s) and the copyright owner(s) are\n",
      "credited and that the original publication in\n",
      "this journal is cited, in accordance with\n",
      "accepted academic practice. No use,\n",
      "distribution or reproduction is permitted\n",
      "which does not comply with these terms.\n",
      "Human-AI collaboration is not\n",
      "very collaborative yet: a\n",
      "taxonomy of interaction patterns\n",
      "in AI-assisted decision making\n",
      "from a systematic review\n",
      "Catalina Gomez, Sue Min Cho, Shichang Ke, Chien-Ming Huang\n",
      "and Mathias Unberath*\n",
      "Department of Computer Science, Johns Hopkins University, Baltim ore, MD, United States\n",
      "Leveraging Artiﬁcial Intelligence (AI) in decision support syst ems has\n",
      "disproportionately focused on technological advancements, ofte n overlooking\n",
      "the alignment between algorithmic outputs and human expectatio ns. A\n",
      "human-centered perspective attempts to alleviate this concern by designing AI\n",
      "solutions for seamless integration with existing processes. Determining what\n",
      "information AI should provide to aid humans is vital, a concept u nderscored by\n",
      "explainable AI’s eﬀorts to justify AI predictions. However, h ow the information\n",
      "is presented, e.g., the sequence of recommendations and solicit ation of\n",
      "interpretations, is equally crucial as complex interactions may e merge between\n",
      "humans and AI. While empirical studies have evaluated human-AI dynamics\n",
      "across domains, a common vocabulary for human-AI interaction prot ocols is\n",
      "lacking. To promote more deliberate consideration of interacti on designs, we\n",
      "introduce a taxonomy of interaction patterns that delineate v arious modes of\n",
      "human-AI interactivity. We summarize the results of a system atic review of\n",
      "AI-assisted decision making literature and identify trends and opportunities\n",
      "in existing interactions across application domains from /one.tnum/zero.tnum/five.tnum articles. We ﬁnd\n",
      "that current interactions are dominated by simplistic collabor ation paradigms,\n",
      "leading to little support for truly interactive functionality . Our taxonomy oﬀers a\n",
      "tool to understand interactivity with AI in decision-making and foster interaction\n",
      "designs for achieving clear communication, trustworthiness, and collaboration.\n",
      "KEYWORDS\n",
      "artiﬁcial intelligence, human-AI interaction, decision-ma king, interaction patterns,\n",
      "interactivity\n",
      "/one.tnum Introduction\n",
      "Advances in Artiﬁcial Intelligence (AI) developments open new possibilities for\n",
      "supporting human decision making across a wide variety of applications. Decision making\n",
      "tasks in a broad range of applications share a process that starts when evidence is presented\n",
      "before making a decision within discrete choices, usually with follow-up eﬀects. Within this\n",
      "framework, the decision-making process emerges as a scenario for human-AI teamwork\n",
      "where at a minimum two parties, i.e., the human and the AI, factor into ﬁnding a solution to\n",
      "the decision problem. The exact dynamics of how this collaboration occurs can vary from\n",
      "one situation to another, leading to multiple interaction options that range from simple\n",
      "Frontiers in Computer Science /zero.tnum/one.tnum frontiersin.org' metadata={'producer': 'dvips + MiKTeX GPL Ghostscript  9.0', 'creator': 'LaTeX with hyperref package + hypdvips', 'creationdate': '2024-12-26T12:14:21+05:30', 'subject': 'Gomez C, Cho SM, Ke S, Huang C-M and Unberath M (2025) Human-AI collaboration is not very collaborative yet: a taxonomy of interaction patterns in AI-assisted decision making from a systematic review. Front. Comput. Sci. 6:1521066. doi: 10.3389/fcomp.2024.1521066', 'author': 'Catalina Gomez', 'keywords': 'artificial intelligence; human-AI interaction; decision-making; interaction patterns; interactivity', 'moddate': '2024-12-26T12:33:06+05:30', 'title': 'Human-AI collaboration is not very collaborative yet: a taxonomy of interaction patterns in AI-assisted decision making from a systematic review', 'source': 'uploads/27218388-957d-4c2b-8aa3-e5cc2355faa8.pdf', 'total_pages': 15, 'page': 0, 'page_label': '1'}\n",
      "Loaded 16 pages from 2cc3dfdf-0e7e-4985-bf22-3aa008c5859b.pdf\n",
      "\n",
      "\n",
      "page_content='Vol.:(0123456789)\n",
      "Discover Artificial Intelligence             (2022) 2:7  | https://doi.org/10.1007/s44163-022-00023-7\n",
      "1 3\n",
      "Discover Artificial Intelligence\n",
      "Perspective\n",
      "AI‑powered narrative building for facilitating public participation \n",
      "and engagement\n",
      "Fernando Marmolejo‑Ramos1 · Thomas Workman2 · Clint Walker2 · Don Lenihan3 · Sarah Moulds4 · Juan C. Correa5 · \n",
      "Anca M. Hanea6 · Belona Sonna7\n",
      "Received: 22 January 2022 / Accepted: 17 March 2022\n",
      "© The Author(s) 2022   OPEN\n",
      "Abstract\n",
      "Algorithms, data, and AI (ADA) technologies permeate most societies worldwide because of their proven benefits in \n",
      "different areas of life. Governments are the entities in charge of harnessing the benefits of ADA technologies above and \n",
      "beyond providing government services digitally. ADA technologies have the potential to transform the way govern-\n",
      "ments develop and deliver services to citizens, and the way citizens engage with their governments. Conventional public \n",
      "engagement strategies employed by governments have limited both the quality and diversity of deliberation between \n",
      "the citizen and their governments, and the potential for ADA technologies to be employed to improve the experience \n",
      "for both governments and the citizens they serve. In this article we argue that ADA technologies can improve the qual-\n",
      "ity, scope, and reach of public engagement by governments, particularly when coupled with other strategies to ensure \n",
      "legitimacy and accessibility among a broad range of communities and other stakeholders. In particular, we explore the \n",
      "role “narrative building” (NB) can play in facilitating public engagement through the use of ADA technologies. We describe \n",
      "a theoretical implementation of NB enhanced by adding natural language processing, expert knowledge elicitation, \n",
      "and semantic differential rating scales capabilities to increase gains in scale and reach. The theoretical implementation \n",
      "focuses on the public’s opinion on ADA-related technologies, and it derives implications for ethical governance.\n",
      "Keywords Narrative building · Artificial intelligence · Governance · Public affairs · Natural language processing · Expert \n",
      "knowledge elicitation\n",
      " * Fernando Marmolejo-Ramos, fernando.marmolejo-ramos@unisa.edu.au | 1Centre for Change and Complexity in Learning, The \n",
      "University of South Australia, Adelaide, SA 5000, Australia. 2Converlens Pty Ltd AU, Melbourne, Australia. 3Middle Ground Policy Research \n",
      "CA, Ottawa, Canada. 4UniSA Justice & Society, The University of South Australia, Adelaide, Australia. 5CESA Business School, Bogotá, \n",
      "Colombia. 6Ecosystem and Forest Sciences, University of Melbourne, Melbourne, Australia. 7African Institute for Mathematical Sciences, \n",
      "Kigali, Rwanda.' metadata={'producer': 'Acrobat Distiller 10.1.8 (Windows); modified using iText® 5.3.5 ©2000-2012 1T3XT BVBA (SPRINGER SBM; licensed version)', 'creator': 'Springer', 'creationdate': '2022-03-30T21:11:42+05:30', 'keywords': 'Narrative building,Artificial intelligence,Governance,Public affairs,Natural language processing,Expert knowledge elicitation', 'crossmarkdomains[1]': 'springer.com', 'moddate': '2022-03-30T23:33:13+02:00', 'crossmarkmajorversiondate': '2010-04-23', 'subject': 'Discover Artificial Intelligence, https://doi.org/10.1007/s44163-022-00023-7', 'author': 'Fernando Marmolejo-Ramos', 'title': 'AI-powered narrative building for facilitating public participation and engagement', 'crossmarkdomainexclusive': 'true', 'robots': 'noindex', 'doi': '10.1007/s44163-022-00023-7', 'crossmarkdomains[2]': 'springerlink.com', 'source': 'uploads/2cc3dfdf-0e7e-4985-bf22-3aa008c5859b.pdf', 'total_pages': 16, 'page': 0, 'page_label': '1'}\n",
      "Loaded 26 pages from 71bc38d0-af61-4976-9031-7a731795ae0f.pdf\n",
      "\n",
      "\n",
      "page_content='LM Agents for Coordinating Multi-User Information Gathering\n",
      "Harsh Jhamtani, Jacob Andreas, Benjamin Van Durme\n",
      "Microsoft\n",
      "{hjhamtani,jaandrea,ben.vandurme}@microsoft.com\n",
      "Abstract\n",
      "This paper introduces PEOPLE JOIN , a bench-\n",
      "mark for evaluating LM-mediated collaborative\n",
      "problem solving. Given a user request, PEO-\n",
      "PLE JOIN agents must identify teammates who\n",
      "might be able to assist, converse with these\n",
      "teammates to gather information, and finally\n",
      "compile a useful answer or summary for the\n",
      "original user. PEOPLE JOIN comprises two eval-\n",
      "uation domains: PEOPLE JOIN -QA, focused on\n",
      "questions about tabular data, and PEOPLE JOIN -\n",
      "DOCCREATION , focused on document creation\n",
      "tasks. The two domains are adapted from ex-\n",
      "isting NLP benchmarks for database question\n",
      "answering and multi-document summarization;\n",
      "here, however, the information needed to com-\n",
      "plete these tasks is distributed across synthetic\n",
      "“organizations” of 2–20 users, simulating natu-\n",
      "ral multi-user collaboration scenarios. We im-\n",
      "plemented several popular LM agent architec-\n",
      "tures, evaluating their accuracy and efficiency\n",
      "at completing tasks, and highlight new research\n",
      "questions that can be studied using PEOPLE -\n",
      "JOIN .1\n",
      "1 Introduction\n",
      "In today’s fast-paced and interconnected world,\n",
      "effective collaboration is essential for achieving\n",
      "complex tasks and making informed decisions\n",
      "(Papachristou et al., 2023; Gemp et al., 2024).\n",
      "Many decision-making, content creation, and\n",
      "information-gathering tasks require collecting in-\n",
      "formation from multiple people. For example,\n",
      "preparing a list of interns across teams in an or-\n",
      "ganization by reaching out to the leader of each\n",
      "team; preparing a newsletter for project updates\n",
      "might necessitate coordinating with multiple con-\n",
      "tributors; identifying a suitable time to meet might\n",
      "require several rounds of negotiations (Lin et al.,\n",
      "2024). Identifying what information is available,\n",
      "1Code and data can be found at https://github.com/\n",
      "microsoft/peoplejoin/\n",
      "judiciously determining who to contact, asking pre-\n",
      "cise questions, and compiling research results can\n",
      "be a challenging and time-consuming process—\n",
      "especially when real-time interaction between team\n",
      "members is difficult to coordinate.\n",
      "At the same time, recent large language mod-\n",
      "els (LLMs), such as GPT-4 (OpenAI, 2023), Phi-3\n",
      "(Abdin et al., 2024), LLaMa (Touvron et al., 2023),\n",
      "and Gemini (Team et al., 2023), are becoming a cru-\n",
      "cial building block in developing automated agents\n",
      "that can assist human users with complex tasks\n",
      "(Xi et al., 2023; Wang et al., 2024; Butler et al.,\n",
      "2023). These tasks include chat applications for\n",
      "assisting individual users with searching and sum-\n",
      "marizing information (such as in Microsoft Copilot\n",
      "Chat2), and even supporting these users in work-\n",
      "place decision-making (Butler et al., 2023; Kim\n",
      "and Hsu, 2024). Could these agents be extended to\n",
      "improve collaboration among multiple users?\n",
      "In this paper, we introduce PEOPLE JOIN , an\n",
      "evaluation framework for studying effectiveness\n",
      "of LLM-powered agents to assist with multi-user\n",
      "collaboration tasks. Each PEOPLE JOIN task takes\n",
      "place within a fictitious organization with 2–20\n",
      "employees, some of whom possess a collection of\n",
      "documents necessary to solve some task. One of\n",
      "the users (the initiating user) communicates the\n",
      "task to an agent (Fig. 1). Agents have direct ac-\n",
      "cess to the initiating user’s documents, and can\n",
      "engage in conversations with other users to gather\n",
      "relevant information. They must rely on limited\n",
      "descriptions of other users, and potentially previ-\n",
      "ous interactions, to determine who to contact for a\n",
      "given task. PEOPLE JOIN comprises two families\n",
      "of tasks: PEOPLE JOIN -QA and PEOPLE JOIN -\n",
      "DOCCREATION , derived from the SPIDER (Yu\n",
      "et al., 2018) and MULTINEWS (Fabbri et al., 2019)\n",
      "datasets respectively. It evaluates agents’ ability\n",
      "to answer questions involving complex relational\n",
      "2https://copilot.microsoft.com/\n",
      "arXiv:2502.12328v1  [cs.CL]  17 Feb 2025' metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2025-02-19T01:08:14+00:00', 'author': '', 'keywords': '', 'moddate': '2025-02-19T01:08:14+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'subject': '', 'title': '', 'trapped': '/False', 'source': 'uploads/71bc38d0-af61-4976-9031-7a731795ae0f.pdf', 'total_pages': 26, 'page': 0, 'page_label': '1'}\n",
      "Loaded 16 pages from 88a2e2ce-6b71-407c-978a-56e2d043ec02.pdf\n",
      "\n",
      "\n",
      "page_content='Vol.:(0123456789)\n",
      "Discover Artificial Intelligence             (2022) 2:7  | https://doi.org/10.1007/s44163-022-00023-7\n",
      "1 3\n",
      "Discover Artificial Intelligence\n",
      "Perspective\n",
      "AI‑powered narrative building for facilitating public participation \n",
      "and engagement\n",
      "Fernando Marmolejo‑Ramos1 · Thomas Workman2 · Clint Walker2 · Don Lenihan3 · Sarah Moulds4 · Juan C. Correa5 · \n",
      "Anca M. Hanea6 · Belona Sonna7\n",
      "Received: 22 January 2022 / Accepted: 17 March 2022\n",
      "© The Author(s) 2022   OPEN\n",
      "Abstract\n",
      "Algorithms, data, and AI (ADA) technologies permeate most societies worldwide because of their proven benefits in \n",
      "different areas of life. Governments are the entities in charge of harnessing the benefits of ADA technologies above and \n",
      "beyond providing government services digitally. ADA technologies have the potential to transform the way govern-\n",
      "ments develop and deliver services to citizens, and the way citizens engage with their governments. Conventional public \n",
      "engagement strategies employed by governments have limited both the quality and diversity of deliberation between \n",
      "the citizen and their governments, and the potential for ADA technologies to be employed to improve the experience \n",
      "for both governments and the citizens they serve. In this article we argue that ADA technologies can improve the qual-\n",
      "ity, scope, and reach of public engagement by governments, particularly when coupled with other strategies to ensure \n",
      "legitimacy and accessibility among a broad range of communities and other stakeholders. In particular, we explore the \n",
      "role “narrative building” (NB) can play in facilitating public engagement through the use of ADA technologies. We describe \n",
      "a theoretical implementation of NB enhanced by adding natural language processing, expert knowledge elicitation, \n",
      "and semantic differential rating scales capabilities to increase gains in scale and reach. The theoretical implementation \n",
      "focuses on the public’s opinion on ADA-related technologies, and it derives implications for ethical governance.\n",
      "Keywords Narrative building · Artificial intelligence · Governance · Public affairs · Natural language processing · Expert \n",
      "knowledge elicitation\n",
      " * Fernando Marmolejo-Ramos, fernando.marmolejo-ramos@unisa.edu.au | 1Centre for Change and Complexity in Learning, The \n",
      "University of South Australia, Adelaide, SA 5000, Australia. 2Converlens Pty Ltd AU, Melbourne, Australia. 3Middle Ground Policy Research \n",
      "CA, Ottawa, Canada. 4UniSA Justice & Society, The University of South Australia, Adelaide, Australia. 5CESA Business School, Bogotá, \n",
      "Colombia. 6Ecosystem and Forest Sciences, University of Melbourne, Melbourne, Australia. 7African Institute for Mathematical Sciences, \n",
      "Kigali, Rwanda.' metadata={'producer': 'Acrobat Distiller 10.1.8 (Windows); modified using iText® 5.3.5 ©2000-2012 1T3XT BVBA (SPRINGER SBM; licensed version)', 'creator': 'Springer', 'creationdate': '2022-03-30T21:11:42+05:30', 'keywords': 'Narrative building,Artificial intelligence,Governance,Public affairs,Natural language processing,Expert knowledge elicitation', 'crossmarkdomains[1]': 'springer.com', 'moddate': '2022-03-30T23:33:13+02:00', 'crossmarkmajorversiondate': '2010-04-23', 'subject': 'Discover Artificial Intelligence, https://doi.org/10.1007/s44163-022-00023-7', 'author': 'Fernando Marmolejo-Ramos', 'title': 'AI-powered narrative building for facilitating public participation and engagement', 'crossmarkdomainexclusive': 'true', 'robots': 'noindex', 'doi': '10.1007/s44163-022-00023-7', 'crossmarkdomains[2]': 'springerlink.com', 'source': 'uploads/88a2e2ce-6b71-407c-978a-56e2d043ec02.pdf', 'total_pages': 16, 'page': 0, 'page_label': '1'}\n",
      "Loaded 16 pages from 3a89dca8-d097-41f3-8003-31fa588a1128.pdf\n",
      "\n",
      "\n",
      "page_content='Vol.:(0123456789)\n",
      "Discover Artificial Intelligence             (2022) 2:7  | https://doi.org/10.1007/s44163-022-00023-7\n",
      "1 3\n",
      "Discover Artificial Intelligence\n",
      "Perspective\n",
      "AI‑powered narrative building for facilitating public participation \n",
      "and engagement\n",
      "Fernando Marmolejo‑Ramos1 · Thomas Workman2 · Clint Walker2 · Don Lenihan3 · Sarah Moulds4 · Juan C. Correa5 · \n",
      "Anca M. Hanea6 · Belona Sonna7\n",
      "Received: 22 January 2022 / Accepted: 17 March 2022\n",
      "© The Author(s) 2022   OPEN\n",
      "Abstract\n",
      "Algorithms, data, and AI (ADA) technologies permeate most societies worldwide because of their proven benefits in \n",
      "different areas of life. Governments are the entities in charge of harnessing the benefits of ADA technologies above and \n",
      "beyond providing government services digitally. ADA technologies have the potential to transform the way govern-\n",
      "ments develop and deliver services to citizens, and the way citizens engage with their governments. Conventional public \n",
      "engagement strategies employed by governments have limited both the quality and diversity of deliberation between \n",
      "the citizen and their governments, and the potential for ADA technologies to be employed to improve the experience \n",
      "for both governments and the citizens they serve. In this article we argue that ADA technologies can improve the qual-\n",
      "ity, scope, and reach of public engagement by governments, particularly when coupled with other strategies to ensure \n",
      "legitimacy and accessibility among a broad range of communities and other stakeholders. In particular, we explore the \n",
      "role “narrative building” (NB) can play in facilitating public engagement through the use of ADA technologies. We describe \n",
      "a theoretical implementation of NB enhanced by adding natural language processing, expert knowledge elicitation, \n",
      "and semantic differential rating scales capabilities to increase gains in scale and reach. The theoretical implementation \n",
      "focuses on the public’s opinion on ADA-related technologies, and it derives implications for ethical governance.\n",
      "Keywords Narrative building · Artificial intelligence · Governance · Public affairs · Natural language processing · Expert \n",
      "knowledge elicitation\n",
      " * Fernando Marmolejo-Ramos, fernando.marmolejo-ramos@unisa.edu.au | 1Centre for Change and Complexity in Learning, The \n",
      "University of South Australia, Adelaide, SA 5000, Australia. 2Converlens Pty Ltd AU, Melbourne, Australia. 3Middle Ground Policy Research \n",
      "CA, Ottawa, Canada. 4UniSA Justice & Society, The University of South Australia, Adelaide, Australia. 5CESA Business School, Bogotá, \n",
      "Colombia. 6Ecosystem and Forest Sciences, University of Melbourne, Melbourne, Australia. 7African Institute for Mathematical Sciences, \n",
      "Kigali, Rwanda.' metadata={'producer': 'Acrobat Distiller 10.1.8 (Windows); modified using iText® 5.3.5 ©2000-2012 1T3XT BVBA (SPRINGER SBM; licensed version)', 'creator': 'Springer', 'creationdate': '2022-03-30T21:11:42+05:30', 'keywords': 'Narrative building,Artificial intelligence,Governance,Public affairs,Natural language processing,Expert knowledge elicitation', 'crossmarkdomains[1]': 'springer.com', 'moddate': '2022-03-30T23:33:13+02:00', 'crossmarkmajorversiondate': '2010-04-23', 'subject': 'Discover Artificial Intelligence, https://doi.org/10.1007/s44163-022-00023-7', 'author': 'Fernando Marmolejo-Ramos', 'title': 'AI-powered narrative building for facilitating public participation and engagement', 'crossmarkdomainexclusive': 'true', 'robots': 'noindex', 'doi': '10.1007/s44163-022-00023-7', 'crossmarkdomains[2]': 'springerlink.com', 'source': 'uploads/3a89dca8-d097-41f3-8003-31fa588a1128.pdf', 'total_pages': 16, 'page': 0, 'page_label': '1'}\n",
      "Loaded 5 pages from 1eb5a765-e7bb-440e-932e-e4ded92bf621.pdf\n",
      "\n",
      "\n",
      "page_content='Amplifying Minority Voices: AI-Mediated Devil’s Advocate\n",
      "System for Inclusive Group Decision-Making\n",
      "Soohwan Lee∗\n",
      "Department of Design, UNIST\n",
      "Ulsan, Republic of Korea\n",
      "soohwanlee@unist.ac.kr\n",
      "Mingyu Kim∗\n",
      "Department of Design, UNIST\n",
      "Ulsan, Republic of Korea\n",
      "gyu7991@unist.ac.kr\n",
      "Seoyeong Hwang\n",
      "Department of Design, UNIST\n",
      "Ulsan, Republic of Korea\n",
      "hseoyeong@unist.ac.kr\n",
      "Dajung Kim\n",
      "Department of Design, UNIST\n",
      "Ulsan, Republic of Korea\n",
      "dajungkim@unist.ac.kr\n",
      "Kyungho Lee\n",
      "Department of Design, UNIST\n",
      "Ulsan, Republic of Korea\n",
      "kyungho@unist.ac.kr\n",
      "T h e  M a j o r i t y  ( ≥ 3 )\n",
      "w i t h  H i g h  P o w e r\n",
      "T h e  M i n o r i t y\n",
      "w i t h  L o w  P o w e r\n",
      "C o m p l i a n c e\n",
      "L L M - p o w e r e d\n",
      "D e v i l ’ s  A d v o c a t e\n",
      "S o c i a l\n",
      "I n f l u e n c e\n",
      "Figure 1: Mitigating Social Influence with an LLM-powered Devil’s Advocate. Minority members often conform to majority\n",
      "opinions due to social pressure. Our system allows minorities to share different opinions with an LLM-powered Devil’s Advocate,\n",
      "which reframes and presents them as its own. This increases psychological safety, mitigates bias, and fosters critical discussion.\n",
      "Abstract\n",
      "Group decision-making often benefits from diverse perspectives, yet\n",
      "power imbalances and social influence can stifle minority opinions\n",
      "and compromise outcomes. This prequel introduces an AI-mediated\n",
      "communication system that leverages the Large Language Model\n",
      "to serve as a devil’s advocate, representing underrepresented view-\n",
      "points without exposing minority members’ identities. Rooted in\n",
      "persuasive communication strategies and anonymity, the system\n",
      "aims to improve psychological safety and foster more inclusive\n",
      "decision-making. Our multi-agent architecture, which consists of\n",
      "∗Equally contributed to this work.\n",
      "Permission to make digital or hard copies of all or part of this work for personal or\n",
      "classroom use is granted without fee provided that copies are not made or distributed\n",
      "for profit or commercial advantage and that copies bear this notice and the full citation\n",
      "on the first page. Copyrights for third-party components of this work must be honored.\n",
      "For all other uses, contact the owner/author(s).\n",
      "IUI Companion ’25, March 24–27, 2025, Cagliari, Italy\n",
      "© 2025 Copyright held by the owner/author(s).\n",
      "ACM ISBN 979-8-4007-1409-2/25/03\n",
      "https://doi.org/10.1145/3708557.3716334\n",
      "a summary agent, conversation agent, AI duplicate checker, and\n",
      "paraphrase agent, encourages the group’s critical thinking while\n",
      "reducing repetitive outputs. We acknowledge that reliance on text-\n",
      "based communication and fixed intervention timings may limit\n",
      "adaptability, indicating pathways for refinement. By focusing on\n",
      "the representation of minority viewpoints anonymously in power-\n",
      "imbalanced settings, this approach highlights how AI-driven meth-\n",
      "ods can evolve to support more divergent and inclusive group\n",
      "decision-making.\n",
      "CCS Concepts\n",
      "• Human-centered computing → Collaborative interaction;\n",
      "Collaborative and social computing systems and tools .\n",
      "Keywords\n",
      "AI-mediated Communication; AI-assisted Decision-making, Group\n",
      "Dynamics, Social Influence, Compliance, LLM\n",
      "arXiv:2502.06251v1  [cs.HC]  10 Feb 2025' metadata={'producer': 'pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'creator': 'LaTeX with acmart 2024/05/27 v2.08 Typesetting articles for the Association for Computing Machinery and hyperref 2023-04-22 v7.00x Hypertext links for LaTeX', 'creationdate': '2025-02-11T02:22:50+00:00', 'moddate': '2025-02-11T02:22:50+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'subject': '-  Human-centered computing  ->  Collaborative interaction.Collaborative and social computing systems and tools.', 'title': \"Amplifying Minority Voices: AI-Mediated Devil's Advocate System for Inclusive Group Decision-Making\", 'trapped': '/False', 'source': 'uploads/1eb5a765-e7bb-440e-932e-e4ded92bf621.pdf', 'total_pages': 5, 'page': 0, 'page_label': '1'}\n",
      "Loaded 14 pages from 749b97d4-b0d6-4059-9e62-eb35a690208a.pdf\n",
      "\n",
      "\n",
      "page_content='See discussions, stats, and author profiles for this publication at: https://www.researchgate.net/publication/384228166\n",
      "How large language models can reshape collective intelligence\n",
      "Article  in   Nature Human Behaviour · September 2024\n",
      "DOI: 10.1038/s41562-024-01959-9\n",
      "CITATIONS\n",
      "27\n",
      "READS\n",
      "3,000\n",
      "28 authors, including:\n",
      "Jason Burton\n",
      "Copenhagen Business School\n",
      "11 PUBLICATIONS   646 CITATIONS   \n",
      "SEE PROFILE\n",
      "Ezequiel Lopez-Lopez\n",
      "Max Planck Institute for Human Development\n",
      "5 PUBLICATIONS   28 CITATIONS   \n",
      "SEE PROFILE\n",
      "Zoe Rahwan\n",
      "Max Planck Institute for Human Development\n",
      "13 PUBLICATIONS   115 CITATIONS   \n",
      "SEE PROFILE\n",
      "Samuel Aeschbach\n",
      "University of Basel\n",
      "8 PUBLICATIONS   103 CITATIONS   \n",
      "SEE PROFILE\n",
      "All content following this page was uploaded by Taha Yasseri on 25 September 2024.\n",
      "The user has requested enhancement of the downloaded file.' metadata={'producer': 'PyPDF', 'creator': 'Springer', 'creationdate': '2024-09-16T16:43:21+05:30', 'author': 'Jason W. Burton', 'crossmarkdomains[1]': 'springer.com', 'crossmarkdomains[2]': 'springerlink.com', 'keywords': '', 'moddate': '2024-09-16T16:44:15+05:30', 'subject': 'Nature Human Behaviour, doi:10.1038/s41562-024-01959-9', 'title': 'How large language models can reshape collective intelligence', 'doi': '10.1038/s41562-024-01959-9', 'rgid': 'PB:384228166_AS:11431281279985736@1727266110169', 'source': 'uploads/749b97d4-b0d6-4059-9e62-eb35a690208a.pdf', 'total_pages': 14, 'page': 0, 'page_label': '1'}\n",
      "Loaded 17 pages from 3db5b2db-1578-482b-bf60-5e7979f0cd52.pdf\n",
      "\n",
      "\n",
      "page_content='Evaluation and Facilitation of Online Discussions in the LLM Era:\n",
      "A Survey\n",
      "Katerina Korre†⋆ , Dimitris Tsirmpas†‡ , Nikos Gkoumas† , Emma Cabalé♢\n",
      "Dionysios Kontarinis†, Danai Myrtzani‡ , Theodoros Evgeniou♠\n",
      "Ion Androutsopoulos‡†, John Pavlopoulos‡†\n",
      "†Archimedes/Athena RC, Greece (n.goumas@athenarc.gr, denniskont@gmail.com)\n",
      "‡Athens University of Economics and Business, Greece ({dim.tsirmpas,dan.myrtzani,ion,annis}@aueb.gr)\n",
      "♢École Normale Supérieure Paris-Saclay, France (emma.cabale@ens-paris-saclay.fr)\n",
      "♠INSEAD, Technology and Business, France (theodoros.evgeniou@insead.edu)\n",
      "⋆Università di Bologna, Italy (aikaterini.korre2@unibo.it)\n",
      "Abstract\n",
      "We present a survey of methods for assessing\n",
      "and enhancing the quality of online discussions,\n",
      "focusing on the potential of Large Language\n",
      "Models (LLMs). While online discourses aim,\n",
      "at least in theory, to foster mutual understand-\n",
      "ing, they often devolve into harmful exchanges,\n",
      "such as hate speech, threatening social cohe-\n",
      "sion and democratic values. Recent advance-\n",
      "ments in LLMs enable facilitation agents that\n",
      "not only moderate content, but also actively\n",
      "improve the quality of interactions. Our sur-\n",
      "vey synthesizes ideas from Natural Language\n",
      "Processing (NLP) and Social Sciences to pro-\n",
      "vide (a) a new taxonomy on discussion quality\n",
      "evaluation, (b) an overview of intervention and\n",
      "facilitation strategies, along with a new taxon-\n",
      "omy on conversation facilitation datasets, (c) an\n",
      "LLM-oriented roadmap of good practices and\n",
      "future research directions, from technological\n",
      "and societal perspectives.\n",
      "1 Introduction\n",
      "Discussions, especially of complex or controver-\n",
      "sial topics, are a cornerstone of collective decision-\n",
      "making (Burton et al., 2024). In contrast to initial\n",
      "hopes of promoting mutual understanding (Rhein-\n",
      "gold, 2000), online discussions (especially in social\n",
      "media) often degenerate into hate speech, personal\n",
      "attacks, promoting conspiracy theories or propa-\n",
      "ganda – to the extent that they can even be con-\n",
      "sidered a threat to social cohesion and democracy\n",
      "(Tucker et al., 2018; Mathew et al., 2019).\n",
      "Natural Language Processing ( NLP) and\n",
      "Machine Learning (ML) can potentially help im-\n",
      "prove the quality of online discussions. For exam-\n",
      "ple, automatic classifiers (Bang et al., 2023; Molina\n",
      "and Sundar, 2022) are already being used to help or\n",
      "even replace human moderators, by flagging posts\n",
      "that violate the law or policies of online discussion\n",
      "fora (Saeidi et al., 2021).\n",
      "Social Science provides theories and applica-\n",
      "tions for the facilitation of a discussion, but in\n",
      "specific contexts, such as teaching/learning (Man-\n",
      "sour, 2024) or clinical discussions (Gelula, 1997),\n",
      "without much research conducted for thread-like\n",
      "discussions.\n",
      "Improving the quality of online discussions pre-\n",
      "supposes being able to define and measure discus-\n",
      "sion quality. Here, work from Social Science, but\n",
      "also Argument Mining (AM) (Lapesa et al., 2024),\n",
      "can again provide several ideas on dimensions (as-\n",
      "pects) of discussion quality, such as logical co-\n",
      "hesion and constructiveness, as well as ideas on\n",
      "methods to measure quality along each dimension.\n",
      "This paper surveys research from Social Sci-\n",
      "ence and relevant NLP areas (e.g., AM, Senti-\n",
      "ment Analysis, Toxicity Detection), focusing on\n",
      "how Large Language Models (LLMs) can facilitate\n",
      "human discussions—similar to human facilitators\n",
      "(Kahane, 2013). While prior studies have explored\n",
      "LLM-facilitated discussions (Burton et al., 2024;\n",
      "Aher et al., 2023; Beck et al., 2024; Schroeder\n",
      "et al., 2024; Small et al., 2023; Cho et al., 2024),\n",
      "their connection to Social Science remains underex-\n",
      "plored. In this survey, we include methods from So-\n",
      "cial Science (e.g., linguistics) when discussing ap-\n",
      "proaches for evaluating online discussions, as well\n",
      "as when exploring intervention strategies (e.g., fa-\n",
      "cilitative tactics). LLM-based facilitation again pre-\n",
      "supposes defining and evaluating discussion qual-\n",
      "ity. This is even more necessary in the case of\n",
      "LLMs, because of their rapid deployment, poten-\n",
      "tial biases, and long-term societal consequences.\n",
      "Without continuous and thorough assessment, we\n",
      "risk implementing LLM-based facilitation systems\n",
      "that may be ineffective, biased, or even harmful,\n",
      "before their full implications are understood.\n",
      "Therefore, we survey discussion evaluation as-\n",
      "pects and their feasibility with LLMs, introducing\n",
      "a new taxonomy inspired by deliberation studies.\n",
      "We map tasks suited for ML models, LLMs, and\n",
      "humans, aggregate multidimensional insights on\n",
      "facilitation strategies, and outline future capabil-\n",
      "1\n",
      "arXiv:2503.01513v1  [cs.CL]  3 Mar 2025' metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2025-03-04T03:13:50+00:00', 'author': '', 'keywords': '', 'moddate': '2025-03-04T03:13:50+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'subject': '', 'title': '', 'trapped': '/False', 'source': 'uploads/3db5b2db-1578-482b-bf60-5e7979f0cd52.pdf', 'total_pages': 17, 'page': 0, 'page_label': '1'}\n",
      "Loaded 14 pages from 40d8e413-ca79-4f63-bfca-d2cc76055a6e.pdf\n",
      "\n",
      "\n",
      "page_content='See discussions, stats, and author profiles for this publication at: https://www.researchgate.net/publication/384228166\n",
      "How large language models can reshape collective intelligence\n",
      "Article  in   Nature Human Behaviour · September 2024\n",
      "DOI: 10.1038/s41562-024-01959-9\n",
      "CITATIONS\n",
      "27\n",
      "READS\n",
      "3,000\n",
      "28 authors, including:\n",
      "Jason Burton\n",
      "Copenhagen Business School\n",
      "11 PUBLICATIONS   646 CITATIONS   \n",
      "SEE PROFILE\n",
      "Ezequiel Lopez-Lopez\n",
      "Max Planck Institute for Human Development\n",
      "5 PUBLICATIONS   28 CITATIONS   \n",
      "SEE PROFILE\n",
      "Zoe Rahwan\n",
      "Max Planck Institute for Human Development\n",
      "13 PUBLICATIONS   115 CITATIONS   \n",
      "SEE PROFILE\n",
      "Samuel Aeschbach\n",
      "University of Basel\n",
      "8 PUBLICATIONS   103 CITATIONS   \n",
      "SEE PROFILE\n",
      "All content following this page was uploaded by Taha Yasseri on 25 September 2024.\n",
      "The user has requested enhancement of the downloaded file.' metadata={'producer': 'PyPDF', 'creator': 'Springer', 'creationdate': '2024-09-16T16:43:21+05:30', 'author': 'Jason W. Burton', 'crossmarkdomains[1]': 'springer.com', 'crossmarkdomains[2]': 'springerlink.com', 'keywords': '', 'moddate': '2024-09-16T16:44:15+05:30', 'subject': 'Nature Human Behaviour, doi:10.1038/s41562-024-01959-9', 'title': 'How large language models can reshape collective intelligence', 'doi': '10.1038/s41562-024-01959-9', 'rgid': 'PB:384228166_AS:11431281279985736@1727266110169', 'source': 'uploads/40d8e413-ca79-4f63-bfca-d2cc76055a6e.pdf', 'total_pages': 14, 'page': 0, 'page_label': '1'}\n",
      "Loaded 22 pages from c01c6ab2-a11f-441b-9120-699bd7a40522.pdf\n",
      "\n",
      "\n",
      "page_content='Technology in Society 78 (2024) 102662\n",
      "Available online 17 July 2024\n",
      "0160-791X/© 2024 The Authors. Published by Elsevier Ltd. This is an open access article under the CC BY-NC-ND license (http://creativecommons.org/licenses/by-\n",
      "nc-nd/4.0/).\n",
      "Exploring collaborative decision-making: A quasi-experimental study of\n",
      "human and Generative AI interaction\n",
      "Xinyue Hao\n",
      "*\n",
      ", Emrah Demir , Daniel Eyers\n",
      "Logistics & Operations Management Section, Cardiff Business School, Cardiff University, Cardiff CF10 3EU, United Kingdom\n",
      "ARTICLE INFO\n",
      "Keywords:\n",
      "ChatGPT\n",
      "Artificial intelligence\n",
      "Human intuition\n",
      "Decision-making\n",
      "Cognitive biases\n",
      "ABSTRACT\n",
      "This paper explores the effects of integrating Generative Artificial Intelligence (GAI) into decision-making pro-\n",
      "cesses within organizations, employing a quasi-experimental pretest-posttest design. The study examines the\n",
      "synergistic interaction between Human Intelligence (HI) and GAI across four group decision-making scenarios\n",
      "within three global organizations renowned for their cutting-edge operational techniques. The research pro-\n",
      "gresses through several phases: identifying research problems, collecting baseline data on decision-making,\n",
      "implementing AI interventions, and evaluating the outcomes post-intervention to identify shifts in perfor-\n",
      "mance. The results demonstrate that GAI effectively reduces human cognitive burdens and mitigates heuristic\n",
      "biases by offering data-driven support and predictive analytics, grounded in System 2 reasoning. This is\n",
      "particularly valuable in complex situations characterized by unfamiliarity and information overload, where\n",
      "intuitive, System 1 thinking is less effective. However, the study also uncovers challenges related to GAI inte-\n",
      "gration, such as potential over-reliance on technology, intrinsic biases particularly ‘out-of-the-box ’ thinking\n",
      "without contextual creativity. To address these issues, this paper proposes an innovative strategic framework for\n",
      "HI-GAI collaboration that emphasizes transparency, accountability, and inclusiveness.\n",
      "1. Introduction\n",
      "The release of ChatGPT on November 30, 2022 [ 1 ], coincided with\n",
      "the aftermath of a global pandemic, was within a period characterized\n",
      "by significant societal and technological transformations. Before the\n",
      "introduction of Generative AI (GAI), ‘traditional AI ’ , which requires\n",
      "structured data for model construction and information processing,\n",
      "including neural networks, evolutionary algorithms, decision trees,\n",
      "random forests, support vector machines, and k-means clustering were\n",
      "already widespread [ 2 ]. Traditional AI was integrated into applications\n",
      "that influenced pricing, inventory management, logistic optimization,\n",
      "content recommendation etc., but were somewhat restricted in their\n",
      "functionality and had difficulties in directly interacting with users [ 3 ].\n",
      "In contrast, GAI technologies such as ChatGPT introduced a user inter-\n",
      "face that made AI both accessible and a regular part of daily technology\n",
      "use [ 4 ]. This made a significant shift towards direct human-AI collabo-\n",
      "ration [ 5 ]. This ease of use and direct interaction has ushered in a new\n",
      "era of machine-driven intelligence, where technological advances have\n",
      "outpaced organizational understanding of their effective management\n",
      "and exploitation.\n",
      "In the traditional paradigms of organizational decision-making,\n",
      "human intelligence (HI) whether individual or collective, is distin-\n",
      "guished by a blend of intuitive perception, emotional sensitivity, and\n",
      "cultural cognizance, that resonates across scenarios, from executing\n",
      "immediate, task-specific objectives [ 6 ] to strategizing for comprehen-\n",
      "sive, long-term aspirations [ 7 ]. These intrinsic human cognitive abilities\n",
      "inject creative and deep-seated insights into the strategic framework,\n",
      "thus equipping the organization with the fitness to adeptly steer through\n",
      "market fluctuations, competitive pressures, and technological ad-\n",
      "vancements [ 8 ]. Where teams must interact dynamically with constantly\n",
      "changing external variables, the comprehensive range of human cogni-\n",
      "tive skills is essential for plotting pathways through ambiguous situa-\n",
      "tions and capitalizing on the opportunities that such adaptability affords\n",
      "[ 9 ]. However, cognitive, and heuristic biases, essentially ‘rule of thumb ’\n",
      "or ‘mental shortcuts ’ evolved for information-processing efficiency [ 10 ],\n",
      "can sometimes be advantageous but often constrict perception and\n",
      "engender systematic errors in judgment, frequently leading to distorted\n",
      "reasoning and suboptimal decision-making outcomes [ 11 ]. High reli-\n",
      "ance on familiar biases can overshadow data-driven analysis. The latest\n",
      "iteration, GPT-4o ( “ o ” for “ omni ” ), expands on GPT-4 with 1.76 trillion\n",
      "* Corresponding author.\n",
      "E-mail address: haox2@cardiff.ac.uk (X. Hao).\n",
      "Contents lists available at ScienceDirect\n",
      "Technology in Society\n",
      "journal homep age: www.el sevier.com/l ocate/techso c\n",
      "https://doi.org/10.1016/j.techsoc.2024.102662\n",
      "Received 22 January 2024; Received in revised form 3 June 2024; Accepted 14 July 2024' metadata={'producer': 'Acrobat Distiller 8.1.0 (Windows)', 'creator': 'Elsevier', 'creationdate': '2024-07-19T14:48:15+00:00', 'crossmarkdomains[1]': 'elsevier.com', 'creationdate--text': '20th July 2024', 'robots': 'noindex', 'elsevierwebpdfspecifications': '7.0', 'moddate': '2024-07-20T09:27:48+00:00', 'doi': '10.1016/j.techsoc.2024.102662', 'keywords': 'ChatGPT,Artificial intelligence,Human intuition,Decision-making,Cognitive biases', 'title': 'Exploring collaborative decision-making: A quasi-experimental study of human and Generative AI interaction', 'subject': 'Technology in Society, 78 (2024) 102662. doi:10.1016/j.techsoc.2024.102662', 'crossmarkdomains[2]': 'sciencedirect.com', 'author': 'Xinyue Hao', 'source': 'uploads/c01c6ab2-a11f-441b-9120-699bd7a40522.pdf', 'total_pages': 22, 'page': 0, 'page_label': '1'}\n",
      "Loaded 22 pages from 24e8a4b6-3e0c-4b6b-a329-2427edc55706.pdf\n",
      "\n",
      "\n",
      "page_content='Technology in Society 78 (2024) 102662\n",
      "Available online 17 July 2024\n",
      "0160-791X/© 2024 The Authors. Published by Elsevier Ltd. This is an open access article under the CC BY-NC-ND license (http://creativecommons.org/licenses/by-\n",
      "nc-nd/4.0/).\n",
      "Exploring collaborative decision-making: A quasi-experimental study of\n",
      "human and Generative AI interaction\n",
      "Xinyue Hao\n",
      "*\n",
      ", Emrah Demir , Daniel Eyers\n",
      "Logistics & Operations Management Section, Cardiff Business School, Cardiff University, Cardiff CF10 3EU, United Kingdom\n",
      "ARTICLE INFO\n",
      "Keywords:\n",
      "ChatGPT\n",
      "Artificial intelligence\n",
      "Human intuition\n",
      "Decision-making\n",
      "Cognitive biases\n",
      "ABSTRACT\n",
      "This paper explores the effects of integrating Generative Artificial Intelligence (GAI) into decision-making pro-\n",
      "cesses within organizations, employing a quasi-experimental pretest-posttest design. The study examines the\n",
      "synergistic interaction between Human Intelligence (HI) and GAI across four group decision-making scenarios\n",
      "within three global organizations renowned for their cutting-edge operational techniques. The research pro-\n",
      "gresses through several phases: identifying research problems, collecting baseline data on decision-making,\n",
      "implementing AI interventions, and evaluating the outcomes post-intervention to identify shifts in perfor-\n",
      "mance. The results demonstrate that GAI effectively reduces human cognitive burdens and mitigates heuristic\n",
      "biases by offering data-driven support and predictive analytics, grounded in System 2 reasoning. This is\n",
      "particularly valuable in complex situations characterized by unfamiliarity and information overload, where\n",
      "intuitive, System 1 thinking is less effective. However, the study also uncovers challenges related to GAI inte-\n",
      "gration, such as potential over-reliance on technology, intrinsic biases particularly ‘out-of-the-box ’ thinking\n",
      "without contextual creativity. To address these issues, this paper proposes an innovative strategic framework for\n",
      "HI-GAI collaboration that emphasizes transparency, accountability, and inclusiveness.\n",
      "1. Introduction\n",
      "The release of ChatGPT on November 30, 2022 [ 1 ], coincided with\n",
      "the aftermath of a global pandemic, was within a period characterized\n",
      "by significant societal and technological transformations. Before the\n",
      "introduction of Generative AI (GAI), ‘traditional AI ’ , which requires\n",
      "structured data for model construction and information processing,\n",
      "including neural networks, evolutionary algorithms, decision trees,\n",
      "random forests, support vector machines, and k-means clustering were\n",
      "already widespread [ 2 ]. Traditional AI was integrated into applications\n",
      "that influenced pricing, inventory management, logistic optimization,\n",
      "content recommendation etc., but were somewhat restricted in their\n",
      "functionality and had difficulties in directly interacting with users [ 3 ].\n",
      "In contrast, GAI technologies such as ChatGPT introduced a user inter-\n",
      "face that made AI both accessible and a regular part of daily technology\n",
      "use [ 4 ]. This made a significant shift towards direct human-AI collabo-\n",
      "ration [ 5 ]. This ease of use and direct interaction has ushered in a new\n",
      "era of machine-driven intelligence, where technological advances have\n",
      "outpaced organizational understanding of their effective management\n",
      "and exploitation.\n",
      "In the traditional paradigms of organizational decision-making,\n",
      "human intelligence (HI) whether individual or collective, is distin-\n",
      "guished by a blend of intuitive perception, emotional sensitivity, and\n",
      "cultural cognizance, that resonates across scenarios, from executing\n",
      "immediate, task-specific objectives [ 6 ] to strategizing for comprehen-\n",
      "sive, long-term aspirations [ 7 ]. These intrinsic human cognitive abilities\n",
      "inject creative and deep-seated insights into the strategic framework,\n",
      "thus equipping the organization with the fitness to adeptly steer through\n",
      "market fluctuations, competitive pressures, and technological ad-\n",
      "vancements [ 8 ]. Where teams must interact dynamically with constantly\n",
      "changing external variables, the comprehensive range of human cogni-\n",
      "tive skills is essential for plotting pathways through ambiguous situa-\n",
      "tions and capitalizing on the opportunities that such adaptability affords\n",
      "[ 9 ]. However, cognitive, and heuristic biases, essentially ‘rule of thumb ’\n",
      "or ‘mental shortcuts ’ evolved for information-processing efficiency [ 10 ],\n",
      "can sometimes be advantageous but often constrict perception and\n",
      "engender systematic errors in judgment, frequently leading to distorted\n",
      "reasoning and suboptimal decision-making outcomes [ 11 ]. High reli-\n",
      "ance on familiar biases can overshadow data-driven analysis. The latest\n",
      "iteration, GPT-4o ( “ o ” for “ omni ” ), expands on GPT-4 with 1.76 trillion\n",
      "* Corresponding author.\n",
      "E-mail address: haox2@cardiff.ac.uk (X. Hao).\n",
      "Contents lists available at ScienceDirect\n",
      "Technology in Society\n",
      "journal homep age: www.el sevier.com/l ocate/techso c\n",
      "https://doi.org/10.1016/j.techsoc.2024.102662\n",
      "Received 22 January 2024; Received in revised form 3 June 2024; Accepted 14 July 2024' metadata={'producer': 'Acrobat Distiller 8.1.0 (Windows)', 'creator': 'Elsevier', 'creationdate': '2024-07-19T14:48:15+00:00', 'crossmarkdomains[1]': 'elsevier.com', 'creationdate--text': '20th July 2024', 'robots': 'noindex', 'elsevierwebpdfspecifications': '7.0', 'moddate': '2024-07-20T09:27:48+00:00', 'doi': '10.1016/j.techsoc.2024.102662', 'keywords': 'ChatGPT,Artificial intelligence,Human intuition,Decision-making,Cognitive biases', 'title': 'Exploring collaborative decision-making: A quasi-experimental study of human and Generative AI interaction', 'subject': 'Technology in Society, 78 (2024) 102662. doi:10.1016/j.techsoc.2024.102662', 'crossmarkdomains[2]': 'sciencedirect.com', 'author': 'Xinyue Hao', 'source': 'uploads/24e8a4b6-3e0c-4b6b-a329-2427edc55706.pdf', 'total_pages': 22, 'page': 0, 'page_label': '1'}\n",
      "Loaded 5 pages from 40905a3f-9afe-4faf-8b0f-21de1cbc5107.pdf\n",
      "\n",
      "\n",
      "page_content='Amplifying Minority Voices: AI-Mediated Devil’s Advocate\n",
      "System for Inclusive Group Decision-Making\n",
      "Soohwan Lee∗\n",
      "Department of Design, UNIST\n",
      "Ulsan, Republic of Korea\n",
      "soohwanlee@unist.ac.kr\n",
      "Mingyu Kim∗\n",
      "Department of Design, UNIST\n",
      "Ulsan, Republic of Korea\n",
      "gyu7991@unist.ac.kr\n",
      "Seoyeong Hwang\n",
      "Department of Design, UNIST\n",
      "Ulsan, Republic of Korea\n",
      "hseoyeong@unist.ac.kr\n",
      "Dajung Kim\n",
      "Department of Design, UNIST\n",
      "Ulsan, Republic of Korea\n",
      "dajungkim@unist.ac.kr\n",
      "Kyungho Lee\n",
      "Department of Design, UNIST\n",
      "Ulsan, Republic of Korea\n",
      "kyungho@unist.ac.kr\n",
      "T h e  M a j o r i t y  ( ≥ 3 )\n",
      "w i t h  H i g h  P o w e r\n",
      "T h e  M i n o r i t y\n",
      "w i t h  L o w  P o w e r\n",
      "C o m p l i a n c e\n",
      "L L M - p o w e r e d\n",
      "D e v i l ’ s  A d v o c a t e\n",
      "S o c i a l\n",
      "I n f l u e n c e\n",
      "Figure 1: Mitigating Social Influence with an LLM-powered Devil’s Advocate. Minority members often conform to majority\n",
      "opinions due to social pressure. Our system allows minorities to share different opinions with an LLM-powered Devil’s Advocate,\n",
      "which reframes and presents them as its own. This increases psychological safety, mitigates bias, and fosters critical discussion.\n",
      "Abstract\n",
      "Group decision-making often benefits from diverse perspectives, yet\n",
      "power imbalances and social influence can stifle minority opinions\n",
      "and compromise outcomes. This prequel introduces an AI-mediated\n",
      "communication system that leverages the Large Language Model\n",
      "to serve as a devil’s advocate, representing underrepresented view-\n",
      "points without exposing minority members’ identities. Rooted in\n",
      "persuasive communication strategies and anonymity, the system\n",
      "aims to improve psychological safety and foster more inclusive\n",
      "decision-making. Our multi-agent architecture, which consists of\n",
      "∗Equally contributed to this work.\n",
      "Permission to make digital or hard copies of all or part of this work for personal or\n",
      "classroom use is granted without fee provided that copies are not made or distributed\n",
      "for profit or commercial advantage and that copies bear this notice and the full citation\n",
      "on the first page. Copyrights for third-party components of this work must be honored.\n",
      "For all other uses, contact the owner/author(s).\n",
      "IUI Companion ’25, March 24–27, 2025, Cagliari, Italy\n",
      "© 2025 Copyright held by the owner/author(s).\n",
      "ACM ISBN 979-8-4007-1409-2/25/03\n",
      "https://doi.org/10.1145/3708557.3716334\n",
      "a summary agent, conversation agent, AI duplicate checker, and\n",
      "paraphrase agent, encourages the group’s critical thinking while\n",
      "reducing repetitive outputs. We acknowledge that reliance on text-\n",
      "based communication and fixed intervention timings may limit\n",
      "adaptability, indicating pathways for refinement. By focusing on\n",
      "the representation of minority viewpoints anonymously in power-\n",
      "imbalanced settings, this approach highlights how AI-driven meth-\n",
      "ods can evolve to support more divergent and inclusive group\n",
      "decision-making.\n",
      "CCS Concepts\n",
      "• Human-centered computing → Collaborative interaction;\n",
      "Collaborative and social computing systems and tools .\n",
      "Keywords\n",
      "AI-mediated Communication; AI-assisted Decision-making, Group\n",
      "Dynamics, Social Influence, Compliance, LLM\n",
      "arXiv:2502.06251v1  [cs.HC]  10 Feb 2025' metadata={'producer': 'pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'creator': 'LaTeX with acmart 2024/05/27 v2.08 Typesetting articles for the Association for Computing Machinery and hyperref 2023-04-22 v7.00x Hypertext links for LaTeX', 'creationdate': '2025-02-11T02:22:50+00:00', 'moddate': '2025-02-11T02:22:50+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'subject': '-  Human-centered computing  ->  Collaborative interaction.Collaborative and social computing systems and tools.', 'title': \"Amplifying Minority Voices: AI-Mediated Devil's Advocate System for Inclusive Group Decision-Making\", 'trapped': '/False', 'source': 'uploads/40905a3f-9afe-4faf-8b0f-21de1cbc5107.pdf', 'total_pages': 5, 'page': 0, 'page_label': '1'}\n",
      "Loaded 14 pages from 723e792d-ec49-4cdd-8662-853f47a1defe.pdf\n",
      "\n",
      "\n",
      "page_content='See discussions, stats, and author profiles for this publication at: https://www.researchgate.net/publication/384228166\n",
      "How large language models can reshape collective intelligence\n",
      "Article  in   Nature Human Behaviour · September 2024\n",
      "DOI: 10.1038/s41562-024-01959-9\n",
      "CITATIONS\n",
      "27\n",
      "READS\n",
      "3,000\n",
      "28 authors, including:\n",
      "Jason Burton\n",
      "Copenhagen Business School\n",
      "11 PUBLICATIONS   646 CITATIONS   \n",
      "SEE PROFILE\n",
      "Ezequiel Lopez-Lopez\n",
      "Max Planck Institute for Human Development\n",
      "5 PUBLICATIONS   28 CITATIONS   \n",
      "SEE PROFILE\n",
      "Zoe Rahwan\n",
      "Max Planck Institute for Human Development\n",
      "13 PUBLICATIONS   115 CITATIONS   \n",
      "SEE PROFILE\n",
      "Samuel Aeschbach\n",
      "University of Basel\n",
      "8 PUBLICATIONS   103 CITATIONS   \n",
      "SEE PROFILE\n",
      "All content following this page was uploaded by Taha Yasseri on 25 September 2024.\n",
      "The user has requested enhancement of the downloaded file.' metadata={'producer': 'PyPDF', 'creator': 'Springer', 'creationdate': '2024-09-16T16:43:21+05:30', 'author': 'Jason W. Burton', 'crossmarkdomains[1]': 'springer.com', 'crossmarkdomains[2]': 'springerlink.com', 'keywords': '', 'moddate': '2024-09-16T16:44:15+05:30', 'subject': 'Nature Human Behaviour, doi:10.1038/s41562-024-01959-9', 'title': 'How large language models can reshape collective intelligence', 'doi': '10.1038/s41562-024-01959-9', 'rgid': 'PB:384228166_AS:11431281279985736@1727266110169', 'source': 'uploads/723e792d-ec49-4cdd-8662-853f47a1defe.pdf', 'total_pages': 14, 'page': 0, 'page_label': '1'}\n",
      "Loaded 15 pages from 63423fad-cf80-42b6-a9fa-1105b9a929e1.pdf\n",
      "\n",
      "\n",
      "page_content='TYPE Review\n",
      "PUBLISHED /zero.tnum/six.tnum January /two.tnum/zero.tnum/two.tnum/five.tnum\n",
      "DOI /one.tnum/zero.tnum./three.tnum/three.tnum/eight.tnum/nine.tnum/fcomp./two.tnum/zero.tnum/two.tnum/four.tnum./one.tnum/five.tnum/two.tnum/one.tnum/zero.tnum/six.tnum/six.tnum\n",
      "OPEN ACCESS\n",
      "EDITED BY\n",
      "Stefan Kopp,\n",
      "Bielefeld University, Germany\n",
      "REVIEWED BY\n",
      "Styliani Kleanthous,\n",
      "Open University of Cyprus, Cyprus\n",
      "Milus˘e Balková,\n",
      "Institute of Technology and Business, Czechia\n",
      "*CORRESPONDENCE\n",
      "Mathias Unberath\n",
      "unberath@jhu.edu\n",
      "RECEIVED /zero.tnum/one.tnum November /two.tnum/zero.tnum/two.tnum/four.tnum\n",
      "ACCEPTED /zero.tnum/six.tnum December /two.tnum/zero.tnum/two.tnum/four.tnum\n",
      "PUBLISHED /zero.tnum/six.tnum January /two.tnum/zero.tnum/two.tnum/five.tnum\n",
      "CITATION\n",
      "Gomez C, Cho SM, Ke S, Huang C-M and\n",
      "Unberath M (/two.tnum/zero.tnum/two.tnum/five.tnum) Human-AI collaboration is\n",
      "not very collaborative yet: a taxonomy of\n",
      "interaction patterns in AI-assisted decision\n",
      "making from a systematic review.\n",
      "Front. Comput. Sci./six.tnum:/one.tnum/five.tnum/two.tnum/one.tnum/zero.tnum/six.tnum/six.tnum.\n",
      "doi: /one.tnum/zero.tnum./three.tnum/three.tnum/eight.tnum/nine.tnum/fcomp./two.tnum/zero.tnum/two.tnum/four.tnum./one.tnum/five.tnum/two.tnum/one.tnum/zero.tnum/six.tnum/six.tnum\n",
      "COPYRIGHT\n",
      "© /two.tnum/zero.tnum/two.tnum/five.tnum Gomez, Cho, Ke, Huang and\n",
      "Unberath. This is an open-access article\n",
      "distributed under the terms of the\n",
      "Creative\n",
      "Commons Attribution License (CC BY) . The\n",
      "use, distribution or reproduction in other\n",
      "forums is permitted, provided the original\n",
      "author(s) and the copyright owner(s) are\n",
      "credited and that the original publication in\n",
      "this journal is cited, in accordance with\n",
      "accepted academic practice. No use,\n",
      "distribution or reproduction is permitted\n",
      "which does not comply with these terms.\n",
      "Human-AI collaboration is not\n",
      "very collaborative yet: a\n",
      "taxonomy of interaction patterns\n",
      "in AI-assisted decision making\n",
      "from a systematic review\n",
      "Catalina Gomez, Sue Min Cho, Shichang Ke, Chien-Ming Huang\n",
      "and Mathias Unberath*\n",
      "Department of Computer Science, Johns Hopkins University, Baltim ore, MD, United States\n",
      "Leveraging Artiﬁcial Intelligence (AI) in decision support syst ems has\n",
      "disproportionately focused on technological advancements, ofte n overlooking\n",
      "the alignment between algorithmic outputs and human expectatio ns. A\n",
      "human-centered perspective attempts to alleviate this concern by designing AI\n",
      "solutions for seamless integration with existing processes. Determining what\n",
      "information AI should provide to aid humans is vital, a concept u nderscored by\n",
      "explainable AI’s eﬀorts to justify AI predictions. However, h ow the information\n",
      "is presented, e.g., the sequence of recommendations and solicit ation of\n",
      "interpretations, is equally crucial as complex interactions may e merge between\n",
      "humans and AI. While empirical studies have evaluated human-AI dynamics\n",
      "across domains, a common vocabulary for human-AI interaction prot ocols is\n",
      "lacking. To promote more deliberate consideration of interacti on designs, we\n",
      "introduce a taxonomy of interaction patterns that delineate v arious modes of\n",
      "human-AI interactivity. We summarize the results of a system atic review of\n",
      "AI-assisted decision making literature and identify trends and opportunities\n",
      "in existing interactions across application domains from /one.tnum/zero.tnum/five.tnum articles. We ﬁnd\n",
      "that current interactions are dominated by simplistic collabor ation paradigms,\n",
      "leading to little support for truly interactive functionality . Our taxonomy oﬀers a\n",
      "tool to understand interactivity with AI in decision-making and foster interaction\n",
      "designs for achieving clear communication, trustworthiness, and collaboration.\n",
      "KEYWORDS\n",
      "artiﬁcial intelligence, human-AI interaction, decision-ma king, interaction patterns,\n",
      "interactivity\n",
      "/one.tnum Introduction\n",
      "Advances in Artiﬁcial Intelligence (AI) developments open new possibilities for\n",
      "supporting human decision making across a wide variety of applications. Decision making\n",
      "tasks in a broad range of applications share a process that starts when evidence is presented\n",
      "before making a decision within discrete choices, usually with follow-up eﬀects. Within this\n",
      "framework, the decision-making process emerges as a scenario for human-AI teamwork\n",
      "where at a minimum two parties, i.e., the human and the AI, factor into ﬁnding a solution to\n",
      "the decision problem. The exact dynamics of how this collaboration occurs can vary from\n",
      "one situation to another, leading to multiple interaction options that range from simple\n",
      "Frontiers in Computer Science /zero.tnum/one.tnum frontiersin.org' metadata={'producer': 'dvips + MiKTeX GPL Ghostscript  9.0', 'creator': 'LaTeX with hyperref package + hypdvips', 'creationdate': '2024-12-26T12:14:21+05:30', 'subject': 'Gomez C, Cho SM, Ke S, Huang C-M and Unberath M (2025) Human-AI collaboration is not very collaborative yet: a taxonomy of interaction patterns in AI-assisted decision making from a systematic review. Front. Comput. Sci. 6:1521066. doi: 10.3389/fcomp.2024.1521066', 'author': 'Catalina Gomez', 'keywords': 'artificial intelligence; human-AI interaction; decision-making; interaction patterns; interactivity', 'moddate': '2024-12-26T12:33:06+05:30', 'title': 'Human-AI collaboration is not very collaborative yet: a taxonomy of interaction patterns in AI-assisted decision making from a systematic review', 'source': 'uploads/63423fad-cf80-42b6-a9fa-1105b9a929e1.pdf', 'total_pages': 15, 'page': 0, 'page_label': '1'}\n",
      "Loaded 14 pages from ca9e839b-5087-4741-928b-8da20712f4d3.pdf\n",
      "\n",
      "\n",
      "page_content='See discussions, stats, and author profiles for this publication at: https://www.researchgate.net/publication/384228166\n",
      "How large language models can reshape collective intelligence\n",
      "Article  in   Nature Human Behaviour · September 2024\n",
      "DOI: 10.1038/s41562-024-01959-9\n",
      "CITATIONS\n",
      "27\n",
      "READS\n",
      "3,000\n",
      "28 authors, including:\n",
      "Jason Burton\n",
      "Copenhagen Business School\n",
      "11 PUBLICATIONS   646 CITATIONS   \n",
      "SEE PROFILE\n",
      "Ezequiel Lopez-Lopez\n",
      "Max Planck Institute for Human Development\n",
      "5 PUBLICATIONS   28 CITATIONS   \n",
      "SEE PROFILE\n",
      "Zoe Rahwan\n",
      "Max Planck Institute for Human Development\n",
      "13 PUBLICATIONS   115 CITATIONS   \n",
      "SEE PROFILE\n",
      "Samuel Aeschbach\n",
      "University of Basel\n",
      "8 PUBLICATIONS   103 CITATIONS   \n",
      "SEE PROFILE\n",
      "All content following this page was uploaded by Taha Yasseri on 25 September 2024.\n",
      "The user has requested enhancement of the downloaded file.' metadata={'producer': 'PyPDF', 'creator': 'Springer', 'creationdate': '2024-09-16T16:43:21+05:30', 'author': 'Jason W. Burton', 'crossmarkdomains[1]': 'springer.com', 'crossmarkdomains[2]': 'springerlink.com', 'keywords': '', 'moddate': '2024-09-16T16:44:15+05:30', 'subject': 'Nature Human Behaviour, doi:10.1038/s41562-024-01959-9', 'title': 'How large language models can reshape collective intelligence', 'doi': '10.1038/s41562-024-01959-9', 'rgid': 'PB:384228166_AS:11431281279985736@1727266110169', 'source': 'uploads/ca9e839b-5087-4741-928b-8da20712f4d3.pdf', 'total_pages': 14, 'page': 0, 'page_label': '1'}\n",
      "Loaded 25 pages from e3998d0e-29fd-4feb-84df-d42383a1a4e0.pdf\n",
      "\n",
      "\n",
      "page_content='Urban Planning\n",
      "2025 • Volume 10• Article 9165\n",
      "https://doi.org/10.17645/up.9165\n",
      "A R T I C L E Open Access Journal\n",
      "AI‐Supported Participatory Workshops: Middle‐Out Engagement\n",
      "for Crisis Events\n",
      "Martin Tomitsch1\n",
      " , Joel Fredericks2\n",
      " , Marius Hoggenmüller2\n",
      " , Alexandra Crosby3\n",
      " ,\n",
      "Adrian Wong2\n",
      " , Xinyan Yu2\n",
      " , and Weidong Huang1\n",
      "1 TransdisciplinarySchool,UniversityofTechnologySydney,Australia\n",
      "2 SchoolofArchitecture,DesignandPlanning,TheUniversityofSydney,Australia\n",
      "3 FacultyofDesign,ArchitectureandBuilding,UniversityofTechnologySydney,Australia\n",
      "Correspondence: MartinTomitsch(martin.tomitsch@uts.edu.au)\n",
      "Submitted: 9August2024 Accepted: 5November2024 Published: 27January2025\n",
      "Issue: This article is part of the issue “The Role of Participatory Planning and Design in Addressing the\n",
      "UN Sustainable Development Goals” edited by Hilary Davis (Swinburne University of Technology), Joel\n",
      "Fredericks(TheUniversityofSydney),MarcusFoth(QueenslandUniversityofTechnology),GlendaCaldwell\n",
      "(QueenslandUniversityofTechnology),andCallumParker(TheUniversityofSydney),fullyopenaccessat\n",
      "https://doi.org/10.17645/up.i394\n",
      "Abstract\n",
      "Consideringthelivedexperienceofcommunitiesiskeywhenmakingdecisionsincomplexscenarios,suchas\n",
      "preparingforandrespondingtocrisisevents.Thearticlereportsonthreeparticipatoryworkshops,which\n",
      "assigned community representative roles to workshop participants. Using role‐playing as a method,\n",
      "participantsweregiventhetaskofcollaboratingonmakingadecisionrelatingtoaspeculativecrisisscenario.\n",
      "Acrosstheworkshops,wecollecteddataaboutsimulatingamiddle‐outengagementapproachandtherole\n",
      "of artificial intelligence (AI) in enhancing collaboration, supporting decision‐making, and representing\n",
      "non‐humanactors.Thearticlemakesthreecontributionstoparticipatoryplanninganddesigninthecontext\n",
      "of the UN Sustainable Development Goals. First, it presents insights about the use of AI in enhancing\n",
      "collaboration and decision‐making in crisis event situations. Second, it discusses approaches for bringing\n",
      "more‐than‐human considerations into participatory planning and design. Third, it reflects on the value of\n",
      "role‐playingasawaytosimulateamiddle‐outengagementprocess,wherebyactorsfromthetopandthe\n",
      "bottomcollaboratetowardsmakinginformeddecisionsincomplexscenarios.Drawingonthefindingsfrom\n",
      "theworkshops,thearticlecriticallyreflectsonchallengesandrisksassociatedwithusingAIinparticipatory\n",
      "workshopsandcollaborativedecision‐making.\n",
      "Keywords\n",
      "artificialintelligence;communityengagement;conversationalagents;middle‐outengagement;non‐human\n",
      "personas;participatorydesign;participatoryplanning\n",
      "©2025bytheauthor(s),licensedunderaCreativeCommonsAttribution4.0InternationalLicense(CCBY). 1' metadata={'producer': 'xdvipdfmx (20240407)', 'creator': 'LaTeX with hyperref', 'creationdate': '2025-01-20T14:46:41+00:00', 'moddate': '2025-01-20T15:21:30+00:00', 'title': 'AI-Supported Participatory Workshops: Middle-Out Engagement for Crisis Events', 'keywords': 'artificial intelligence; community engagement; conversational agents; middle-out engagement; non-human personas; participatory design; participatory planning', 'author': 'Martin Tomitsch, Joel Fredericks, Marius Hoggenmüller, Alexandra Crosby, Adrian Wong, Xinyan Yu, and Weidong Huang', 'source': 'uploads/e3998d0e-29fd-4feb-84df-d42383a1a4e0.pdf', 'total_pages': 25, 'page': 0, 'page_label': '1'}\n",
      "Loaded 5 pages from 20f572ba-7a30-4dbe-a175-30352547698d.pdf\n",
      "\n",
      "\n",
      "page_content='Amplifying Minority Voices: AI-Mediated Devil’s Advocate\n",
      "System for Inclusive Group Decision-Making\n",
      "Soohwan Lee∗\n",
      "Department of Design, UNIST\n",
      "Ulsan, Republic of Korea\n",
      "soohwanlee@unist.ac.kr\n",
      "Mingyu Kim∗\n",
      "Department of Design, UNIST\n",
      "Ulsan, Republic of Korea\n",
      "gyu7991@unist.ac.kr\n",
      "Seoyeong Hwang\n",
      "Department of Design, UNIST\n",
      "Ulsan, Republic of Korea\n",
      "hseoyeong@unist.ac.kr\n",
      "Dajung Kim\n",
      "Department of Design, UNIST\n",
      "Ulsan, Republic of Korea\n",
      "dajungkim@unist.ac.kr\n",
      "Kyungho Lee\n",
      "Department of Design, UNIST\n",
      "Ulsan, Republic of Korea\n",
      "kyungho@unist.ac.kr\n",
      "T h e  M a j o r i t y  ( ≥ 3 )\n",
      "w i t h  H i g h  P o w e r\n",
      "T h e  M i n o r i t y\n",
      "w i t h  L o w  P o w e r\n",
      "C o m p l i a n c e\n",
      "L L M - p o w e r e d\n",
      "D e v i l ’ s  A d v o c a t e\n",
      "S o c i a l\n",
      "I n f l u e n c e\n",
      "Figure 1: Mitigating Social Influence with an LLM-powered Devil’s Advocate. Minority members often conform to majority\n",
      "opinions due to social pressure. Our system allows minorities to share different opinions with an LLM-powered Devil’s Advocate,\n",
      "which reframes and presents them as its own. This increases psychological safety, mitigates bias, and fosters critical discussion.\n",
      "Abstract\n",
      "Group decision-making often benefits from diverse perspectives, yet\n",
      "power imbalances and social influence can stifle minority opinions\n",
      "and compromise outcomes. This prequel introduces an AI-mediated\n",
      "communication system that leverages the Large Language Model\n",
      "to serve as a devil’s advocate, representing underrepresented view-\n",
      "points without exposing minority members’ identities. Rooted in\n",
      "persuasive communication strategies and anonymity, the system\n",
      "aims to improve psychological safety and foster more inclusive\n",
      "decision-making. Our multi-agent architecture, which consists of\n",
      "∗Equally contributed to this work.\n",
      "Permission to make digital or hard copies of all or part of this work for personal or\n",
      "classroom use is granted without fee provided that copies are not made or distributed\n",
      "for profit or commercial advantage and that copies bear this notice and the full citation\n",
      "on the first page. Copyrights for third-party components of this work must be honored.\n",
      "For all other uses, contact the owner/author(s).\n",
      "IUI Companion ’25, March 24–27, 2025, Cagliari, Italy\n",
      "© 2025 Copyright held by the owner/author(s).\n",
      "ACM ISBN 979-8-4007-1409-2/25/03\n",
      "https://doi.org/10.1145/3708557.3716334\n",
      "a summary agent, conversation agent, AI duplicate checker, and\n",
      "paraphrase agent, encourages the group’s critical thinking while\n",
      "reducing repetitive outputs. We acknowledge that reliance on text-\n",
      "based communication and fixed intervention timings may limit\n",
      "adaptability, indicating pathways for refinement. By focusing on\n",
      "the representation of minority viewpoints anonymously in power-\n",
      "imbalanced settings, this approach highlights how AI-driven meth-\n",
      "ods can evolve to support more divergent and inclusive group\n",
      "decision-making.\n",
      "CCS Concepts\n",
      "• Human-centered computing → Collaborative interaction;\n",
      "Collaborative and social computing systems and tools .\n",
      "Keywords\n",
      "AI-mediated Communication; AI-assisted Decision-making, Group\n",
      "Dynamics, Social Influence, Compliance, LLM\n",
      "arXiv:2502.06251v1  [cs.HC]  10 Feb 2025' metadata={'producer': 'pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'creator': 'LaTeX with acmart 2024/05/27 v2.08 Typesetting articles for the Association for Computing Machinery and hyperref 2023-04-22 v7.00x Hypertext links for LaTeX', 'creationdate': '2025-02-11T02:22:50+00:00', 'moddate': '2025-02-11T02:22:50+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'subject': '-  Human-centered computing  ->  Collaborative interaction.Collaborative and social computing systems and tools.', 'title': \"Amplifying Minority Voices: AI-Mediated Devil's Advocate System for Inclusive Group Decision-Making\", 'trapped': '/False', 'source': 'uploads/20f572ba-7a30-4dbe-a175-30352547698d.pdf', 'total_pages': 5, 'page': 0, 'page_label': '1'}\n",
      "Loaded 14 pages from 7bc07167-7aed-459e-bdb5-6a0f8f0d489c.pdf\n",
      "\n",
      "\n",
      "page_content='AI and the Future of Collaborative Work: Group Ideation with an\n",
      "LLM in a Virtual Canvas\n",
      "Jessica He\n",
      "IBM Research AI\n",
      "Seattle, USA\n",
      "jessicahe@ibm.com\n",
      "Stephanie Houde\n",
      "IBM Research AI\n",
      "Cambridge, USA\n",
      "Stephanie.Houde@ibm.com\n",
      "Gabriel Enrique Gonzalez\n",
      "IBM Argentina\n",
      "Necochea, Argentina\n",
      "gabriel.gonzalez@ibm.com\n",
      "Dario Andres Silva Moran\n",
      "IBM Argentina\n",
      "La Plata, Argentina\n",
      "dario.silva@ibm.com\n",
      "Steven I. Ross\n",
      "IBM Research AI\n",
      "Cambridge, USA\n",
      "steven_ross@us.ibm.com\n",
      "Michael Muller\n",
      "IBM Research AI\n",
      "Cambridge, USA\n",
      "michael_muller@us.ibm.com\n",
      "Justin D. Weisz\n",
      "IBM Research AI\n",
      "Yorktown Heights, USA\n",
      "jweisz@us.ibm.com\n",
      "ABSTRACT\n",
      "The introduction of generative AI into multi-user applications raises\n",
      "novel considerations for the future of collaborative work. How\n",
      "might collaborative work practices change? How might we incor-\n",
      "porate generative AI into shared tools with users’ needs at the\n",
      "forefront? We examine these questions in the context of a remote\n",
      "team conducting ideation tasks – an example of collaborative work\n",
      "enabled by a shared digital workspace. We conducted a user study\n",
      "with 17 professionals experienced with virtual group ideation work-\n",
      "shops. Our study examined their use of the Collaborative Canvas , a\n",
      "virtual canvas tool with integrated generative AI capabilities that\n",
      "we created as a probe. Participants saw value in using generative\n",
      "AI to assist with group facilitation and to augment perspectives\n",
      "and ideas. However, they worried about losing human perspectives\n",
      "and critical thinking, as well as reputational harms resulting from\n",
      "harmful AI outputs. Participants shared suggestions for appropriate\n",
      "ways to incorporate generative AI capabilities within multi-user\n",
      "applications and identified needs for transparency of content own-\n",
      "ership, private digital spaces, and specialized AI capabilities. Based\n",
      "on participants’ insights, we share implications and opportunities\n",
      "for the incorporation of generative AI into collaborative work in\n",
      "ways that place user needs at the forefront.\n",
      "CCS CONCEPTS\n",
      "• Human-centered computing →Empirical studies in HCI ;\n",
      "Empirical studies in collaborative and social computing ; •\n",
      "Computing methodologies →Artificial intelligence.\n",
      "This work is licensed under a Creative Commons Attribution-NonCommercial\n",
      "International 4.0 License.\n",
      "CHIWORK ’24, June 25–27, 2024, Newcastle upon Tyne, United Kingdom\n",
      "© 2024 Copyright held by the owner/author(s).\n",
      "ACM ISBN 979-8-4007-1017-9/24/06\n",
      "https://doi.org/10.1145/3663384.3663398\n",
      "KEYWORDS\n",
      "Group ideation, Brainstorming, Shared virtual canvas, Mixed initia-\n",
      "tive, Generative AI, Future of work\n",
      "ACM Reference Format:\n",
      "Jessica He, Stephanie Houde, Gabriel Enrique Gonzalez, Dario Andres Silva\n",
      "Moran, Steven I. Ross, Michael Muller, and Justin D. Weisz. 2024. AI and\n",
      "the Future of Collaborative Work: Group Ideation with an LLM in a Virtual\n",
      "Canvas. In Proceedings of the 3rd Annual Meeting of the Symposium on\n",
      "Human-Computer Interaction for Work (CHIWORK ’24), June 25–27, 2024,\n",
      "Newcastle upon Tyne, United Kingdom. ACM, New York, NY, USA, 14 pages.\n",
      "https://doi.org/10.1145/3663384.3663398\n",
      "1 INTRODUCTION\n",
      "Generative AI has the potential to automate tasks that were pre-\n",
      "viously thought to be exclusive to humans, raising questions of\n",
      "its impact on the future of work. Rapid advancements in gener-\n",
      "ative AI have already enabled its incorporation into professional\n",
      "work domains such as programming [ 95], research [ 1, 60], and\n",
      "design [41, 57, 113]. In these domains, generative AI can produce\n",
      "ideas, summaries, and suggestions that rival those produced by\n",
      "humans.\n",
      "In the past, many research studies on AI-augmented work have\n",
      "been configured such that one human works with a single AI agent\n",
      "(e.g., [55, 94, 119, 122]). Work by Farrell et al. [26] took an expanded\n",
      "view in which a human works with a back-end collection of AI\n",
      "agents, through a single front-end interface [26]. However, this view\n",
      "does not reflect the reality that work is often performed by groups\n",
      "of colleagues working together [104, 116, 127]. As advancements in\n",
      "generative AI make their way into collaborative domains, there is a\n",
      "need to shift our view to realistic work contexts in which multiple\n",
      "humans interact with each other along with AI agents.\n",
      "One indication of the rise of AI-supported group work is in the\n",
      "introduction of generative AI features to digital canvas tools such as\n",
      "Mural1, Miro2, and Microsoft Whiteboard3. These features include\n",
      "1Mural. https://mural.co\n",
      "2Miro. https://miro.com\n",
      "3Microsoft Whiteboard. https://whiteboard.microsoft.com' metadata={'producer': 'pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5; modified using iText 4.2.0 by 1T3XT', 'creator': 'LaTeX with acmart 2024/04/17 v2.07 Typesetting articles for the Association for Computing Machinery and hyperref 2023-02-07 v7.00v Hypertext links for LaTeX', 'creationdate': '2024-05-06T19:54:44+00:00', 'moddate': '2025-03-20T06:29:09-07:00', 'trapped': '/False', 'subject': '-  Human-centered computing  ->  Empirical studies in HCI.Empirical studies in collaborative and social computing.-  Computing methodologies  ->  Artificial intelligence.', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'title': 'AI and the Future of Collaborative Work: Group Ideation with an LLM in a Virtual Canvas', 'source': 'uploads/7bc07167-7aed-459e-bdb5-6a0f8f0d489c.pdf', 'total_pages': 14, 'page': 0, 'page_label': '1'}\n",
      "Loaded 15 pages from 56305057-255f-464a-bd9e-e53739a2c52c.pdf\n",
      "\n",
      "\n",
      "page_content='TYPE Review\n",
      "PUBLISHED /zero.tnum/six.tnum January /two.tnum/zero.tnum/two.tnum/five.tnum\n",
      "DOI /one.tnum/zero.tnum./three.tnum/three.tnum/eight.tnum/nine.tnum/fcomp./two.tnum/zero.tnum/two.tnum/four.tnum./one.tnum/five.tnum/two.tnum/one.tnum/zero.tnum/six.tnum/six.tnum\n",
      "OPEN ACCESS\n",
      "EDITED BY\n",
      "Stefan Kopp,\n",
      "Bielefeld University, Germany\n",
      "REVIEWED BY\n",
      "Styliani Kleanthous,\n",
      "Open University of Cyprus, Cyprus\n",
      "Milus˘e Balková,\n",
      "Institute of Technology and Business, Czechia\n",
      "*CORRESPONDENCE\n",
      "Mathias Unberath\n",
      "unberath@jhu.edu\n",
      "RECEIVED /zero.tnum/one.tnum November /two.tnum/zero.tnum/two.tnum/four.tnum\n",
      "ACCEPTED /zero.tnum/six.tnum December /two.tnum/zero.tnum/two.tnum/four.tnum\n",
      "PUBLISHED /zero.tnum/six.tnum January /two.tnum/zero.tnum/two.tnum/five.tnum\n",
      "CITATION\n",
      "Gomez C, Cho SM, Ke S, Huang C-M and\n",
      "Unberath M (/two.tnum/zero.tnum/two.tnum/five.tnum) Human-AI collaboration is\n",
      "not very collaborative yet: a taxonomy of\n",
      "interaction patterns in AI-assisted decision\n",
      "making from a systematic review.\n",
      "Front. Comput. Sci./six.tnum:/one.tnum/five.tnum/two.tnum/one.tnum/zero.tnum/six.tnum/six.tnum.\n",
      "doi: /one.tnum/zero.tnum./three.tnum/three.tnum/eight.tnum/nine.tnum/fcomp./two.tnum/zero.tnum/two.tnum/four.tnum./one.tnum/five.tnum/two.tnum/one.tnum/zero.tnum/six.tnum/six.tnum\n",
      "COPYRIGHT\n",
      "© /two.tnum/zero.tnum/two.tnum/five.tnum Gomez, Cho, Ke, Huang and\n",
      "Unberath. This is an open-access article\n",
      "distributed under the terms of the\n",
      "Creative\n",
      "Commons Attribution License (CC BY) . The\n",
      "use, distribution or reproduction in other\n",
      "forums is permitted, provided the original\n",
      "author(s) and the copyright owner(s) are\n",
      "credited and that the original publication in\n",
      "this journal is cited, in accordance with\n",
      "accepted academic practice. No use,\n",
      "distribution or reproduction is permitted\n",
      "which does not comply with these terms.\n",
      "Human-AI collaboration is not\n",
      "very collaborative yet: a\n",
      "taxonomy of interaction patterns\n",
      "in AI-assisted decision making\n",
      "from a systematic review\n",
      "Catalina Gomez, Sue Min Cho, Shichang Ke, Chien-Ming Huang\n",
      "and Mathias Unberath*\n",
      "Department of Computer Science, Johns Hopkins University, Baltim ore, MD, United States\n",
      "Leveraging Artiﬁcial Intelligence (AI) in decision support syst ems has\n",
      "disproportionately focused on technological advancements, ofte n overlooking\n",
      "the alignment between algorithmic outputs and human expectatio ns. A\n",
      "human-centered perspective attempts to alleviate this concern by designing AI\n",
      "solutions for seamless integration with existing processes. Determining what\n",
      "information AI should provide to aid humans is vital, a concept u nderscored by\n",
      "explainable AI’s eﬀorts to justify AI predictions. However, h ow the information\n",
      "is presented, e.g., the sequence of recommendations and solicit ation of\n",
      "interpretations, is equally crucial as complex interactions may e merge between\n",
      "humans and AI. While empirical studies have evaluated human-AI dynamics\n",
      "across domains, a common vocabulary for human-AI interaction prot ocols is\n",
      "lacking. To promote more deliberate consideration of interacti on designs, we\n",
      "introduce a taxonomy of interaction patterns that delineate v arious modes of\n",
      "human-AI interactivity. We summarize the results of a system atic review of\n",
      "AI-assisted decision making literature and identify trends and opportunities\n",
      "in existing interactions across application domains from /one.tnum/zero.tnum/five.tnum articles. We ﬁnd\n",
      "that current interactions are dominated by simplistic collabor ation paradigms,\n",
      "leading to little support for truly interactive functionality . Our taxonomy oﬀers a\n",
      "tool to understand interactivity with AI in decision-making and foster interaction\n",
      "designs for achieving clear communication, trustworthiness, and collaboration.\n",
      "KEYWORDS\n",
      "artiﬁcial intelligence, human-AI interaction, decision-ma king, interaction patterns,\n",
      "interactivity\n",
      "/one.tnum Introduction\n",
      "Advances in Artiﬁcial Intelligence (AI) developments open new possibilities for\n",
      "supporting human decision making across a wide variety of applications. Decision making\n",
      "tasks in a broad range of applications share a process that starts when evidence is presented\n",
      "before making a decision within discrete choices, usually with follow-up eﬀects. Within this\n",
      "framework, the decision-making process emerges as a scenario for human-AI teamwork\n",
      "where at a minimum two parties, i.e., the human and the AI, factor into ﬁnding a solution to\n",
      "the decision problem. The exact dynamics of how this collaboration occurs can vary from\n",
      "one situation to another, leading to multiple interaction options that range from simple\n",
      "Frontiers in Computer Science /zero.tnum/one.tnum frontiersin.org' metadata={'producer': 'dvips + MiKTeX GPL Ghostscript  9.0', 'creator': 'LaTeX with hyperref package + hypdvips', 'creationdate': '2024-12-26T12:14:21+05:30', 'subject': 'Gomez C, Cho SM, Ke S, Huang C-M and Unberath M (2025) Human-AI collaboration is not very collaborative yet: a taxonomy of interaction patterns in AI-assisted decision making from a systematic review. Front. Comput. Sci. 6:1521066. doi: 10.3389/fcomp.2024.1521066', 'author': 'Catalina Gomez', 'keywords': 'artificial intelligence; human-AI interaction; decision-making; interaction patterns; interactivity', 'moddate': '2024-12-26T12:33:06+05:30', 'title': 'Human-AI collaboration is not very collaborative yet: a taxonomy of interaction patterns in AI-assisted decision making from a systematic review', 'source': 'uploads/56305057-255f-464a-bd9e-e53739a2c52c.pdf', 'total_pages': 15, 'page': 0, 'page_label': '1'}\n",
      "Loaded 17 pages from bbbb7c3e-1ebf-4142-afc9-8534aa2e9fab.pdf\n",
      "\n",
      "\n",
      "page_content='Journal of Public Administration Research and Theory, 2023, 33, 153–169\n",
      "https://doi.org/10.1093/jopart/muac007\n",
      "Advance access publication 8 February 2022\n",
      "Article\n",
      "Human–AI Interactions in Public Sector Decision Making: \n",
      "“ Automation Bias” and “Selective Adherence” to \n",
      "Algorithmic Advice\n",
      "Saar Alon-Barkat,*,  Madalina Busuioc†,\n",
      "*University of Haifa, Israel\n",
      "†Vrije Universiteit Amsterdam, The Netherlands\n",
      "Address correspondence to the author at e.m.busuioc@vu.nl.\n",
      "Abstract \n",
      "Artificial intelligence algorithms are increasingly adopted as decisional aides by public bodies, with the promise of overcoming biases of human \n",
      "decision-makers. At the same time, they may introduce new biases in the human–algorithm interaction. Drawing on psychology and public \n",
      "administration literatures, we investigate two key biases: overreliance on algorithmic advice even in the face of “warning signals” from other \n",
      "sources (automation bias), and selective adoption of algorithmic advice when this corresponds to stereotypes (selective adherence). We assess \n",
      "these via three experimental studies conducted in the Netherlands: In study 1 (N = 605), we test automation bias by exploring participants’ \n",
      "adherence to an algorithmic prediction compared to an equivalent human-expert prediction. We do not find evidence for automation bias. In \n",
      "study 2 (N = 904), we replicate these findings, and also test selective adherence. We find a stronger propensity for adherence when the advice \n",
      "is aligned with group stereotypes, with no significant differences between algorithmic and human-expert advice. In study 3 (N = 1,345), we \n",
      "replicate our design with a sample of civil servants. This study was conducted shortly after a major scandal involving public authorities’ reliance \n",
      "on an algorithm with discriminatory outcomes (the “childcare benefits scandal”). The scandal is itself illustrative of our theory and patterns \n",
      "diagnosed empirically in our experiment, yet in our study 3, while supporting our prior findings as to automation bias, we do not find patterns of \n",
      "selective adherence. We suggest this is driven by bureaucrats’ enhanced awareness of discrimination and algorithmic biases in the aftermath of \n",
      "the scandal. We discuss the implications of our findings for public sector decision making in the age of automation. Overall, our study speaks to \n",
      "potential negative effects of automation of the administrative state for already vulnerable and disadvantaged citizens.\n",
      "Introduction\n",
      "Artificial intelligence (AI) algorithms are being widely adopted \n",
      "in the public sector across jurisdictions. Essentially a set of tools \n",
      "that display (or can even surpass) human-level performance \n",
      "on given tasks traditionally associated with human intelli-\n",
      "gence, AI algorithms are being relied upon in areas as varied as \n",
      "policing, welfare, criminal justice, healthcare, immigration, or \n",
      "education (Busuioc 2021; Calo and Citron 2021; Diakopoulos \n",
      "2014; Eubanks 2018; Engstrom et al. 2020; O’Neil 2016; \n",
      "Richardson, Schultz, and Crawford 2019; Veale and Brass \n",
      "2019; Yeung and Lodge 2019), increasingly permeating  \n",
      "non-routine and high-stakes aspects of bureaucratic work. The \n",
      "growing and deepening reliance on AI and machine learning \n",
      "technologies in the public sector has been diagnosed as “trans-\n",
      "formative” of public administrations (Bullock 2019; Vogl et al. \n",
      "2020; Young, Bullock, and Lecy 2019).\n",
      "These developments are driven by the promise of policy \n",
      "solutions that are potentially more effective, efficient, and \n",
      "low-cost. In addition, and importantly, algorithms are said to \n",
      "come with the “promise of neutrality,” in contrast to decision \n",
      "making based on human intuition, which involves biases and \n",
      "can result in discrimination. In other words, AI use in deci-\n",
      "sion making is said to hold the potential to help us overcome \n",
      "our cognitive biases and limitations. This has been an impor-\n",
      "tant driver for the adoption of such technologies in highly \n",
      "consequential public sector areas such as law enforcement or \n",
      "criminal justice: Predictive policing technologies, for instance, \n",
      "were propagated in the US context “as one answer to racially \n",
      "discriminatory policing, offering a seemingly race-neutral, ‘ob-\n",
      "jective’ justification for police targeting of poor communities” \n",
      "(Ferguson 2017, 5). Numerous other jurisdictions have \n",
      "followed suit with predictive technologies relied upon by po-\n",
      "lice forces in the United Kingdom, the Netherlands, Germany, \n",
      "among many others. Like rationales precipitated the adoption \n",
      "of predictive risk assessment systems in criminal justice, sim-\n",
      "ilarly in part in response to concerns with human bias and \n",
      "discrimination (Israni 2017), despite such systems themselves \n",
      "being flagged as sources of bias (Angwin et al. 2016).\n",
      "For a large part, AI algorithms currently serve as decisional \n",
      "aides to human decision-makers (“decision-support sys-\n",
      "tems”) in many bureaucratic contexts. This is especially so \n",
      "in highly consequential public sector areas, where “full au-\n",
      "tomation seems inappropriate or far off” (Edward and Veale \n",
      "2017, 45). Rather than making decisions on their own, al-\n",
      "gorithmic outputs—be they risk assessment scores used in \n",
      "criminal justice or the algorithm-generated “heat maps” of \n",
      "© The Author(s) 2022. Published by Oxford University Press on behalf of the Public Management Research Association.\n",
      "This is an Open Access article distributed under the terms of the Creative Commons Attribution-NonCommercial License (https://creativecommons.org/\n",
      "licenses/by-nc/4.0/), which permits non-commercial re-use, distribution, and reproduction in any medium, provided the original work is properly cited. For \n",
      "commercial re-use, please contact journals.permissions@oup.com\n",
      "We thank the three anonymous JPART reviewers for their extremely help-\n",
      "ful comments. We are also grateful to Dimiter Toshkov, Nadine Raaphorst, \n",
      "Joris van der Voet, Dana Vashdi, Sharon Gilad, Markus Tepe, Stephan \n",
      "Grimmelikhuijsen, Thijs de Boer, Benjamin Tidå, Omer Yair, and Aaron \n",
      "Swaving for their valuable comments and feedback in the process of devel-\n",
      "oping this project. We thank Luuk van Roozendaal for excellent research \n",
      "assistance.\n",
      "Downloaded from https://academic.oup.com/jpart/article/33/1/153/6524536 by guest on 21 March 2025' metadata={'producer': 'Adobe PDF Library 15.0; modified using iTextSharp 4.1.6 by 1T3XT', 'creator': 'Adobe InDesign 15.1 (Windows)', 'creationdate': '2022-12-23T18:23:16+05:30', 'trapped': '/False', 'moddate': '2025-03-21T10:34:28+00:00', 'source': 'uploads/bbbb7c3e-1ebf-4142-afc9-8534aa2e9fab.pdf', 'total_pages': 17, 'page': 0, 'page_label': '153'}\n",
      "Loaded 26 pages from 8561a95c-bae5-4056-9502-e4cce427e1db.pdf\n",
      "\n",
      "\n",
      "page_content='LM Agents for Coordinating Multi-User Information Gathering\n",
      "Harsh Jhamtani, Jacob Andreas, Benjamin Van Durme\n",
      "Microsoft\n",
      "{hjhamtani,jaandrea,ben.vandurme}@microsoft.com\n",
      "Abstract\n",
      "This paper introduces PEOPLE JOIN , a bench-\n",
      "mark for evaluating LM-mediated collaborative\n",
      "problem solving. Given a user request, PEO-\n",
      "PLE JOIN agents must identify teammates who\n",
      "might be able to assist, converse with these\n",
      "teammates to gather information, and finally\n",
      "compile a useful answer or summary for the\n",
      "original user. PEOPLE JOIN comprises two eval-\n",
      "uation domains: PEOPLE JOIN -QA, focused on\n",
      "questions about tabular data, and PEOPLE JOIN -\n",
      "DOCCREATION , focused on document creation\n",
      "tasks. The two domains are adapted from ex-\n",
      "isting NLP benchmarks for database question\n",
      "answering and multi-document summarization;\n",
      "here, however, the information needed to com-\n",
      "plete these tasks is distributed across synthetic\n",
      "“organizations” of 2–20 users, simulating natu-\n",
      "ral multi-user collaboration scenarios. We im-\n",
      "plemented several popular LM agent architec-\n",
      "tures, evaluating their accuracy and efficiency\n",
      "at completing tasks, and highlight new research\n",
      "questions that can be studied using PEOPLE -\n",
      "JOIN .1\n",
      "1 Introduction\n",
      "In today’s fast-paced and interconnected world,\n",
      "effective collaboration is essential for achieving\n",
      "complex tasks and making informed decisions\n",
      "(Papachristou et al., 2023; Gemp et al., 2024).\n",
      "Many decision-making, content creation, and\n",
      "information-gathering tasks require collecting in-\n",
      "formation from multiple people. For example,\n",
      "preparing a list of interns across teams in an or-\n",
      "ganization by reaching out to the leader of each\n",
      "team; preparing a newsletter for project updates\n",
      "might necessitate coordinating with multiple con-\n",
      "tributors; identifying a suitable time to meet might\n",
      "require several rounds of negotiations (Lin et al.,\n",
      "2024). Identifying what information is available,\n",
      "1Code and data can be found at https://github.com/\n",
      "microsoft/peoplejoin/\n",
      "judiciously determining who to contact, asking pre-\n",
      "cise questions, and compiling research results can\n",
      "be a challenging and time-consuming process—\n",
      "especially when real-time interaction between team\n",
      "members is difficult to coordinate.\n",
      "At the same time, recent large language mod-\n",
      "els (LLMs), such as GPT-4 (OpenAI, 2023), Phi-3\n",
      "(Abdin et al., 2024), LLaMa (Touvron et al., 2023),\n",
      "and Gemini (Team et al., 2023), are becoming a cru-\n",
      "cial building block in developing automated agents\n",
      "that can assist human users with complex tasks\n",
      "(Xi et al., 2023; Wang et al., 2024; Butler et al.,\n",
      "2023). These tasks include chat applications for\n",
      "assisting individual users with searching and sum-\n",
      "marizing information (such as in Microsoft Copilot\n",
      "Chat2), and even supporting these users in work-\n",
      "place decision-making (Butler et al., 2023; Kim\n",
      "and Hsu, 2024). Could these agents be extended to\n",
      "improve collaboration among multiple users?\n",
      "In this paper, we introduce PEOPLE JOIN , an\n",
      "evaluation framework for studying effectiveness\n",
      "of LLM-powered agents to assist with multi-user\n",
      "collaboration tasks. Each PEOPLE JOIN task takes\n",
      "place within a fictitious organization with 2–20\n",
      "employees, some of whom possess a collection of\n",
      "documents necessary to solve some task. One of\n",
      "the users (the initiating user) communicates the\n",
      "task to an agent (Fig. 1). Agents have direct ac-\n",
      "cess to the initiating user’s documents, and can\n",
      "engage in conversations with other users to gather\n",
      "relevant information. They must rely on limited\n",
      "descriptions of other users, and potentially previ-\n",
      "ous interactions, to determine who to contact for a\n",
      "given task. PEOPLE JOIN comprises two families\n",
      "of tasks: PEOPLE JOIN -QA and PEOPLE JOIN -\n",
      "DOCCREATION , derived from the SPIDER (Yu\n",
      "et al., 2018) and MULTINEWS (Fabbri et al., 2019)\n",
      "datasets respectively. It evaluates agents’ ability\n",
      "to answer questions involving complex relational\n",
      "2https://copilot.microsoft.com/\n",
      "arXiv:2502.12328v1  [cs.CL]  17 Feb 2025' metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2025-02-19T01:08:14+00:00', 'author': '', 'keywords': '', 'moddate': '2025-02-19T01:08:14+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'subject': '', 'title': '', 'trapped': '/False', 'source': 'uploads/8561a95c-bae5-4056-9502-e4cce427e1db.pdf', 'total_pages': 26, 'page': 0, 'page_label': '1'}\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "from langchain_community.document_loaders import PyPDFLoader\n",
    "\n",
    "# Get all PDF files from uploads directory\n",
    "pdf_files = [f for f in os.listdir(\"uploads\") if f.endswith(\".pdf\")]\n",
    "source = os.path.join(\"uploads\", pdf_files[0]) if pdf_files else None\n",
    "\n",
    "if not source:\n",
    "    print(\"No PDF files found in uploads directory\")\n",
    "for file in pdf_files:\n",
    "    if file == \"0fe06f76-79e9-4ad0-99a1-233b2ecb776d.pdf\":\n",
    "        continue\n",
    "    loader = PyPDFLoader(os.path.join(\"uploads\", file))\n",
    "    pages = []\n",
    "    async for page in loader.alazy_load():\n",
    "        pages.append(page)\n",
    "    print(f\"Loaded {len(pages)} pages from {file}\")\n",
    "    print(f\"\\n\\n{pages[0]}\")\n",
    "# pages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded layout model s3://layout/2025_02_18 on device mps with dtype torch.float16\n",
      "Loaded texify model s3://texify/2025_02_18 on device mps with dtype torch.float16\n",
      "Loaded recognition model s3://text_recognition/2025_02_18 on device mps with dtype torch.float16\n",
      "Loaded table recognition model s3://table_recognition/2025_02_18 on device mps with dtype torch.float16\n",
      "Loaded detection model s3://text_detection/2025_02_28 on device mps with dtype torch.float16\n",
      "Loaded detection model s3://inline_math_detection/2025_02_24 on device mps with dtype torch.float16\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Recognizing layout: 100%|██████████| 3/3 [00:36<00:00, 12.27s/it]\n",
      "Running OCR Error Detection: 100%|██████████| 5/5 [00:01<00:00,  3.44it/s]\n",
      "Detecting bboxes: 0it [00:00, ?it/s]\n",
      "Detecting bboxes: 100%|██████████| 1/1 [00:03<00:00,  3.31s/it]\n",
      "Recognizing Text: 100%|██████████| 3/3 [04:16<00:00, 85.64s/it] \n",
      "Recognizing tables: 100%|██████████| 3/3 [02:01<00:00, 40.65s/it]\n"
     ]
    }
   ],
   "source": [
    "from marker.converters.pdf import PdfConverter\n",
    "from marker.models import create_model_dict\n",
    "from marker.output import text_from_rendered\n",
    "\n",
    "converter = PdfConverter(\n",
    "    artifact_dict=create_model_dict(),\n",
    ")\n",
    "rendered = converter(\"uploads/00b332c3-bc85-4dd0-9baf-15983e523e97.pdf\")\n",
    "text, _, images = text_from_rendered(rendered)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "participatory-ai-for-workshops",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
